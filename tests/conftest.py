import pytest
from unittest.mock import Mock, AsyncMock
from ai_diplomacy.services.config import AgentConfig
from ai_diplomacy.services.llm_coordinator import LLMCoordinator
from ai_diplomacy.services.context_provider import (
    ContextProviderFactory,
    ContextProvider,
)
from ai_diplomacy.core.state import PhaseState
from datetime import datetime
from ai_diplomacy.game_config import GameConfig
from typing import List, Any, Optional, Dict
import logging
import os


@pytest.fixture
def agent_config():
    return AgentConfig(
        country="ENGLAND",
        type="llm",
        model_id="test_model",
        context_provider="inline",
    )


@pytest.fixture
def mock_llm_coordinator():
    return AsyncMock(spec=LLMCoordinator)


@pytest.fixture
def mock_context_provider():
    provider = AsyncMock(spec=ContextProvider)
    provider.provide_context = AsyncMock(
        return_value={
            "context_text": "Mocked context",
            "tools_available": False,
            "tools": [],
            "provider_type": "mock_inline",
        }
    )
    return provider


@pytest.fixture
def mock_context_provider_factory(mock_context_provider):
    factory = Mock(spec=ContextProviderFactory)
    factory.get_provider.return_value = mock_context_provider
    return factory


@pytest.fixture
def mock_phase_state():
    phase_state = AsyncMock(spec=PhaseState)
    phase_state.phase_name = "S1901M"
    phase_state.get_power_units = Mock(return_value=["A LON", "F EDI"])
    phase_state.get_power_centers = Mock(return_value=["LON", "EDI"])
    phase_state.is_game_over = False
    phase_state.powers = ["ENGLAND", "FRANCE", "GERMANY"]
    phase_state.is_power_eliminated = Mock(return_value=False)
    return phase_state


@pytest.fixture
def mock_load_prompt_file(mocker):
    # TODO(remove-when-fixed-upstream): If this mock is considered egregious because it patches a utility function,
    # consider refactoring LLMAgent to allow injecting the system prompt content directly for easier testing.
    return mocker.patch(
        "ai_diplomacy.llm_utils.load_prompt_file",
        return_value="Mocked system prompt",
        autospec=True,  # Adhering to custom instructions
    )


class MockGameConfigResults(GameConfig):
    def __init__(self, game_id="results_test_game", log_to_file=True):
        # Create minimal mock args for parent constructor
        class MockArgs:
            def __init__(self):
                self.game_id = game_id
                self.game_id_prefix = "test"
                self.log_level = "INFO"
                self.log_to_file = log_to_file
                self.log_dir = None  # GameConfig will create a default if None
                self.power_name = None
                self.model_id = None
                self.num_players = 7
                self.perform_planning_phase = False
                self.num_negotiation_rounds = 1
                self.negotiation_style = "simultaneous"
                self.fixed_models = None
                self.randomize_fixed_models = False
                self.exclude_powers = None
                self.max_years = None
                self.dev_mode = False
                self.verbose_llm_debug = False
                self.max_diary_tokens = 6500
                self.models_config_file = "models.toml"  # Default, ensure it exists or is not strictly needed by GameConfig for this mock

        super().__init__(MockArgs())
        # Override for testing if specific paths are needed and not dynamically generated by GameConfig
        self.current_datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        # Ensure game_id_specific_log_dir is set up if GameResultsProcessor uses it directly from the config
        # GameConfig usually sets this up in its __init__


class MockDiplomacyAgent:
    def __init__(self, power_name, model_id="mock_model"):
        self.power_name = power_name
        self.model_id = model_id
        self.goals = [f"Take over the world ({power_name})", "Make friends"]
        self.relationships = {"OTHER_POWER": "Neutral"}
        self.private_journal = [
            f"Journal Entry 1 for {power_name}",
            f"Journal Entry 2 for {power_name}",
        ]
        self.private_diary = [f"[S1901M] Diary entry for {power_name}"]

    def get_agent_info(
        self,
    ):  # Added to match BaseAgent interface if needed by processor
        return {
            "agent_id": f"mock_agent_{self.power_name}",
            "country": self.power_name,
            "type": self.__class__.__name__,
            "model_id": self.model_id,
        }


class MockGameHistoryResults:
    def __init__(self):
        self.phases = [  # Simplified phase objects for testing to_dict fallback
            {"name": "SPRING 1901M", "orders_by_power": {"FRANCE": ["A PAR H"]}},
            {
                "name": "AUTUMN 1901M",
                "orders_by_power": {"FRANCE": ["A PAR - BUR"]},
            },
        ]

    def to_dict(self):  # Added to satisfy GameResultsProcessor's expectation
        return {"phases": self.phases}


class MockDiplomacyGame:  # Mock for diplomacy.Game
    def __init__(self):
        self.is_game_done = True  # Mark as done for saving state
        self._current_phase = "WINTER 1905"  # Example
        self._centers = {  # Example SC map
            "FRANCE": ["PAR", "MAR", "BRE", "SPA", "POR", "BEL", "HOL"],
            "ENGLAND": ["LON", "LVP", "EDI", "NWY", "SWE"],
            "GERMANY": ["BER", "MUN", "KIE", "DEN", "RUH", "WAR", "MOS"],
        }
        self._winners = ["GERMANY"]  # Example winner

    def get_current_phase(self):
        return self._current_phase

    def get_state(self):  # Corresponds to game.map.centers in some diplomacy versions
        return {
            "centers": self._centers
        }  # Or however the real Game object structures this

    def get_winners(self):
        return self._winners

    # This is a static method in the diplomacy library, usually imported.
    # If GameResultsProcessor calls `to_saved_game_format(game_instance)`,
    # it will use the real one. If that's not available or desired in a unit test,
    # this mock might need to be injectable or the calling code refactored.
    # For now, assuming the real `to_saved_game_format` is used or the test doesn't reach it.
    # If to_saved_game_format is part of the Game class in the version used:
    # def to_saved_game_format(self):
    #     import json
    #     return json.dumps({"mock_game_state": self._current_phase, "centers": self._centers, "winners": self._winners})


@pytest.fixture
def mock_game_config_results():
    return MockGameConfigResults()


@pytest.fixture
def mock_diplomacy_agent_france():
    return MockDiplomacyAgent("FRANCE")


@pytest.fixture
def mock_diplomacy_agent_germany():
    return MockDiplomacyAgent("GERMANY", model_id="gpt-4-mini")


@pytest.fixture
def mock_game_history_results():
    return MockGameHistoryResults()


@pytest.fixture
def mock_diplomacy_game():
    return MockDiplomacyGame()


# Mock classes from ai_diplomacy.phase_summary for testing purposes
# TODO: Consider moving these to a more specific fixture file e.g. tests/fixtures/phase_summary_fixtures.py


class MockLLMInterface_PhaseSummary:  # Renamed to avoid conflict if other MockLLMInterfaces exist
    def __init__(self, power_name="FRANCE"):
        self.power_name = power_name
        self.logger = logging.getLogger(f"MockLLMInterface_PhaseSummary.{power_name}")

    async def request(
        self,
        model_id,
        prompt_text,
        system_prompt_text,
        game_id,
        agent_name,
        phase_str,
        request_identifier,
    ):
        # This mock simulate the request method of LLMCoordinator,
        # as PhaseSummaryGenerator uses llm_coordinator.request
        self.logger.info(
            f"request called for {phase_str} by {agent_name} with prompt: {prompt_text[:50]}..."
        )
        return f"This is a generated summary for {agent_name} for phase {phase_str}. Events: ..."


class MockGame_PhaseSummary:  # Renamed to avoid conflict
    def __init__(self, current_phase_name="SPRING 1901M"):
        self.current_short_phase = current_phase_name
        self.powers = {"FRANCE": None, "GERMANY": None}  # Dummy powers

    def get_current_phase(self):  # Ensure this method exists
        return self.current_short_phase


class MockPhase_PhaseSummary:  # Renamed
    def __init__(self, name):
        self.name = name
        self.orders_by_power = {}
        self.messages = []
        self.phase_summaries = {}

    def add_phase_summary(self, power_name, summary):
        self.phase_summaries[power_name] = summary


class MockGameHistory_PhaseSummary:  # Renamed
    def __init__(self):
        self.phases: List[MockPhase_PhaseSummary] = []  # Use renamed MockPhase

    def get_phase_by_name(
        self, name_to_find: str
    ) -> Optional[MockPhase_PhaseSummary]:  # Use renamed
        for p in self.phases:
            if p.name == name_to_find:
                return p
        new_phase = MockPhase_PhaseSummary(name_to_find)
        self.phases.append(new_phase)
        logging.info(
            f"[MockGameHistory_PhaseSummary] Auto-added phase {name_to_find} for summary testing."
        )
        return new_phase

    def get_messages_by_phase(self, phase_name: str) -> List[Any]:
        phase = self.get_phase_by_name(phase_name)
        # Simulate returning list of message-like objects or dictionaries
        # Example: return [type('MockMessage', (), {'sender': 'GERMANY', 'recipient': 'FRANCE', 'content': 'Hello!'})()]
        return phase.messages if phase else []

    def add_phase_summary(self, phase_name: str, power_name: str, summary: str):
        phase = self.get_phase_by_name(phase_name)
        if phase:
            phase.add_phase_summary(power_name, summary)
        else:
            logging.error(
                f"[MockGameHistory_PhaseSummary] Phase {phase_name} not found to add summary for {power_name}"
            )


# MockGameConfig is already imported and potentially mocked from game_results section
# If a distinct MockGameConfig for phase_summary is needed, it should be defined here.
# For now, assuming the existing MockGameConfigResults or direct GameConfig usage is okay.
# Re-using MockArgs from MockGameConfigResults for brevity if it were to be redefined here.


class MockGameConfig_PhaseSummary(GameConfig):
    def __init__(self, power_name="FRANCE"):
        class MockArgs_PhaseSummary:  # Inner class specific to this mock
            def __init__(self):
                self.game_id = "test_phase_summary"
                self.game_id_prefix = "test"
                self.log_level = "INFO"
                self.log_to_file = True
                self.log_dir = None
                self.power_name = power_name
                self.model_id = "default_summary_model"  # Specific for phase summary
                self.num_players = 7
                self.perform_planning_phase = False
                self.num_negotiation_rounds = 1
                self.negotiation_style = "simultaneous"
                self.fixed_models = None
                self.randomize_fixed_models = False
                self.exclude_powers = None
                self.max_years = None
                self.dev_mode = False
                self.verbose_llm_debug = False
                self.max_diary_tokens = 6500
                self.models_config_file = "models.toml"

        super().__init__(MockArgs_PhaseSummary())
        self.llm_log_path = "dummy_llm_log.csv"
        self.agents: Dict[str, Any] = {}  # Store mock agents

        class MockAgent_PhaseSummary:  # Inner class to mock agent behavior for this config
            def __init__(self, p_name):
                self.power_name = p_name
                self.goals = [f"Goal 1 for {p_name}", f"Goal 2 for {p_name}"]
                self.relationships = (
                    {"GERMANY": "Neutral", "ENGLAND": "Friendly"}
                    if p_name == "FRANCE"
                    else {}
                )

        if power_name:
            self.agents[power_name] = MockAgent_PhaseSummary(power_name)


@pytest.fixture
def mock_llm_interface_phase_summary():
    return MockLLMInterface_PhaseSummary()


@pytest.fixture
def mock_game_phase_summary():
    return MockGame_PhaseSummary()


@pytest.fixture
def mock_game_history_phase_summary():
    return MockGameHistory_PhaseSummary()


@pytest.fixture
def mock_game_config_phase_summary():
    return MockGameConfig_PhaseSummary()


# Mock classes from ai_diplomacy.logging_setup for testing purposes
# TODO: Consider moving these to a more specific fixture file e.g. tests/fixtures/logging_fixtures.py


class MockArgs_LoggingSetup:
    def __init__(
        self,
        log_level="DEBUG",
        game_id="test_log_game_conftest",
        log_to_file=True,
        log_dir=None,
    ):
        self.log_level = log_level
        self.game_id_prefix = "test_log_conftest"
        self.game_id = game_id
        # self.current_datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S") # Not needed by MinimalGameConfig_LoggingSetup
        self.log_to_file = log_to_file
        self.log_dir = log_dir
        # Attributes GameConfig expects from args, that MinimalGameConfig_LoggingSetup might not use directly
        # but could be part of a fuller GameConfig mock if this were to replace it.
        self.power_name = None
        self.model_id = None
        self.num_players = 7
        self.perform_planning_phase = False
        self.num_negotiation_rounds = 3
        self.negotiation_style = "simultaneous"
        self.fixed_models = None
        self.randomize_fixed_models = False
        self.exclude_powers = None
        self.max_years = None
        self.dev_mode = False  # Added as GameConfig might expect it
        self.verbose_llm_debug = False  # Added as GameConfig might expect it
        self.max_diary_tokens = 6500  # Added
        self.models_config_file = "models.toml"  # Added


class MinimalGameConfig_LoggingSetup:
    """Minimal mock for GameConfig to test logging_setup.py directly."""

    def __init__(
        self,
        log_level="DEBUG",
        game_id="test_log_game_conftest",
        log_to_file=True,
        log_dir=None,
        verbose_llm_debug=False,
    ):
        self.log_level = log_level
        self.game_id = game_id
        self.log_to_file = log_to_file
        # Ensure log_dir is used to construct general_log_path, creating a default if None.
        # This logic should ideally mirror GameConfig or be robust for testing.
        effective_log_dir = log_dir if log_dir else os.path.join(".", "temp_test_logs")
        os.makedirs(effective_log_dir, exist_ok=True)  # Ensure dir exists for test runs
        self.general_log_path = os.path.join(
            effective_log_dir, f"{game_id}_general.log"
        )
        self.verbose_llm_debug = verbose_llm_debug
        # Add other attributes that setup_logging might expect from GameConfig
        # For example, if setup_logging accesses self.config.some_other_path


@pytest.fixture
def mock_args_logging_setup():
    return MockArgs_LoggingSetup()


@pytest.fixture
def minimal_game_config_logging_setup_debug_verbose_false():
    return MinimalGameConfig_LoggingSetup(
        log_level="DEBUG", game_id="conftest_log_test_dvf", verbose_llm_debug=False
    )


@pytest.fixture
def minimal_game_config_logging_setup_debug_verbose_true():
    return MinimalGameConfig_LoggingSetup(
        log_level="DEBUG", game_id="conftest_log_test_dvt", verbose_llm_debug=True
    )


@pytest.fixture
def minimal_game_config_logging_setup_info_verbose_false():
    return MinimalGameConfig_LoggingSetup(
        log_level="INFO", game_id="conftest_log_test_ivf", verbose_llm_debug=False
    )
