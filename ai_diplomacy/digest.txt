Directory structure:
└── ai_diplomacy/
    ├── __init__.py
    ├── agent.py
    ├── agent_manager.py
    ├── game_config.py
    ├── game_history.py
    ├── game_orchestrator.py
    ├── game_results.py
    ├── initialization.py
    ├── llm_coordinator.py
    ├── llm_utils.py
    ├── llms.txt
    ├── logging_setup.py
    ├── narrative.py
    ├── negotiations.py
    ├── phase_summary.py
    ├── planning.py
    ├── possible_order_context.py
    ├── prompt_constructor.py
    ├── prompt_utils.py
    ├── utils.py
    ├── agents/
    │   ├── __init__.py
    │   ├── base.py
    │   ├── factory.py
    │   ├── llm_agent.py
    │   ├── scripted_agent.py
    │   └── __pycache__/
    ├── core/
    │   ├── __init__.py
    │   ├── manager.py
    │   ├── state.py
    │   └── __pycache__/
    ├── prompts/
    │   ├── __init__.py
    │   ├── austria_system_prompt.txt
    │   ├── context_prompt.txt
    │   ├── conversation_instructions.txt
    │   ├── diary_consolidation_prompt.j2
    │   ├── england_system_prompt.txt
    │   ├── few_shot_example.txt
    │   ├── france_system_prompt.txt
    │   ├── germany_system_prompt.txt
    │   ├── italy_system_prompt.txt
    │   ├── negotiation_diary_prompt.txt
    │   ├── order_diary_prompt.j2
    │   ├── order_instructions.txt
    │   ├── phase_result_diary_prompt.txt
    │   ├── planning_instructions.txt
    │   ├── russia_system_prompt.txt
    │   ├── state_update_prompt.txt
    │   ├── system_prompt.txt
    │   └── turkey_system_prompt.txt
    └── services/
        ├── __init__.py
        ├── config.py
        ├── context_provider.py
        ├── llm_coordinator.py
        ├── usage_tracker.py
        └── __pycache__/

================================================
File: __init__.py
================================================



================================================
File: agent.py
================================================
import logging
import os
from typing import List, Dict, Optional
# Removed: import re
# Removed: import asyncio
# Removed: import json

import llm # Import the llm library
from diplomacy import Game # Message is removed
from .game_history import GameHistory
from . import llm_utils # Import the new module
from . import prompt_utils # Import for Jinja2 rendering
# Removed: from .utils import log_llm_response
from .prompt_constructor import build_context_prompt # Added import
from .services.llm_coordinator import LLMCoordinator, LLMCallResult
from .game_config import GameConfig # Added import for GameConfig
# Removed: from .llm_interface import AgentLLMInterface
# Removed: from ai_diplomacy.prompts import SYSTEM_PROMPT_TEMPLATE, POWER_SPECIFIC_PROMPTS, PLANNING_PROMPT_TEMPLATE, NEGOTIATION_DIARY_PROMPT_TEMPLATE, ORDER_SUBMISSION_PROMPT_TEMPLATE, ORDER_DIARY_PROMPT_TEMPLATE

logger = logging.getLogger(__name__) # Module-level logger

# == Best Practice: Define constants at module level ==
ALL_POWERS = frozenset({"AUSTRIA", "ENGLAND", "FRANCE", "GERMANY", "ITALY", "RUSSIA", "TURKEY"})
ALLOWED_RELATIONSHIPS = ["Enemy", "Unfriendly", "Neutral", "Friendly", "Ally"]

# Global LLM Coordinator instance
_global_llm_coordinator = LLMCoordinator()

# _local_llm_lock has been moved to llm_coordinator.py
# _load_prompt_file function has been moved to llm_utils.py

class DiplomacyAgent:
    """
    Represents a stateful AI agent playing as a specific power in Diplomacy.
    It holds the agent's goals, relationships, and private journal,
    and uses a BaseModelClient instance to interact with the LLM.
    """
    def __init__(
        self, 
        power_name: str, 
        model_id: str, # Changed from client: BaseModelClient
        game_config: 'GameConfig', # Added game_config parameter
        game_id: str = "unknown_game",  # Add game_id parameter
        initial_goals: Optional[List[str]] = None,
        initial_relationships: Optional[Dict[str, str]] = None,
    ):
        """
        Initializes the DiplomacyAgent.

        Args:
            power_name: The name of the power this agent represents (e.g., 'FRANCE').
            model_id: The llm-compatible model ID string for LLM interaction.
            game_config: The game configuration object.
            game_id: The ID of the game this agent is playing in.
            initial_goals: An optional list of initial strategic goals.
            initial_relationships: An optional dictionary mapping other power names to 
                                     relationship statuses (e.g., 'ALLY', 'ENEMY', 'NEUTRAL').
        """
        if power_name not in ALL_POWERS:
            raise ValueError(f"Invalid power name: {power_name}. Must be one of {ALL_POWERS}")

        self.power_name: str = power_name
        self.model_id: str = model_id
        self.game_config = game_config # Store game_config
        self.game_id: str = game_id
        
        # Validate the model_id at initialization
        try:
            # Validate the model_id by trying to get the model instance
            # The Ollama plugin for the 'llm' library typically relies on
            # environment variables like OLLAMA_HOST or OLLAMA_BASE_URL.
            # Passing 'options' here was causing the TypeError.
            logger.debug(f"[{self.power_name} __init__] Checking Ollama ENV VARS before llm.get_model for validation:")
            logger.debug(f"[{self.power_name} __init__] OLLAMA_HOST: {os.environ.get('OLLAMA_HOST')}")
            logger.debug(f"[{self.power_name} __init__] OLLAMA_BASE_URL: {os.environ.get('OLLAMA_BASE_URL')}")
            logger.debug(f"[{self.power_name} __init__] OLLAMA_PORT: {os.environ.get('OLLAMA_PORT')}")

            # Corrected call: removed the 'options' argument.
            _ = llm.get_model(self.model_id)
            
            logger.info(f"Successfully validated model_id '{self.model_id}' for agent {self.power_name}.")
            self._model_instance = None # Initialize but don't keep it loaded yet. Lazy load in methods.
        except llm.UnknownModelError as ume:
            logger.error(f"CRITICAL: Unknown model_id '{self.model_id}' for agent {self.power_name}. This agent will not function. Error: {ume}")
            raise # Re-raise the error to halt initialization if the model is unknown
        except Exception as e: # General exception handling for other errors
            logger.error(f"CRITICAL: Unexpected error validating model_id '{self.model_id}' for agent {self.power_name}: {e}")
            raise # Re-raise any other critical error during model validation
        
        self.goals: List[str] = initial_goals if initial_goals is not None else [] 
        
        # Initialize relationships to Neutral if not provided
        if initial_relationships is None:
            self.relationships: Dict[str, str] = {p: "Neutral" for p in ALL_POWERS if p != self.power_name}
        else:
            self.relationships: Dict[str, str] = initial_relationships
        
        # Initialize private tracking lists
        self.private_journal: List[str] = []
        self.private_diary: List[str] = []

        # --- Load and store the system prompt ---
        # Note: llm_utils.load_prompt_file defaults to looking in 'ai_diplomacy/prompts/'
        power_prompt_filename_only = f"{power_name.lower()}_system_prompt.txt"
        default_prompt_filename_only = "system_prompt.txt"

        system_prompt_content = llm_utils.load_prompt_file(power_prompt_filename_only)

        if not system_prompt_content:
            logger.warning(f"Power-specific prompt '{power_prompt_filename_only}' not found or empty. Loading default system prompt.")
            system_prompt_content = llm_utils.load_prompt_file(default_prompt_filename_only)
        else:
            logger.info(f"Loaded power-specific system prompt for {power_name}.")
        
        self.system_prompt: Optional[str] = system_prompt_content
        if not self.system_prompt:
            logger.error(f"Could not load default system prompt either! Agent {power_name} may not function correctly.")
        
        # Removed: Initialize the LLM interface for this agent
        # self.llm_interface = AgentLLMInterface(
        #     model_id=self.model_id,
        #     system_prompt=self.system_prompt,
        #     coordinator=_global_llm_coordinator,
        #     power_name=self.power_name
        # )
        
        logger.info(f"Initialized DiplomacyAgent for {self.power_name} with model_id {self.model_id} and goals: {self.goals}")
        self.add_journal_entry(f"Agent initialized with model {self.model_id}. Initial Goals: {self.goals}")

    # _extract_json_from_text and _clean_json_text have been moved to llm_utils.py

    def add_journal_entry(self, entry: str):
        """Adds a formatted entry string to the agent's private journal."""
        if not isinstance(entry, str):
            entry = str(entry)
        self.private_journal.append(entry)
        logger.debug(f"[{self.power_name} Journal]: {entry}")

    def add_diary_entry(self, entry: str, phase: str):
        """Adds a formatted entry string to the agent's private diary."""
        if not isinstance(entry, str):
            entry = str(entry)
        formatted_entry = f"[{phase}] {entry}"
        self.private_diary.append(formatted_entry)
        logger.info(f"[{self.power_name}] DIARY ENTRY ADDED for {phase}. Total entries: {len(self.private_diary)}. New entry: {entry[:100]}...")

    def format_private_diary_for_prompt(self, initial_max_entries_fallback=40) -> str:
        """
        Formats private diary entries for inclusion in a prompt, respecting a token budget.
        The diary (self.private_diary) may be trimmed if its estimated token count exceeds the budget.
        """
        logger.info(f"[{self.power_name}] Formatting diary. Max entries hint: {initial_max_entries_fallback}, Token budget: {self.game_config.max_diary_tokens}")

        if not self.private_diary:
            logger.warning(f"[{self.power_name}] No diary entries found.")
            return "(No diary entries yet)"

        # Start with a slice of the diary based on initial_max_entries_fallback
        # Ensure we don't go out of bounds if diary is shorter than initial_max_entries_fallback
        start_index = max(0, len(self.private_diary) - initial_max_entries_fallback)
        # Make a copy to work with, to decide what to keep from the original self.private_diary
        working_diary_entries = list(self.private_diary[start_index:]) 
        
        final_formatted_diary = ""
        final_kept_entries_for_prompt: List[str] = []


        while True:
            if not working_diary_entries:
                logger.warning(f"[{self.power_name}] Diary (working copy) became empty while trying to meet token budget {self.game_config.max_diary_tokens}.")
                final_formatted_diary = "(Diary empty after trimming for token budget)"
                final_kept_entries_for_prompt = []
                break

            current_formatted_diary = "\n".join(working_diary_entries)
            # Token estimation: characters / 3 (approximate)
            estimated_tokens = len(current_formatted_diary) / 3 

            if estimated_tokens <= self.game_config.max_diary_tokens:
                logger.info(f"[{self.power_name}] Diary token count ({estimated_tokens:.0f}) for {len(working_diary_entries)} entries is within budget ({self.game_config.max_diary_tokens}).")
                final_formatted_diary = current_formatted_diary
                final_kept_entries_for_prompt = list(working_diary_entries) # Store the version that fits
                break
            
            # If over budget, remove the oldest entry from our working list
            removed_entry = working_diary_entries.pop(0) # Remove from the front (oldest)
            logger.info(f"[{self.power_name}] Trimming diary for token budget. Approx tokens: {estimated_tokens:.0f}. Budget: {self.game_config.max_diary_tokens}. Removed oldest of {len(working_diary_entries)+1} entries: {removed_entry[:70]}...")
            
            if not working_diary_entries: # Check again if empty after pop
                 logger.warning(f"[{self.power_name}] Diary (working copy) became empty after last trim for token budget {self.game_config.max_diary_tokens}.")
                 final_formatted_diary = "(Diary empty after trimming for token budget)"
                 final_kept_entries_for_prompt = []
                 break
        
        # Update self.private_diary to reflect the entries that were actually used for the prompt AFTER trimming.
        # This means self.private_diary will now only contain final_kept_entries_for_prompt.
        original_diary_len = len(self.private_diary)
        
        # If final_kept_entries_for_prompt is shorter than the original self.private_diary, update it.
        # This effectively trims self.private_diary to only what was selected and token-budgeted.
        if len(final_kept_entries_for_prompt) < original_diary_len:
            self.private_diary = final_kept_entries_for_prompt
            logger.info(f"[{self.power_name}] Updated self.private_diary due to token budget trimming. Was {original_diary_len} entries, now {len(self.private_diary)}.")
        elif len(final_kept_entries_for_prompt) == original_diary_len and start_index > 0:
            # This means the initial slice based on initial_max_entries_fallback was used without further token trimming,
            # but this slice was shorter than the full diary. So, effectively, the diary was trimmed by initial_max_entries_fallback.
            self.private_diary = final_kept_entries_for_prompt # working_diary_entries was already a slice
            logger.info(f"[{self.power_name}] Updated self.private_diary based on initial_max_entries_fallback. Was {original_diary_len} entries, now {len(self.private_diary)}.")
        # If len(final_kept_entries_for_prompt) == original_diary_len and start_index == 0, no trimming happened.
        
        num_entries_in_prompt = len(final_kept_entries_for_prompt)
        logger.info(f"[{self.power_name}] Formatted {num_entries_in_prompt} diary entries for prompt. Preview: {final_formatted_diary[:200]}...")
        return final_formatted_diary
    
    async def consolidate_year_diary_entries(self, year: str, game: 'Game', log_file_path: str):
        """
        Consolidates all diary entries from a specific year into a concise summary.
        This is called when we're 2+ years past a given year to prevent context bloat.
        
        Args:
            year: The year to consolidate (e.g., "1901")
            game: The game object for context
            log_file_path: Path for logging LLM responses
        """
        logger.debug(f"[{self.power_name}] CONSOLIDATION CALLED for year {year}")
        logger.debug(f"[{self.power_name}] Current diary has {len(self.private_diary)} total entries")
        if self.private_diary:
            logger.debug(f"[{self.power_name}] Sample diary entries:")
            for i, entry in enumerate(self.private_diary[:3]):
                logger.debug(f"[{self.power_name}]   Entry {i}: {entry[:100]}...")
        
        # Find all diary entries from the specified year
        year_entries = []
        # Update pattern to match phase format: [S1901M], [F1901M], [W1901A] etc.
        # We need to check for [S1901, [F1901, [W1901
        patterns_to_check = [f"[S{year}", f"[F{year}", f"[W{year}"]
        logger.debug(f"[{self.power_name}] Looking for entries matching patterns: {patterns_to_check}")
        
        for i, entry in enumerate(self.private_diary):
            # Check if entry matches any of our patterns
            for pattern in patterns_to_check:
                if pattern in entry:
                    year_entries.append(entry)
                    logger.debug(f"[{self.power_name}] Found matching entry {i} with pattern '{pattern}': {entry[:50]}...")
                    break  # Don't add the same entry multiple times
        
        if not year_entries:
            logger.debug(f"[{self.power_name}] No diary entries found for year {year} using patterns: {patterns_to_check}")
            return
        
        logger.debug(f"[{self.power_name}] Found {len(year_entries)} entries to consolidate for year {year}")
        
        year_diary_text_for_prompt = "\n\n".join(year_entries)
        current_game_phase = game.current_short_phase if game else f"Consolidate-{year}"
        consolidated_entry = f"(Error: LLM call for diary consolidation failed for year {year})" # Default fallback

        try:
            prompt_text = prompt_utils.render_prompt(
                'diary_consolidation_prompt.j2', # Using .j2 extension now
                power_name=self.power_name,
                year=year,
                year_diary_entries=year_diary_text_for_prompt
            )
            logger.info(f"[{self.power_name}] Successfully rendered diary_consolidation_prompt.j2 template using Jinja2.")
        except FileNotFoundError as e:
            logger.error(f"[{self.power_name}] diary_consolidation_prompt.j2 template file not found: {e}.")
            consolidated_entry = f"(Error: Prompt template 'diary_consolidation_prompt.j2' not found for year {year})"
        except Exception as e: # Catch other Jinja2 rendering errors
            logger.error(f"[{self.power_name}] Error rendering diary_consolidation_prompt.j2 with Jinja2: {e}.")
            consolidated_entry = f"(Error: Could not render prompt for diary_consolidation for year {year}: {e})"
        else:
            # Proceed with LLM call only if prompt rendering was successful
            result: LLMCallResult = await _global_llm_coordinator.call_llm_with_json_parsing(
                model_id=self.model_id,
                prompt=prompt_text,
                system_prompt=self.system_prompt,
                request_identifier=f"{self.power_name}-diary_consolidation",
                expected_json_fields=None,  # Expecting raw text
                game_id=self.game_id,
                agent_name=self.power_name,
                phase_str=current_game_phase,
                log_to_file_path=log_file_path,
                response_type="diary_consolidation"
            )

            if result.success:
                consolidated_entry = result.raw_response.strip() if result.raw_response else ""
                if not consolidated_entry: # If LLM returned empty string
                    logger.warning(f"[{self.power_name}] Diary consolidation for {year} returned empty response.")
                    consolidated_entry = f"(LLM returned empty summary for {year} consolidation)"
            else:
                logger.error(f"[{self.power_name}] LLM call for diary consolidation for {year} failed: {result.error_message}")
                consolidated_entry = f"(Error: LLM call failed during diary consolidation for {year}: {result.error_message})"

        # Process the consolidated_entry (whether it's a success or an error/fallback message)
        if consolidated_entry and not consolidated_entry.startswith("(Error:") and not consolidated_entry.startswith("(LLM returned empty summary"):
            try:
                # Separate entries logic
                existing_consolidated = []
                entries_to_keep = []
                for existing_entry_item in self.private_diary: # Renamed to avoid conflict
                    if existing_entry_item.startswith("[CONSOLIDATED"):
                        existing_consolidated.append(existing_entry_item)
                    else:
                        is_from_consolidated_year = False
                        for pattern_to_check in patterns_to_check:
                            if pattern_to_check in existing_entry_item:
                                is_from_consolidated_year = True
                                break
                        if not is_from_consolidated_year:
                            entries_to_keep.append(existing_entry_item)
                
                new_consolidated_summary = f"[CONSOLIDATED {year}] {consolidated_entry.strip()}" # consolidated_entry is already stripped if successful
                existing_consolidated.append(new_consolidated_summary)
                # Sort consolidated entries by year (ascending) to keep historical order
                existing_consolidated.sort(key=lambda x: x[14:18], reverse=False) # Assuming format [CONSOLIDATED YYYY]
                
                self.private_diary = existing_consolidated + entries_to_keep
                logger.info(f"[{self.power_name}] Successfully processed diary consolidation for {year}. Consolidated {len(year_entries)} entries.")
            except Exception as e:
                 logger.error(f"[{self.power_name}] Error processing successfully generated consolidated diary entry for {year}: {e}", exc_info=True)
                 self.add_diary_entry(f"Raw successful consolidation for {year} (processing error): {consolidated_entry.strip()}", current_game_phase)
        else: # This 'else' now covers cases where consolidated_entry starts with "(Error:" or "(LLM returned empty summary"
            logger.warning(f"[{self.power_name}] Diary consolidation for {year} resulted in: {consolidated_entry}")
            self.add_diary_entry(f"Consolidation attempt for {year}: {consolidated_entry}", current_game_phase)


    async def generate_negotiation_diary_entry(self, game: 'Game', game_history: 'GameHistory', log_file_path: str):
        """
        Generates a diary entry summarizing negotiations and updates relationships.
        """
        logger.info(f"[{self.power_name}] Generating negotiation diary entry for {game.current_short_phase}..." )
        
        # Load the template
        prompt_template = llm_utils.load_prompt_file('negotiation_diary_prompt.txt')
        if not prompt_template:
            logger.error(f"[{self.power_name}] Could not load negotiation_diary_prompt.txt. Skipping diary entry.")
            return
        
        # Prepare context for the prompt (this logic remains largely the same)
        try:
            board_state_dict = game.get_state()
            board_state_str = f"Units: {board_state_dict.get('units', {})}, Centers: {board_state_dict.get('centers', {})}"
            
            messages_this_round = game_history.get_messages_this_round(
                power_name=self.power_name,
                current_phase_name=game.current_short_phase
            )
            if not messages_this_round.strip() or messages_this_round.startswith("\n(No messages"):
                messages_this_round = "(No messages involving your power this round that require deep reflection for diary. Focus on overall situation.)"
            
            current_relationships_str = str(self.relationships)
            current_goals_str = str(self.goals)
            formatted_diary = self.format_private_diary_for_prompt()
            
            ignored_messages = game_history.get_ignored_messages_by_power(self.power_name)
            ignored_context_parts = []
            if ignored_messages:
                ignored_context_parts.append("\n\nPOWERS NOT RESPONDING TO YOUR MESSAGES:")
                for power, msgs in ignored_messages.items():
                    ignored_context_parts.append(f"{power}:")
                    for msg_data in msgs[-2:]:
                        ignored_context_parts.append(f"  - Phase {msg_data['phase']}: {msg_data['content'][:100]}...")
            else:
                ignored_context_parts.append("\n\nAll powers have been responsive to your messages.")
            ignored_context = "\n".join(ignored_context_parts)

            # Create the prompt using the template
            prompt = prompt_template.format(
                power_name=self.power_name,
                current_phase=game.current_short_phase,
                board_state_str=board_state_str,
                messages_this_round=messages_this_round,
                agent_relationships=current_relationships_str,
                agent_goals=current_goals_str,
                allowed_relationships_str=", ".join(ALLOWED_RELATIONSHIPS),
                private_diary_summary=formatted_diary,
                ignored_messages_context=ignored_context
            )
            
            logger.debug(f"[{self.power_name}] Negotiation diary prompt:\n{prompt[:500]}...")

            # Use the new centralized LLM call approach
            result = await _global_llm_coordinator.call_llm_with_json_parsing(
                model_id=self.model_id,
                prompt=prompt,
                system_prompt=self.system_prompt,
                request_identifier=f"{self.power_name}-negotiation_diary",
                expected_json_fields=["negotiation_summary"],  # Main field we expect
                game_id=self.game_id,
                agent_name=self.power_name,
                phase_str=game.current_short_phase,
                log_to_file_path=log_file_path,
                response_type="negotiation_diary"
            )

            diary_entry_text = "(LLM diary entry generation or parsing failed.)" # Fallback
            relationships_updated = False

            if result.success and result.parsed_json:
                parsed_data = result.parsed_json
                
                # Fix 1: Be more robust about extracting the negotiation_summary field
                diary_text_candidate = None
                for key in ['negotiation_summary', 'summary', 'diary_entry']:
                    if key in parsed_data and isinstance(parsed_data[key], str) and parsed_data[key].strip():
                        diary_text_candidate = parsed_data[key].strip()
                        logger.info(f"[{self.power_name}] Successfully extracted '{key}' for diary.")
                        break
                        
                if diary_text_candidate:
                    diary_entry_text = diary_text_candidate
                else:
                    logger.warning(f"[{self.power_name}] Could not find valid summary field in diary response. Using fallback.")
                
                # Fix 2: Be more robust about extracting relationship updates
                new_relationships = llm_utils.extract_relationships(parsed_data)
                        
                if new_relationships is not None:
                    valid_new_rels = {}
                    for p, r in new_relationships.items():
                        p_upper = str(p).upper()
                        r_title = str(r).title()
                        if p_upper in ALL_POWERS and p_upper != self.power_name and r_title in ALLOWED_RELATIONSHIPS:
                            valid_new_rels[p_upper] = r_title
                        elif p_upper != self.power_name: # Log invalid relationship for a valid power
                            logger.warning(f"[{self.power_name}] Invalid relationship '{r}' for power '{p}' in diary update. Keeping old.")
                    
                    if valid_new_rels:
                        # Log changes before applying
                        for p_changed, new_r_val in valid_new_rels.items():
                            old_r_val = self.relationships.get(p_changed, "Unknown")
                            if old_r_val != new_r_val:
                                logger.info(f"[{self.power_name}] Relationship with {p_changed} changing from {old_r_val} to {new_r_val} based on diary.")
                        self.relationships.update(valid_new_rels)
                        relationships_updated = True
                    else:
                        logger.info(f"[{self.power_name}] No valid relationship updates found in diary response.")
                else:
                    logger.info(f"[{self.power_name}] No relationship updates found in diary response.")
            else:
                logger.warning(f"[{self.power_name}] Failed to generate negotiation diary: {result.error_message}")

            # Add the generated (or fallback) diary entry
            self.add_diary_entry(diary_entry_text, game.current_short_phase)
            if relationships_updated:
                self.add_journal_entry(f"[{game.current_short_phase}] Relationships updated after negotiation diary: {self.relationships}")

        except Exception as e:
            # Log the full exception details for better debugging
            logger.error(f"[{self.power_name}] Caught unexpected error in generate_negotiation_diary_entry: {type(e).__name__}: {e}", exc_info=True)
            # Add a fallback diary entry in case of general error
            self.add_diary_entry(f"(Error generating diary entry: {type(e).__name__})", game.current_short_phase)

    async def generate_order_diary_entry(self, game: 'Game', orders: List[str], log_file_path: str):
        """
        Generates a diary entry reflecting on the decided orders.
        """
        logger.info(f"[{self.power_name}] Generating order diary entry for {game.current_short_phase}...")
        
        board_state_dict = game.get_state()
        board_state_str = f"Units: {board_state_dict.get('units', {})}, Centers: {board_state_dict.get('centers', {})}"
        
        orders_list_str = "\n".join([f"- {o}" for o in orders]) if orders else "No orders submitted."
        
        goals_str = "\n".join([f"- {g}" for g in self.goals]) if self.goals else "None"
        relationships_str = "\n".join([f"- {p}: {s}" for p, s in self.relationships.items()]) if self.relationships else "None"
        
        try:
            prompt = prompt_utils.render_prompt(
                'order_diary_prompt.j2',  # Use the new .j2 extension
                power_name=self.power_name,
                current_phase=game.current_short_phase,
                orders_list_str=orders_list_str,
                board_state_str=board_state_str,
                agent_goals=goals_str,
                agent_relationships=relationships_str
            )
            logger.info(f"[{self.power_name}] Successfully rendered order diary prompt template using Jinja2.")
        except FileNotFoundError as e:
            logger.error(f"[{self.power_name}] Order diary prompt template file not found: {e}. Skipping diary entry.")
            fallback_diary_on_file_not_found = f"Submitted orders for {game.current_short_phase}: {', '.join(orders)}. (Internal error: Prompt template file not found)"
            self.add_diary_entry(fallback_diary_on_file_not_found, game.current_short_phase)
            return
        except Exception as e: # Catch other Jinja2 rendering errors
            logger.error(f"[{self.power_name}] Error rendering order diary template with Jinja2: {e}. Skipping diary entry.")
            # Add a fallback diary entry in case of prompt rendering error
            fallback_diary_on_render_error = f"Submitted orders for {game.current_short_phase}: {', '.join(orders)}. (Internal error: Could not render prompt: {e})"
            self.add_diary_entry(fallback_diary_on_render_error, game.current_short_phase)
            logger.warning(f"[{self.power_name}] Added fallback diary due to prompt rendering error.")
            return
        
        logger.debug(f"[{self.power_name}] Order diary prompt (first 300 chars):\n{prompt[:300]}...")

        # Use the new centralized LLM call wrapper
        result: LLMCallResult = await _global_llm_coordinator.call_llm_with_json_parsing(
            model_id=self.model_id,
            prompt=prompt,
            system_prompt=self.system_prompt,
            request_identifier=f"{self.power_name}-order_diary",
            expected_json_fields=["order_summary"],
            game_id=self.game_id,
            agent_name=self.power_name,
            phase_str=game.current_short_phase,
            log_to_file_path=log_file_path,
            response_type="order_diary"
        )

        if result.success:
            diary_text = result.get_field("order_summary")
            if diary_text and isinstance(diary_text, str) and diary_text.strip():
                self.add_diary_entry(diary_text, game.current_short_phase)
                logger.info(f"[{self.power_name}] Order diary entry generated and added.")
            else:
                # Success was true, but the field was missing or empty
                missing_field_msg = "LLM response successful but 'order_summary' field missing or empty."
                logger.warning(f"[{self.power_name}] {missing_field_msg}")
                fallback_diary = f"Submitted orders for {game.current_short_phase}: {', '.join(orders)}. ({missing_field_msg})"
                self.add_diary_entry(fallback_diary, game.current_short_phase)
        else:
            # Fallback if LLM call failed or returned invalid data
            error_message_for_log = result.error_message if result.error_message else "Unknown error during LLM call."
            fallback_diary = f"Submitted orders for {game.current_short_phase}: {', '.join(orders)}. (LLM failed to generate specific diary entry: {error_message_for_log})"
            self.add_diary_entry(fallback_diary, game.current_short_phase)
            logger.warning(f"[{self.power_name}] Failed to generate specific order diary entry. Added fallback. Error: {error_message_for_log}")

    async def generate_phase_result_diary_entry(
        self, 
        game: 'Game', 
        game_history: 'GameHistory',
        phase_summary: str,
        all_orders: Dict[str, List[str]],
        log_file_path: str
    ):
        """
        Generates a diary entry analyzing the actual phase results,
        comparing them to negotiations and identifying betrayals/collaborations.
        """
        logger.info(f"[{self.power_name}] Generating phase result diary entry for {game.current_short_phase}...")
        
        # Load the template
        prompt_template = llm_utils.load_prompt_file('phase_result_diary_prompt.txt')
        if not prompt_template:
            logger.error(f"[{self.power_name}] Could not load phase_result_diary_prompt.txt. Skipping diary entry.")
            return
        
        # Format all orders for the prompt
        all_orders_formatted = ""
        for power, orders in all_orders.items():
            orders_str = ", ".join(orders) if orders else "No orders"
            all_orders_formatted += f"{power}: {orders_str}\n"
        
        # Get your own orders
        your_orders = all_orders.get(self.power_name, [])
        your_orders_str = ", ".join(your_orders) if your_orders else "No orders"
        
        # Get recent negotiations for this phase
        messages_this_phase = game_history.get_messages_by_phase(game.current_short_phase)
        your_negotiations = ""
        for msg in messages_this_phase:
            if msg.sender == self.power_name:
                your_negotiations += f"To {msg.recipient}: {msg.content}\n"
            elif msg.recipient == self.power_name:
                your_negotiations += f"From {msg.sender}: {msg.content}\n"
        
        if not your_negotiations:
            your_negotiations = "No negotiations this phase"
        
        # Format relationships
        relationships_str = "\n".join([f"{p}: {r}" for p, r in self.relationships.items()])
        
        # Format goals
        goals_str = "\n".join([f"- {g}" for g in self.goals]) if self.goals else "None"
        
        # Create the prompt
        prompt = prompt_template.format(
            power_name=self.power_name,
            current_phase=game.current_short_phase,
            phase_summary=phase_summary,
            all_orders_formatted=all_orders_formatted,
            your_negotiations=your_negotiations,
            pre_phase_relationships=relationships_str,
            agent_goals=goals_str,
            your_actual_orders=your_orders_str
        )
        
        logger.debug(f"[{self.power_name}] Phase result diary prompt:\n{prompt[:500]}...")
        
        # Use the new centralized LLM call approach
        result = await _global_llm_coordinator.call_llm_with_json_parsing(
            model_id=self.model_id,
            prompt=prompt,
            system_prompt=self.system_prompt,
            request_identifier=f"{self.power_name}-phase_result_diary",
            expected_json_fields=None,  # This might return plain text or JSON
            game_id=self.game_id,
            agent_name=self.power_name,
            phase_str=game.current_short_phase,
            log_to_file_path=log_file_path,
            response_type="phase_result_diary"
        )

        if result.success and result.raw_response.strip():
            diary_entry = result.raw_response.strip()
            self.add_diary_entry(diary_entry, game.current_short_phase)
            logger.info(f"[{self.power_name}] Phase result diary entry generated and added.")
        else:
            fallback_diary = f"Phase {game.current_short_phase} completed. Orders executed as: {your_orders_str}. (Failed to generate detailed analysis: {result.error_message})"
            self.add_diary_entry(fallback_diary, game.current_short_phase)
            logger.warning(f"[{self.power_name}] Failed to generate phase result diary. Added fallback. Error: {result.error_message}")

    def log_state(self, prefix=""):
        logger.debug(f"[{self.power_name}] {prefix} State: Goals={self.goals}, Relationships={self.relationships}")

    # Make this method async
    async def analyze_phase_and_update_state(self, game: 'Game', board_state: dict, phase_summary: str, game_history: 'GameHistory', log_file_path: str):
        """Analyzes the outcome of the last phase and updates goals/relationships using the LLM."""
        power_name = self.power_name 
        current_phase = game.get_current_phase()
        logger.info(f"[{power_name}] Analyzing phase {current_phase} outcome to update state...")
        self.log_state(f"Before State Update ({current_phase})")

        try:
            # 1. Construct the prompt using the dedicated state update prompt file
            prompt_template = llm_utils.load_prompt_file('state_update_prompt.txt')
            if not prompt_template:
                 logger.error(f"[{power_name}] Could not load state_update_prompt.txt. Skipping state update.")
                 return
 
            # Get previous phase safely from history
            if not game_history or not game_history.phases:
                logger.warning(f"[{power_name}] No game history available to analyze for {game.current_short_phase}. Skipping state update.")
                return

            last_phase = game_history.phases[-1]
            last_phase_name = last_phase.name # Assuming phase object has a 'name' attribute
            
            # Use the provided phase_summary parameter instead of retrieving it
            last_phase_summary = phase_summary
            if not last_phase_summary:
                logger.warning(f"[{power_name}] No summary available for previous phase {last_phase_name}. Skipping state update.")
                return
 
            # Add previous phase summary to the information provided to the LLM
            other_powers = [p for p in game.powers if p != power_name]
            
            # Create a readable board state string from the board_state dict
            board_state_str = "Board State:\n"
            for p_name, power_data in board_state.get('powers', {}).items():
                # Get units and centers from the board state
                units = power_data.get('units', [])
                centers = power_data.get('centers', [])
                board_state_str += f"  {p_name}: Units={units}, Centers={centers}\n"
            
            # Extract year from the phase name (e.g., "S1901M" -> "1901")
            current_year = last_phase_name[1:5] if len(last_phase_name) >= 5 else "unknown"
            
            prompt = prompt_template.format(
                power_name=power_name,
                current_year=current_year,
                current_phase=last_phase_name, # Analyze the phase that just ended
                board_state_str=board_state_str,
                phase_summary=last_phase_summary, # Use provided phase_summary
                other_powers=str(other_powers),
                current_goals="\n".join([f"- {g}" for g in self.goals]) if self.goals else "None",
                current_relationships=str(self.relationships) if self.relationships else "None"
            )
            logger.debug(f"[{power_name}] State update prompt:\n{prompt}")

            # Use the new centralized LLM call approach
            result = await _global_llm_coordinator.call_llm_with_json_parsing(
                model_id=self.model_id,
                prompt=prompt,
                system_prompt=self.system_prompt,
                request_identifier=f"{power_name}-state_update",
                expected_json_fields=["reasoning", "relationships", "goals"],
                game_id=self.game_id,
                agent_name=power_name,
                phase_str=current_phase,
                log_to_file_path=log_file_path,
                response_type="state_update"
            )

            if result.success and result.parsed_json:
                update_data = result.parsed_json
                
                # Use the helper functions to extract goals and relationships
                extracted_goals = llm_utils.extract_goals(update_data)
                extracted_relationships = llm_utils.extract_relationships(update_data)
                
                if extracted_goals is not None:
                    self.goals = extracted_goals
                    self.add_journal_entry(f"[{game.current_short_phase}] Goals updated based on {last_phase_name}: {self.goals}")
                else:
                    logger.warning(f"[{power_name}] LLM did not provide valid goals in state update. Current goals remain: {self.goals}")

                if extracted_relationships is not None:
                    valid_new_relationships = {}
                    invalid_count = 0
                    for p, r_status in extracted_relationships.items():
                        p_upper = str(p).upper()
                        if p_upper in ALL_POWERS and p_upper != power_name:
                            r_title = str(r_status).title() if isinstance(r_status, str) else r_status
                            if r_title in ALLOWED_RELATIONSHIPS:
                                valid_new_relationships[p_upper] = r_title
                            else:
                                invalid_count += 1
                                if invalid_count <= 2:
                                    logger.warning(f"[{power_name}] Received invalid relationship label '{r_status}' for '{p}'. Ignoring.")
                        elif p_upper != self.power_name: # Avoid logging self as invalid
                            invalid_count += 1
                            if invalid_count <= 2:
                                logger.warning(f"[{power_name}] Received relationship for invalid/own power '{p}'. Ignoring.")
                    if invalid_count > 2:
                        logger.warning(f"[{power_name}] {invalid_count} total invalid relationships were ignored.")
                    
                    if valid_new_relationships:
                        self.relationships.update(valid_new_relationships)
                        self.add_journal_entry(f"[{game.current_short_phase}] Relationships updated based on {last_phase_name}: {valid_new_relationships}")
                    elif extracted_relationships: 
                        logger.warning(f"[{power_name}] Found relationships in LLM response but none were valid after normalization. Current relationships remain: {self.relationships}")
                else:
                    logger.warning(f"[{power_name}] LLM did not provide valid relationships in state update. Current relationships remain: {self.relationships}")
            else:
                logger.warning(f"[{power_name}] State update failed: {result.error_message}")

        except FileNotFoundError:
            logger.error(f"[{power_name}] state_update_prompt.txt not found. Skipping state update.")
        except Exception as e:
            logger.error(f"[{power_name}] Error during state analysis/update for phase {game.current_short_phase}: {e}", exc_info=True)

        self.log_state(f"After State Update ({game.current_short_phase})")

    def update_goals(self, new_goals: List[str]):
        """Updates the agent's strategic goals."""
        self.goals = new_goals
        self.add_journal_entry(f"Goals updated: {self.goals}")
        logger.info(f"[{self.power_name}] Goals updated to: {self.goals}")

    def update_relationship(self, other_power: str, status: str):
        """Updates the agent's perceived relationship with another power."""
        if other_power != self.power_name:
             self.relationships[other_power] = status
             self.add_journal_entry(f"Relationship with {other_power} updated to {status}.")
             logger.info(f"[{self.power_name}] Relationship with {other_power} set to {status}.")
        else:
             logger.warning(f"[{self.power_name}] Attempted to set relationship with self.")

    def get_agent_state_summary(self) -> str:
        """Returns a string summary of the agent's current state."""
        summary = f"Agent State for {self.power_name} (Model: {self.model_id}):\n" # Added model_id
        summary += f"  Goals: {self.goals}\n"
        summary += f"  Relationships: {self.relationships}\n"
        summary += f"  Journal Entries: {len(self.private_journal)}"
        return summary

    async def generate_plan(self, game: 'Game', game_history: 'GameHistory', log_file_path: str) -> str:
        """Generates a strategic plan using the llm library and logs it."""
        logger.info(f"Agent {self.power_name} (model: {self.model_id}) generating strategic plan for phase {game.current_short_phase}...")
        
        prompt_template = llm_utils.load_prompt_file('planning_prompt.txt') # Assuming a generic planning prompt
        if not prompt_template:
            logger.error(f"[{self.power_name}] Could not load planning_prompt.txt. Cannot generate plan.")
            return "Error: Planning prompt file not found."

        board_state = game.get_state()
        possible_orders_for_context = {} # For planning, detailed orders might not be needed for context

        # Re-use build_context_prompt if it's suitable for planning context
        context_prompt_text = build_context_prompt(
            game,
            board_state,
            self.power_name,
            possible_orders_for_context, 
            game_history,
            agent_goals=self.goals,
            agent_relationships=self.relationships,
            agent_private_diary=self.format_private_diary_for_prompt(),
        )
        
        full_prompt = f"{context_prompt_text}\n\n{prompt_template}"

        # Use the new centralized LLM call wrapper (no JSON parsing expected for plans)
        result = await _global_llm_coordinator.call_llm_with_json_parsing(
            model_id=self.model_id,
            prompt=full_prompt,
            system_prompt=self.system_prompt,
            request_identifier=f"{self.power_name}-plan_generation",
            expected_json_fields=None,  # No JSON expected for planning
            game_id=self.game_id,
            agent_name=self.power_name,
            phase_str=game.current_short_phase,
            log_to_file_path=log_file_path,
            response_type="plan_generation"
        )

        if result.success and result.raw_response.strip():
            plan_text = result.raw_response.strip()
            self.add_journal_entry(f"Generated plan for phase {game.current_short_phase}:\n{plan_text[:200]}...") # Log a preview
            return plan_text
        else:
            error_msg = f"Error: Failed to generate plan for {self.power_name} - {result.error_message}"
            self.add_journal_entry(f"Failed to generate plan for phase {game.current_short_phase}: {result.error_message}")
            return error_msg

    async def generate_messages(
        self,
        game: 'Game',
        board_state: dict,
        possible_orders: Dict[str, List[str]], # For context, might not be directly used in prompt
        game_history: 'GameHistory',
        current_phase: str,
        log_file_path: str,
        active_powers: List[str],
        # agent_goals, agent_relationships, agent_private_diary_str are available via self
    ) -> List[Dict[str, str]]:
        """
        Generates messages to send to other powers during negotiations.
        """
        logger.info(f"[{self.power_name}] Generating messages for phase {current_phase}...")

        prompt_template_conversation = llm_utils.load_prompt_file('conversation_instructions.txt')
        if not prompt_template_conversation:
            logger.error(f"[{self.power_name}] Could not load conversation_instructions.txt. Cannot generate messages.")
            return []

        # Prepare context for the main prompt
        context_prompt_text = build_context_prompt(
            game=game,
            board_state=board_state,
            power_name=self.power_name,
            possible_orders=possible_orders,
            game_history=game_history,
            agent_goals=self.goals,
            agent_relationships=self.relationships,
            agent_private_diary=self.format_private_diary_for_prompt(),
        )

        # Create the full prompt
        active_powers_str = ", ".join([p for p in active_powers if p != self.power_name])
        
        negotiation_context_enhancement = (
            f"\n\n--- Negotiation Context ---\n"
            f"You are {self.power_name}.\n"
            f"Other active powers you can negotiate with: {active_powers_str}.\n"
            f"Previous messages and game state are provided above.\n"
            f"Your current goals: {self.goals}\n"
            f"Your current relationships: {self.relationships}\n"
            f"Review your private diary for reflections and plans.\n"
            f"--- End Negotiation Context ---\n\n"
        )

        full_prompt = (
            context_prompt_text +
            negotiation_context_enhancement +
            prompt_template_conversation
        )

        # Use the new centralized LLM call approach
        result = await _global_llm_coordinator.call_llm_with_json_parsing(
            model_id=self.model_id,
            prompt=full_prompt,
            system_prompt=self.system_prompt,
            request_identifier=f"{self.power_name}-message_generation",
            expected_json_fields=None,  # Messages can have various formats
            game_id=self.game_id,
            agent_name=self.power_name,
            phase_str=current_phase,
            log_to_file_path=log_file_path,
            response_type="message_generation"
        )

        extracted_messages: List[Dict[str, str]] = []

        if result.success and result.raw_response.strip():
            # Try to extract messages from the response
            parsed_data = result.parsed_json if result.parsed_json else {}
            
            if isinstance(parsed_data, dict) and "messages" in parsed_data and isinstance(parsed_data["messages"], list):
                extracted_messages = parsed_data["messages"]
            elif isinstance(parsed_data, list):
                # If LLM directly returns a list of messages
                extracted_messages = parsed_data
            else:
                logger.warning(f"[{self.power_name}] Unexpected message format in LLM response")
                
            # Validate message structure
            valid_messages = []
            for msg in extracted_messages:
                if isinstance(msg, dict) and "message_type" in msg and "content" in msg:
                    # For private messages, ensure recipient is specified
                    if msg.get("message_type") == "private" and "recipient" in msg:
                        valid_messages.append(msg)
                    elif msg.get("message_type") == "global":
                        valid_messages.append(msg)
                    else:
                        logger.warning(f"[{self.power_name}] Invalid message structure: {msg}")
                else:
                    logger.warning(f"[{self.power_name}] Invalid message format: {msg}")
            
            extracted_messages = valid_messages
            logger.info(f"[{self.power_name}] Extracted {len(extracted_messages)} valid messages.")
        else:
            logger.warning(f"[{self.power_name}] Failed to generate messages: {result.error_message}")
        
        return extracted_messages


================================================
File: agent_manager.py
================================================
import logging
import random
from typing import Optional, List, Dict, TYPE_CHECKING # Removed Set

from .agent import DiplomacyAgent # Assuming DiplomacyAgent is in agent.py
if TYPE_CHECKING:
    from .game_config import GameConfig

logger = logging.getLogger(__name__)

# Default model if not enough are specified or for remaining players
DEFAULT_AGENT_MANAGER_FALLBACK_MODEL = "gemma3:4b" # More specific name

class AgentManager:
    """
    Manages the creation, initialization, and storage of DiplomacyAgents.
    """

    def __init__(self, game_config: 'GameConfig'):
        """
        Initializes the AgentManager.

        Args:
            game_config: The game configuration object.
        """
        self.game_config = game_config
        self.agents: Dict[str, DiplomacyAgent] = {}
        logger.info("AgentManager initialized.")

    def assign_models(self, all_game_powers: List[str]) -> Dict[str, str]:
        """
        Assigns LLM model IDs to each participating power in the game.

        This method considers:
        - A specific power controlled by a specific model (from config.power_name & config.model_id).
        - A list of fixed models to be assigned to other powers (from config.fixed_models).
        - Randomization of fixed model assignments (config.randomize_fixed_models).
        - Powers to be excluded (config.exclude_powers).
        - The total number of LLM-controlled players (config.num_players).

        Args:
            all_game_powers: A list of all power names in the game (e.g., ["AUSTRIA", "ENGLAND", ...]).

        Returns:
            A dictionary mapping power names to their assigned model IDs.
        """
        logger.info("Assigning models to powers using TOML config and GameConfig overrides...")
        
        # Handle None exclude_powers by using empty list
        exclude_powers = self.game_config.exclude_powers or []
        
        # Start with TOML configurations from GameConfig
        powers_and_models: Dict[str, str] = dict(self.game_config.power_model_assignments) 
        default_model = self.game_config.default_model_from_config or DEFAULT_AGENT_MANAGER_FALLBACK_MODEL
        logger.info(f"Using default model: '{default_model}' (from TOML or AgentManager fallback)")

        # Determine powers that still need assignment (not in TOML or to be LLM controlled)
        # powers_needing_assignment_for_llm_control = [] # This variable is assigned but not used.
        # for p in all_game_powers:
        #     if p not in exclude_powers:
        #         if p not in powers_and_models: # Not specified in TOML
        #             powers_needing_assignment_for_llm_control.append(p)
                # If p is in powers_and_models, it means TOML explicitly assigned it.
                # We will respect that, unless num_players limits LLM control.

        # Override or fill in based on primary agent settings from GameConfig (CLI overrides)
        primary_agent_power = self.game_config.power_name
        primary_agent_model_cli = self.game_config.model_id # Model specified via CLI for primary agent

        if primary_agent_power and primary_agent_model_cli:
            if primary_agent_power in exclude_powers:
                logger.warning(f"Primary agent power {primary_agent_power} is excluded. Ignoring CLI model assignment.")
            else:
                logger.info(f"CLI override: Assigning primary agent {primary_agent_power} -> {primary_agent_model_cli}")
                powers_and_models[primary_agent_power] = primary_agent_model_cli
        elif primary_agent_power and primary_agent_power not in powers_and_models:
            # Primary power specified but no model via CLI, and not in TOML.
            # Assign default model to it if it's not excluded.
            if primary_agent_power not in exclude_powers:
                 logger.info(f"Primary power {primary_agent_power} specified without model, assigning default: {default_model}")
                 powers_and_models[primary_agent_power] = default_model
        
        # Fill remaining LLM slots using fixed_models from CLI or default model
        # Count how many LLM-controlled powers we have so far from TOML + primary CLI override.
        current_llm_powers = {p for p, m in powers_and_models.items() if p not in exclude_powers}
        num_llm_controlled_so_far = len(current_llm_powers)
        
        num_additional_llm_players_needed = self.game_config.num_players - num_llm_controlled_so_far

        # Consider powers from TOML that are not excluded for this calculation
        candidate_powers_for_filling_slots = [p for p in all_game_powers if p not in exclude_powers and p not in current_llm_powers]
        
        if self.game_config.randomize_fixed_models:
            random.shuffle(candidate_powers_for_filling_slots)

        fixed_models_cli_list = list(self.game_config.fixed_models) if self.game_config.fixed_models else []
        if self.game_config.randomize_fixed_models and fixed_models_cli_list:
            random.shuffle(fixed_models_cli_list)
        
        additional_llm_assigned_count = 0
        # Loop variable 'i' was not used. Replaced with '_'
        for _, power_to_assign_additional_model in enumerate(candidate_powers_for_filling_slots):
            if additional_llm_assigned_count >= num_additional_llm_players_needed:
                break
            
            if fixed_models_cli_list: # Use CLI fixed_models first for these additional slots
                model_to_assign = fixed_models_cli_list[additional_llm_assigned_count % len(fixed_models_cli_list)]
            else: # If no CLI fixed_models, use the default (from TOML or AgentManager fallback)
                model_to_assign = default_model
            
            powers_and_models[power_to_assign_additional_model] = model_to_assign
            logger.info(f"Assigned additional LLM agent: {power_to_assign_additional_model} -> {model_to_assign} (num_players target)")
            additional_llm_assigned_count += 1

        # Final filter: ensure only num_players are LLM controlled, respecting exclusions
        final_llm_assignments: Dict[str, str] = {}
        powers_considered_for_final_llm_list = [p for p in all_game_powers if p not in exclude_powers]
        
        # Prioritize powers that have specific assignments (CLI primary, then TOML)
        priority_order: List[str] = []
        if primary_agent_power and primary_agent_power in powers_and_models and primary_agent_power not in exclude_powers:
            priority_order.append(primary_agent_power)
        for p in powers_and_models.keys(): # Iterate keys from TOML based assignments
            if p not in priority_order and p not in exclude_powers:
                priority_order.append(p)
        for p in powers_considered_for_final_llm_list:
            if p not in priority_order: # Add remaining non-excluded powers
                priority_order.append(p)

        llm_slots_filled = 0
        for power_name in priority_order:
            if llm_slots_filled >= self.game_config.num_players:
                break
            if power_name in powers_and_models: # Has an assignment from TOML or CLI override or additional filling
                final_llm_assignments[power_name] = powers_and_models[power_name]
                llm_slots_filled +=1
            elif power_name not in exclude_powers: # Needs a default because it wasn't specified earlier
                final_llm_assignments[power_name] = default_model
                logger.info(f"Assigning default model '{default_model}' to {power_name} to meet num_players target.")
                llm_slots_filled +=1

        logger.info(f"Final model assignments after considering num_players ({self.game_config.num_players}): {final_llm_assignments}")
        
        # Store in game_config as well
        self.game_config.powers_and_models = final_llm_assignments
        return final_llm_assignments

    def _initialize_agent_state_ext(self, agent: DiplomacyAgent):
        """
        Initializes extended state for an agent (e.g., loading from files, specific heuristics).
        Currently, the DiplomacyAgent constructor handles basic default initialization
        of goals and relationships. This method is a placeholder for more complex setup.
        """
        # In the original lm_game.py, initial goals and relationships were largely
        # handled by the DiplomacyAgent's __init__ (e.g., relationships default to Neutral).
        # This function can be expanded if there's a need to load specific initial states
        # from files or apply more complex power-specific heuristics here.
        logger.debug(f"Performing extended state initialization for {agent.power_name} (currently minimal).")
        # Example: Load power-specific initial goals from a configuration file if it existed
        # initial_goals_config = load_goals_for_power(agent.power_name)
        # if initial_goals_config:
        #    agent.goals = initial_goals_config
        # agent.add_journal_entry("Extended state initialization complete.")
        pass


    def initialize_agents(self, powers_and_models: Dict[str, str]):
        """
        Creates and initializes DiplomacyAgent instances for each power.

        Args:
            powers_and_models: A dictionary mapping power names to their assigned model IDs.
        """
        logger.info("Initializing agents...")
        self.agents = {} # Clear any previous agents
        for power_name, model_id_for_power in powers_and_models.items():
            logger.info(f"Creating agent for {power_name} with model {model_id_for_power}")
            try:
                agent = DiplomacyAgent(
                    power_name=power_name,
                    model_id=model_id_for_power,
                    game_config=self.game_config, # Add this line
                    game_id=self.game_config.game_id  # Pass game_id to agent
                    # Initial goals and relationships are handled by DiplomacyAgent's __init__
                )
                self._initialize_agent_state_ext(agent) # Call extended initializer
                self.agents[power_name] = agent
                logger.info(f"Agent for {power_name} created and initialized.")
            except Exception as e:
                logger.error(f"Failed to create or initialize agent for {power_name} with model {model_id_for_power}: {e}", exc_info=True)
                # Decide if this is fatal or if the game can proceed without this agent
                # For now, it will skip this agent.

        # Store in game_config as well
        self.game_config.agents = self.agents
        logger.info(f"All {len(self.agents)} agents initialized.")


    def get_agent(self, power_name: str) -> Optional[DiplomacyAgent]:
        """
        Retrieves an initialized agent by its power name.

        Args:
            power_name: The name of the power whose agent is to be retrieved.

        Returns:
            The DiplomacyAgent instance, or None if not found.
        """
        return self.agents.get(power_name)



================================================
File: game_config.py
================================================
import os
import logging
import argparse
from datetime import datetime
from typing import Optional, List, Dict, TYPE_CHECKING
import toml

# Import GameHistory and DiplomacyAgent only for type hinting if they are complex
# to avoid circular dependencies at runtime.
if TYPE_CHECKING:
    from diplomacy import Game
    from .game_history import GameHistory
    from .agent import DiplomacyAgent # Assuming DiplomacyAgent is in agent.py

logger = logging.getLogger(__name__)

# Default values that might have been in parse_arguments defaults
DEFAULT_LOG_LEVEL = "INFO"
DEFAULT_GAME_ID_PREFIX = "diplomacy_game"
DEFAULT_NUM_PLAYERS = 7
DEFAULT_NUM_NEGOTIATION_ROUNDS = 3
DEFAULT_NEGOTIATION_STYLE = "simultaneous" # or "round-robin"
# DEFAULT_GAME_SERVER_URL = "ws://localhost:8080" # Unused constant

class GameConfig:
    """
    Holds game configuration derived from command-line arguments and defaults.
    Also manages derived path configurations for logging and results.
    """
    def __init__(self, args: argparse.Namespace):
        self.args = args

        self.power_name: Optional[str] = getattr(args, 'power_name', None)
        self.model_id: Optional[str] = getattr(args, 'model_id', None)
        self.num_players: int = getattr(args, 'num_players', DEFAULT_NUM_PLAYERS)
        self.game_id_prefix: str = getattr(args, 'game_id_prefix', DEFAULT_GAME_ID_PREFIX)
        self.log_level: str = getattr(args, 'log_level', DEFAULT_LOG_LEVEL).upper()
        self.perform_planning_phase: bool = getattr(args, 'perform_planning_phase', False)
        self.num_negotiation_rounds: int = getattr(args, 'num_negotiation_rounds', DEFAULT_NUM_NEGOTIATION_ROUNDS)
        self.negotiation_style: str = getattr(args, 'negotiation_style', DEFAULT_NEGOTIATION_STYLE)
        self.fixed_models: Optional[List[str]] = getattr(args, 'fixed_models', None)
        self.randomize_fixed_models: bool = getattr(args, 'randomize_fixed_models', False)
        self.exclude_powers: Optional[List[str]] = getattr(args, 'exclude_powers', None)
        self.max_years: Optional[int] = getattr(args, 'max_years', None) # Added from lm_game.py logic
        self.log_to_file: bool = getattr(args, 'log_to_file', True) # Assuming default behavior
        self.dev_mode: bool = getattr(args, 'dev_mode', False) # Added dev_mode
        self.verbose_llm_debug: bool = getattr(args, 'verbose_llm_debug', False) # New attribute
        self.max_diary_tokens: int = getattr(args, 'max_diary_tokens', 6500) # New attribute

        # --- Load Model Configuration from TOML ---
        self.models_config_path: Optional[str] = getattr(args, 'models_config_file', "models.toml")
        self.power_model_assignments: Dict[str, str] = {}
        self.default_model_from_config: Optional[str] = None
        self._load_models_config()
        # --- End Model Configuration Loading ---

        # Generate game_id if not provided
        self.current_datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.game_id: str = getattr(args, 'game_id', None)
        if not self.game_id:
            self.game_id = f"{self.game_id_prefix}_{self.current_datetime_str}"

        # Configure paths
        self.base_log_dir: str = os.path.join(os.getcwd(), "logs") # Default base log dir
        # Allow overriding base_log_dir if provided in args (e.g. from network_lm_agent)
        if getattr(args, 'log_dir', None) is not None:
            self.base_log_dir = args.log_dir
        
        # If log_dir in args was a full path for a specific game, adjust base_log_dir
        # This logic assumes log_dir from args might be game-specific or a base.
        # For lm_game.py, we usually construct the game_id_specific_log_dir from a base.
        if getattr(args, 'log_dir', None) and self.game_id in getattr(args, 'log_dir', ""):
             self.game_id_specific_log_dir = getattr(args, 'log_dir')
             self.base_log_dir = os.path.dirname(self.game_id_specific_log_dir)
        else: # Construct game_id_specific_log_dir
            self.game_id_specific_log_dir = os.path.join(self.base_log_dir, self.game_id)

        # Ensure the specific log directory for this game ID exists
        if self.log_to_file:
            os.makedirs(self.game_id_specific_log_dir, exist_ok=True)

        self.llm_log_path: str = os.path.join(self.game_id_specific_log_dir, f"{self.game_id}_llm_interactions.csv")
        self.general_log_path: str = os.path.join(self.game_id_specific_log_dir, f"{self.game_id}_general.log")
        
        self.results_dir: str = os.path.join(self.game_id_specific_log_dir, "results")
        if self.log_to_file: # Only create if logging to file, implies saving results too
            os.makedirs(self.results_dir, exist_ok=True)
            
        self.manifestos_dir: str = os.path.join(self.results_dir, "manifestos")
        if self.log_to_file:
            os.makedirs(self.manifestos_dir, exist_ok=True)

        # Initialize game state placeholders (these will be populated later)
        # Need to import these properly at runtime if used beyond type hints
        from .game_history import GameHistory # Runtime import
        self.game_history: "GameHistory" = GameHistory()
        self.game_instance: Optional["Game"] = None
        self.powers_and_models: Optional[Dict[str, str]] = None
        self.agents: Optional[Dict[str, "DiplomacyAgent"]] = None # Dict mapping power_name to DiplomacyAgent instance

        self.log_configuration()

    def log_configuration(self):
        logger.info("Game Configuration Initialized:")
        logger.info(f"  Game ID: {self.game_id}")
        logger.info(f"  Log Level: {self.log_level}")
        logger.info(f"  Number of Players (LLM-controlled): {self.num_players}")
        logger.info(f"  Log to File: {self.log_to_file}")
        if self.log_to_file:
            logger.info(f"  Base Log Directory: {self.base_log_dir}")
            logger.info(f"  Game-Specific Log Directory: {self.game_id_specific_log_dir}")
            logger.info(f"  LLM Interaction Log: {self.llm_log_path}")
            logger.info(f"  General Log File: {self.general_log_path}")
            logger.info(f"  Results Directory: {self.results_dir}")
            logger.info(f"  Manifestos Directory: {self.manifestos_dir}")
        
        if self.power_name and self.model_id:
            logger.info(f"  Single Power Mode: {self.power_name} controlled by {self.model_id}")
        
        logger.info(f"  Perform Planning Phase: {self.perform_planning_phase}")
        logger.info(f"  Number of Negotiation Rounds: {self.num_negotiation_rounds}")
        logger.info(f"  Negotiation Style: {self.negotiation_style}")
        
        if self.fixed_models:
            logger.info(f"  Fixed Models: {self.fixed_models}")
            logger.info(f"  Randomize Fixed Models: {self.randomize_fixed_models}")
        if self.exclude_powers:
            logger.info(f"  Excluded Powers: {self.exclude_powers}")
        if self.max_years:
            logger.info(f"  Maximum Game Years: {self.max_years}")
        logger.info(f"  Development Mode: {self.dev_mode}")
        logger.info(f"  Verbose LLM Debug Logging: {self.verbose_llm_debug}")
        logger.info(f"  Max Diary Tokens: {self.max_diary_tokens}")

    def _load_models_config(self):
        """Loads model assignments from the TOML configuration file."""
        if not self.models_config_path or not os.path.exists(self.models_config_path):
            logger.warning(f"Models configuration file not found at '{self.models_config_path}'. Model assignments will rely on AgentManager defaults or command-line overrides.")
            return

        try:
            config_data = toml.load(self.models_config_path)
            self.default_model_from_config = config_data.get("default_model")
            
            if self.default_model_from_config:
                logger.info(f"Loaded default model from config: {self.default_model_from_config}")

            loaded_assignments = config_data.get("powers", {})
            if isinstance(loaded_assignments, dict):
                self.power_model_assignments = {str(k).upper(): str(v) for k, v in loaded_assignments.items()}
                logger.info(f"Loaded power-specific model assignments from '{self.models_config_path}': {self.power_model_assignments}")
            else:
                logger.warning(f"'powers' section in '{self.models_config_path}' is not a valid dictionary. No power-specific models loaded from file.")

        except toml.TomlDecodeError as e:
            logger.error(f"Error decoding TOML from '{self.models_config_path}': {e}")
        except Exception as e:
            logger.error(f"Unexpected error loading models configuration from '{self.models_config_path}': {e}", exc_info=True)

# Example of how parse_arguments might look (to be kept in lm_game.py or similar entry point)
# def parse_arguments_example() -> argparse.Namespace:
#     parser = argparse.ArgumentParser(description="AI Diplomacy Game Runner")
#     parser.add_argument("--power_name", type=str, help="Name of the power to control (e.g., FRANCE).")
#     parser.add_argument("--model_id", type=str, help="Model ID for the LLM (e.g., ollama/llama3, gpt-4o).")
#     parser.add_argument("--num_players", type=int, default=DEFAULT_NUM_PLAYERS, help="Number of LLM-controlled players.")
#     # ... other arguments ...
#     return parser.parse_args()

if __name__ == '__main__':
    # This is for example usage/testing of GameConfig
    # In a real scenario, args would come from ArgumentParser in the main script.
    
    # Create a dummy argparse.Namespace for testing
    args_dict = {
        'power_name': None, # 'FRANCE',
        'model_id': None, # 'ollama/llama3',
        'num_players': 3,
        'game_id_prefix': 'test_game',
        'log_level': 'DEBUG',
        'perform_planning_phase': True,
        'num_negotiation_rounds': 2,
        'negotiation_style': 'round-robin',
        'fixed_models': ['ollama/mistral', 'ollama/llama2'],
        'randomize_fixed_models': True,
        'exclude_powers': ['ITALY'],
        'game_id': None, # To test auto-generation
        'max_years': 1,
        'log_to_file': True,
        'log_dir': None, # Test default log directory creation
        'models_config_file': None, # Test default models configuration file
        'dev_mode': True, # For testing
        'verbose_llm_debug': False, # For testing
        'max_diary_tokens': 6500 # For testing
    }
    test_args = argparse.Namespace(**args_dict)

    # Setup basic logging for the test output
    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    logger.info("--- Testing GameConfig Initialization ---")
    config = GameConfig(test_args)
    
    # Example of accessing attributes
    logger.info(f"Accessing config.game_id: {config.game_id}")
    logger.info(f"Accessing config.llm_log_path: {config.llm_log_path}")
    logger.info(f"Accessing config.game_history (should be empty GameHistory object): {config.game_history}")

    # Test with a specific log_dir (game specific)
    args_dict_log_dir = args_dict.copy()
    args_dict_log_dir['log_dir'] = os.path.join(os.getcwd(), "logs", "my_specific_game_log")
    test_args_log_dir = argparse.Namespace(**args_dict_log_dir)
    logger.info("--- Testing GameConfig with specific log_dir ---")
    config_log_dir = GameConfig(test_args_log_dir)
    logger.info(f"Accessing config_log_dir.game_id_specific_log_dir: {config_log_dir.game_id_specific_log_dir}")
    
    logger.info("--- GameConfig Test Complete ---")



================================================
File: game_history.py
================================================
from dotenv import load_dotenv
import logging
from collections import defaultdict
from dataclasses import dataclass, field
from typing import Dict, List, Optional

logger = logging.getLogger(__name__) # Changed "utils" to __name__
# Removed: logger.setLevel(logging.INFO)
# Removed: logging.basicConfig(level=logging.INFO)
load_dotenv()


@dataclass
class Message:
    sender: str
    recipient: str
    content: str


@dataclass
class Phase:
    name: str  # e.g. "SPRING 1901"
    plans: Dict[str, str] = field(default_factory=dict)
    messages: List[Message] = field(default_factory=list)
    orders_by_power: Dict[str, List[str]] = field(
        default_factory=lambda: defaultdict(list)
    )
    results_by_power: Dict[str, List[List[str]]] = field(
        default_factory=lambda: defaultdict(list)
    )
    # NEW: Store phase-end summaries provided by each power
    phase_summaries: Dict[str, str] = field(default_factory=dict)
    # NEW: Store experience/journal updates from each power for this phase
    experience_updates: Dict[str, str] = field(default_factory=dict)

    def add_plan(self, power_name: str, plan: str):
        self.plans[power_name] = plan
    
    def add_message(self, sender: str, recipient: str, content: str):
        self.messages.append(
            Message(sender=sender, recipient=recipient, content=content)
        )

    def add_orders(self, power: str, orders: List[str], results: List[List[str]]):
        self.orders_by_power[power].extend(orders)
        # Make sure results has the same length as orders, if not, pad with empty lists
        if len(results) < len(orders):
            results.extend([[] for _ in range(len(orders) - len(results))])
        self.results_by_power[power].extend(results)

    def get_global_messages(self) -> str:
        result = ""
        for msg in self.messages:
            if msg.recipient == "GLOBAL":
                result += f" {msg.sender}: {msg.content}\n"
        return result

    def get_private_messages(self, power: str) -> Dict[str, str]:
        conversations = defaultdict(str)
        for msg in self.messages:
            if msg.sender == power and msg.recipient != "GLOBAL":
                conversations[msg.recipient] += f"  {power}: {msg.content}\n"
            elif msg.recipient == power:
                conversations[msg.sender] += f"  {msg.sender}: {msg.content}\n"
        return conversations

    def get_all_orders_formatted(self) -> str:
        if not self.orders_by_power:
            return ""

        result = f"\nOrders for {self.name}:\n"
        for power, orders in self.orders_by_power.items():
            result += f"{power}:\n"
            results = self.results_by_power.get(power, [])
            for i, order in enumerate(orders):
                if i < len(results) and results[i]:
                    # Join multiple results with commas
                    result_str = f" ({', '.join(results[i])})"
                else:
                    result_str = " (successful)"
                result += f"  {order}{result_str}\n"
            result += "\n"
        return result


@dataclass
class GameHistory:
    phases: List[Phase] = field(default_factory=list)

    def add_phase(self, phase_name: str):
        # Avoid adding duplicate phases
        if not self.phases or self.phases[-1].name != phase_name:
            self.phases.append(Phase(name=phase_name))
            logger.debug(f"Added new phase: {phase_name}")
        else:
            logger.warning(f"Phase {phase_name} already exists. Not adding again.")

    def _get_phase(self, phase_name: str) -> Optional[Phase]:
        for phase in reversed(self.phases):
            if phase.name == phase_name:
                return phase
        logger.error(f"Phase {phase_name} not found in history.")
        return None

    def get_phase_by_name(self, phase_name_to_find: str) -> Optional[Phase]:
        """Finds and returns a phase by its exact name."""
        for phase in self.phases:
            if phase.name == phase_name_to_find:
                return phase
        # Optionally log if not found, or let caller handle None
        # logger.warning(f"Phase with name '{phase_name_to_find}' not found in history.")
        return None

    def add_plan(self, phase_name: str, power_name: str, plan: str):
        phase = self._get_phase(phase_name)
        if phase:
            phase.plans[power_name] = plan
            logger.debug(f"Added plan for {power_name} in {phase_name}")

    def add_message(
        self, phase_name: str, sender: str, recipient: str, message_content: str
    ):
        phase = self._get_phase(phase_name)
        if phase:
            message = Message(
                sender=sender, recipient=recipient, content=message_content
            )
            phase.messages.append(message)
            logger.debug(f"Added message from {sender} to {recipient} in {phase_name}")

    def add_orders(self, phase_name: str, power_name: str, orders: List[str]):
        phase = self._get_phase(phase_name)
        if phase:
            phase.orders_by_power[power_name].extend(orders)
            logger.debug(f"Added orders for {power_name} in {phase_name}: {orders}")

    def add_results(self, phase_name: str, power_name: str, results: List[List[str]]):
        phase = self._get_phase(phase_name)
        if phase:
            phase.results_by_power[power_name].extend(results)
            logger.debug(f"Added results for {power_name} in {phase_name}: {results}")

    # NEW: Method to add phase summary for a power
    def add_phase_summary(self, phase_name: str, power_name: str, summary: str):
        phase = self._get_phase(phase_name)
        if phase:
            phase.phase_summaries[power_name] = summary
            logger.debug(f"Added phase summary for {power_name} in {phase_name}")

    # NEW: Method to add experience update for a power
    def add_experience_update(self, phase_name: str, power_name: str, update: str):
        phase = self._get_phase(phase_name)
        if phase:
            phase.experience_updates[power_name] = update
            logger.debug(f"Added experience update for {power_name} in {phase_name}")

    def get_strategic_directives(self): 
        # returns for last phase only if exists
        if not self.phases: 
            return {}
        return self.phases[-1].plans

    # NEW METHOD
    def get_messages_this_round(self, power_name: str, current_phase_name: str) -> str:
        current_phase: Optional[Phase] = None
        for phase_obj in self.phases:
            if phase_obj.name == current_phase_name:
                current_phase = phase_obj
                break

        if not current_phase:
            return f"\n(No messages found for current phase: {current_phase_name})\n"

        messages_str = "" 

        global_msgs_content = current_phase.get_global_messages()
        if global_msgs_content:
            messages_str += "**GLOBAL MESSAGES THIS ROUND:**\n"
            messages_str += global_msgs_content
        else:
            messages_str += "**GLOBAL MESSAGES THIS ROUND:**\n (No global messages this round)\n"

        private_msgs_dict = current_phase.get_private_messages(power_name)
        if private_msgs_dict:
            messages_str += "\n**PRIVATE MESSAGES TO/FROM YOU THIS ROUND:**\n"
            for other_power, conversation_content in private_msgs_dict.items():
                messages_str += f" Conversation with {other_power}:\n"
                messages_str += conversation_content
                messages_str += "\n"
        else:
            messages_str += "\n**PRIVATE MESSAGES TO/FROM YOU THIS ROUND:**\n (No private messages this round)\n"
        
        if not global_msgs_content and not private_msgs_dict:
            return f"\n(No messages recorded for current phase: {current_phase_name})\n"

        return messages_str.strip()

    # New method to get recent messages TO a specific power
    def get_recent_messages_to_power(self, power_name: str, limit: int = 3) -> List[Dict[str, str]]:
        """
        Gets the most recent messages sent TO this power, useful for tracking messages that need replies.
        Returns a list of dictionaries with 'sender', 'content', and 'phase' keys.
        """
        if not self.phases:
            return []
            
        # Get the most recent 2 phases including current phase
        recent_phases = self.phases[-2:] if len(self.phases) >= 2 else self.phases[-1:]
        
        # Collect all messages sent TO this power
        messages_to_power = []
        for phase in recent_phases:
            for msg in phase.messages:
                # Personal messages to this power or global messages from others
                if msg.recipient == power_name or (msg.recipient == "GLOBAL" and msg.sender != power_name):
                    # Skip if sender is this power (don't need to respond to own messages)
                    if msg.sender != power_name:
                        messages_to_power.append({
                            'sender': msg.sender,
                            'content': msg.content,
                            'phase': phase.name
                        })
        
        # Removed comment: # Add debug logging
        logger.debug(f"Found {len(messages_to_power)} messages to {power_name} across {len(recent_phases)} phases") # Changed to DEBUG
        if not messages_to_power:
            logger.debug(f"No messages found for {power_name} to respond to") # Changed to DEBUG
        
        # Take the most recent 'limit' messages
        return messages_to_power[-limit:] if messages_to_power else []
    
    def get_ignored_messages_by_power(self, sender_name: str, num_phases: int = 3) -> Dict[str, List[Dict[str, str]]]:
        """
        Identifies which powers are not responding to messages from sender_name.
        Returns a dict mapping power names to their ignored messages.
        
        A message is considered ignored if:
        1. It was sent from sender_name to another power (private)
        2. No response from that power was received in the same or next phase
        """
        ignored_by_power = {}
        
        # Get recent phases
        recent_phases = self.phases[-num_phases:] if self.phases else []
        if not recent_phases:
            return ignored_by_power
        
        for i, phase in enumerate(recent_phases):
            # Get messages sent by sender to specific powers (not global)
            sender_messages = []
            for msg in phase.messages:
                # Handle both Message objects and dict objects
                if isinstance(msg, Message):
                    if msg.sender == sender_name and msg.recipient not in ['GLOBAL', 'ALL']:
                        sender_messages.append(msg)
                else:  # Assume dict
                    if msg['sender'] == sender_name and msg['recipient'] not in ['GLOBAL', 'ALL']:
                        sender_messages.append(msg)
            
            # Check for responses in this and next phases
            for msg in sender_messages:
                # Handle both Message objects and dict objects
                if isinstance(msg, Message):
                    recipient = msg.recipient
                    msg_content = msg.content
                else:
                    recipient = msg['recipient']
                    msg_content = msg['content']
                
                # Look for responses in current phase and next phases
                found_response = False
                
                # Check remaining phases starting from current
                for check_phase in recent_phases[i:min(i+2, len(recent_phases))]:
                    # Look for messages FROM the recipient TO the sender (direct response)
                    # or FROM the recipient to GLOBAL/ALL that might acknowledge sender
                    response_msgs = []
                    for m in check_phase.messages:
                        if isinstance(m, Message):
                            if m.sender == recipient and (m.recipient == sender_name or 
                               (m.recipient in ['GLOBAL', 'ALL'] and sender_name in m.content)):
                                response_msgs.append(m)
                        else:  # Assume dict
                            if m['sender'] == recipient and (m['recipient'] == sender_name or 
                               (m['recipient'] in ['GLOBAL', 'ALL'] and sender_name in m.get('content', ''))):
                                response_msgs.append(m)
                    
                    if response_msgs:
                        found_response = True
                        break
                
                if not found_response:
                    if recipient not in ignored_by_power:
                        ignored_by_power[recipient] = []
                    ignored_by_power[recipient].append({
                        'phase': phase.name,
                        'content': msg_content
                    })
        
        return ignored_by_power
    
    # MODIFIED METHOD (renamed from get_game_history)
    def get_previous_phases_history(
        self, power_name: str, current_phase_name: str, include_plans: bool = True, num_prev_phases: int = 5
    ) -> str:
        if not self.phases:
            return "\n(No game history available)\n"

        relevant_phases = [p for p in self.phases if p.name != current_phase_name]

        if not relevant_phases:
            return "\n(No previous game history before this round)\n"

        phases_to_report = relevant_phases[-num_prev_phases:]

        if not phases_to_report:
            return "\n(No previous game history available within the lookback window)\n"
        
        game_history_str = ""

        for phase_idx, phase in enumerate(phases_to_report):
            phase_content_str = f"\nPHASE: {phase.name}\n"
            current_phase_has_content = False

            global_msgs = phase.get_global_messages()
            if global_msgs:
                phase_content_str += "\n  GLOBAL MESSAGES:\n"
                phase_content_str += "".join([f"    {line}\n" for line in global_msgs.strip().split('\n')])
                current_phase_has_content = True

            private_msgs = phase.get_private_messages(power_name)
            if private_msgs:
                phase_content_str += "\n  PRIVATE MESSAGES:\n"
                for other_power, messages in private_msgs.items():
                    phase_content_str += f"    Conversation with {other_power}:\n"
                    phase_content_str += "".join([f"      {line}\n" for line in messages.strip().split('\n')])
                current_phase_has_content = True

            if phase.orders_by_power:
                phase_content_str += "\n  ORDERS:\n"
                for power, orders in phase.orders_by_power.items():
                    indicator = " (your power)" if power == power_name else ""
                    phase_content_str += f"    {power}{indicator}:\n"
                    results = phase.results_by_power.get(power, [])
                    for i, order in enumerate(orders):
                        result_str = " (successful)"
                        if i < len(results) and results[i] and not all(r == "" for r in results[i]):
                            result_str = f" ({', '.join(results[i])})"
                        phase_content_str += f"      {order}{result_str}\n"
                    phase_content_str += "\n"
                current_phase_has_content = True
            
            if current_phase_has_content:
                if not game_history_str:
                    game_history_str = "**PREVIOUS GAME HISTORY (Messages, Orders, & Plans from older rounds & phases)**\n"
                game_history_str += phase_content_str
                if phase_idx < len(phases_to_report) -1 :
                    game_history_str += "  " + "-" * 48 + "\n"

        if include_plans and phases_to_report:
            last_reported_previous_phase = phases_to_report[-1]
            if last_reported_previous_phase.plans:
                if not game_history_str:
                    game_history_str = "**PREVIOUS GAME HISTORY (Messages, Orders, & Plans from older rounds & phases)**\n"
                game_history_str += f"\n  PLANS SUBMITTED FOR PHASE {last_reported_previous_phase.name}:\n"
                if power_name in last_reported_previous_phase.plans:
                    game_history_str += f"    Your Plan: {last_reported_previous_phase.plans[power_name]}\n"
                for p_other, plan_other in last_reported_previous_phase.plans.items():
                    if p_other != power_name:
                        game_history_str += f"    {p_other}'s Plan: {plan_other}\n"
                game_history_str += "\n"

        if not game_history_str.replace("**PREVIOUS GAME HISTORY (Messages, Orders, & Plans from older rounds & phases)**\n", "").strip():
            return "\n(No relevant previous game history to display)\n"

        return game_history_str.strip()

    def get_messages_by_phase(self, phase_name: str) -> List[dict]:
        """Return all messages for a given phase as a list of dicts."""
        phase = self.get_phase_by_name(phase_name)
        if not phase:
            logger.error(f"Phase {phase_name} not found in history.")
            return []
        return [
            {"sender": m.sender, "recipient": m.recipient, "content": m.content}
            for m in phase.messages
        ]

    def to_dict(self) -> dict:
        """Convert GameHistory to a dictionary for JSON serialization."""
        return {
            "phases": [
                {
                    "name": phase.name,
                    "plans": dict(phase.plans),
                    "messages": [
                        {
                            "sender": msg.sender,
                            "recipient": msg.recipient,
                            "content": msg.content
                        }
                        for msg in phase.messages
                    ],
                    "orders_by_power": {
                        power: list(orders) 
                        for power, orders in phase.orders_by_power.items()
                    },
                    "results_by_power": {
                        power: list(results) 
                        for power, results in phase.results_by_power.items()
                    },
                    "phase_summaries": dict(phase.phase_summaries),
                    "experience_updates": dict(phase.experience_updates)
                }
                for phase in self.phases
            ]
        }



================================================
File: game_orchestrator.py
================================================
import logging
import asyncio
# Removed: import random
from typing import Optional, List, Dict, Callable, Coroutine, TYPE_CHECKING, Any # Removed Set
from enum import Enum

from diplomacy import Game  # Removed Phase import
# Removed: from diplomacy.utils.export import to_saved_game_format

# Add a local Enum for phase types
class PhaseType(Enum):
    MVT = "M"
    RET = "R"
    BLD = "A"

if TYPE_CHECKING:
    from .game_config import GameConfig
    from .agent_manager import AgentManager
    from .game_history import GameHistory # Removed Message as GameHistoryMessage
    from .agent import DiplomacyAgent


logger = logging.getLogger(__name__)

# Define a type for the get_valid_orders function that will be passed
GetValidOrdersFuncType = Callable[['Game', str, 'AgentLLMInterface', 'GameHistory', 'GameConfig', int], Coroutine[Any, Any, List[str]]]


class GamePhaseOrchestrator:
    """
    Orchestrates the main game loop, including phase transitions, agent actions,
    negotiations, order submissions, and game processing.
    """

    @staticmethod
    def get_phase_type_from_game(game: 'Game') -> str:
        """Extracts the phase type character from the current phase string (e.g., 'M', 'R', 'A')."""
        phase = game.get_current_phase()
        if not phase or phase in ("FORMING", "COMPLETED"):
            return "-"
        return phase[-1]

    def __init__(
        self, 
        game_config: 'GameConfig', 
        agent_manager: 'AgentManager', 
        # Removed: phase_summary_generator: 'PhaseSummaryGenerator',
        get_valid_orders_func: GetValidOrdersFuncType # Passed from lm_game.py
    ):
        self.config = game_config
        self.agent_manager = agent_manager
        # Removed: self.phase_summary_generator = phase_summary_generator
        self.get_valid_orders_func = get_valid_orders_func
        self.active_powers: List[str] = [] # Powers actively playing (not eliminated, not excluded)
        
        if self.config.powers_and_models: # Should be set by AgentManager.assign_models_to_powers
            self.active_powers = list(self.config.powers_and_models.keys())
        else:
            logger.warning("GameConfig.powers_and_models not set when GamePhaseOrchestrator is initialized. Active powers list will be empty initially.")

    def _extract_year_from_phase(self, phase_name: str) -> Optional[int]:
        """Extracts the year as int from a phase string like 'S1901M' or 'SPRING 1901 MOVEMENT'."""
        # Try short format: S1901M, F1902R, etc.
        if phase_name and len(phase_name) >= 5 and phase_name[1:5].isdigit():
            return int(phase_name[1:5])
        # Try long format: SPRING 1901 MOVEMENT
        parts = phase_name.split()
        if len(parts) >= 2 and parts[1].isdigit():
            return int(parts[1])
        return None

    async def run_game_loop(self, game: 'Game', game_history: 'GameHistory'):
        """
        Main game loop iterating through years and phases.
        """
        logger.info(f"Starting game loop for game ID: {self.config.game_id}")
        self.config.game_instance = game # Store game instance in config for access by other components

        try:
            while True:
                current_phase_val = getattr(game, 'phase', "Unknown")
                # Extract year safely
                current_year = getattr(game, 'year', None)
                if current_year is None:
                    current_year = self._extract_year_from_phase(current_phase_val)

                # Check for max_years condition
                if self.config.max_years and current_year is not None and current_year >= self.config.max_years:
                    logger.info(f"Reached max_year {self.config.max_years}. Ending game.")
                    # Properly mark the game as completed
                    try:
                        game.draw()  # This sets status to COMPLETED and marks game as done
                        logger.info("Game marked as completed via draw.")
                    except Exception as e:
                        logger.warning(f"Could not call game.draw(): {e}. Setting status manually.")
                        if hasattr(game, 'set_status'):
                            game.set_status('COMPLETED')
                        if hasattr(game, 'phase'):
                            game.phase = 'COMPLETED'
                    break

                if game.is_game_done:
                    logger.info("Game is done. Exiting game loop.")
                    break

                logger.info(f"--- Current Phase: {current_phase_val} ---")
                game_history.add_phase(current_phase_val)

                # Update active powers based on game state (e.g. eliminated powers)
                self.active_powers = [
                    p for p in game.powers if p in self.config.powers_and_models and not game.powers[p].is_eliminated()
                ]
                if not self.active_powers:
                    logger.info("No active LLM-controlled powers remaining. Ending game.")
                    break
                logger.info(f"Active LLM-controlled powers for this phase: {self.active_powers}")

                all_orders_for_phase: Dict[str, List[str]] = {}

                phase_type = self.get_phase_type_from_game(game)
                if phase_type == PhaseType.MVT.value:
                    all_orders_for_phase = await self._execute_movement_phase_actions(game, game_history)
                elif phase_type == PhaseType.RET.value:
                    all_orders_for_phase = await self._execute_retreat_phase_actions(game, game_history)
                elif phase_type == PhaseType.BLD.value:
                    all_orders_for_phase = await self._execute_build_phase_actions(game, game_history)
                else:
                    logger.error(f"Unknown phase type: {game.get_phase_type()}. Skipping.")
                    game.process() # Process to advance the phase
                    continue 

                await self._process_phase_results_and_updates(game, game_history, all_orders_for_phase, current_phase_val)

                # Check for max years condition
                # Use safe year extraction again
                current_year = getattr(game, 'year', None)
                if current_year is None:
                    current_year = self._extract_year_from_phase(current_phase_val)
                if self.config.max_years and current_year is not None and current_year >= self.config.max_years:
                    current_phase_type = self.get_phase_type_from_game(game)
                    if (current_phase_type == PhaseType.BLD.value and "WINTER" in current_phase_val.upper()) or \
                       ("WINTER" in current_phase_val.upper() and game.is_game_done):
                        logger.info(f"Reached max_years ({self.config.max_years}). Ending game after {current_phase_val}.")
                        # Properly mark the game as completed
                        try:
                            game.draw()  # This sets status to COMPLETED and marks game as done
                            logger.info("Game marked as completed via draw.")
                        except Exception as e:
                            logger.warning(f"Could not call game.draw(): {e}. Setting status manually.")
                            if hasattr(game, 'set_status'):
                                game.set_status('COMPLETED')
                            if hasattr(game, 'phase'):
                                game.phase = 'COMPLETED'
                        break
            logger.info(f"Game {self.config.game_id} finished. Final phase: {game.get_current_phase()}")
        except AttributeError as e:
            logger.error(f"AttributeError in game loop: {e}. This might indicate an issue with the game object's structure.", exc_info=True)
        except Exception as e:
            logger.error(f"An unexpected error occurred during the game loop: {e}", exc_info=True)
        finally:
            logger.info("Game loop finished or interrupted. Processing final results...")

    async def _execute_movement_phase_actions(self, game: 'Game', game_history: 'GameHistory') -> Dict[str, List[str]]:
        logger.info("Executing Movement Phase actions...")
        current_phase_name = game.get_current_phase()

        if self.config.perform_planning_phase:
            await self._perform_planning_phase(game, game_history)

        await self._perform_negotiation_rounds(game, game_history)

        orders_by_power: Dict[str, List[str]] = {}

        # SERIALIZE order generation instead of running concurrently
        for power_name in self.active_powers:
            agent = self.agent_manager.get_agent(power_name)
            if agent:
                logger.debug(f"Generating orders for {power_name}...") # INFO to DEBUG
                try:
                    orders = await self._get_orders_for_power(game, power_name, agent, game_history) # Removed self.config.num_negotiation_rounds as it's unused
                    orders_by_power[power_name] = orders
                    logger.debug(f"✅ {power_name}: Generated {len(orders)} orders") # INFO to DEBUG
                except Exception as e:
                    logger.error(f"❌ Error getting orders for {power_name}: {e}", exc_info=e)
                    orders_by_power[power_name] = [] # Submit no orders on error
            else: # Should not happen if active_powers is derived from agent_manager.agents
                logger.warning(f"No agent found for active power {power_name} during order generation.")
                orders_by_power[power_name] = [] # Submit no orders
            
            game_history.add_orders(current_phase_name, power_name, orders_by_power[power_name])
            
            # Generate order diary entry
            if agent: # Agent should exist if orders were successfully generated
                try:
                    await agent.generate_order_diary_entry(game, orders_by_power[power_name], self.config.llm_log_path)
                    logger.debug(f"✅ {power_name}: Generated order diary entry") # INFO to DEBUG
                except Exception as e:
                    logger.error(f"❌ Error generating order diary for {power_name}: {e}", exc_info=e)
        
        return orders_by_power

    async def _execute_retreat_phase_actions(self, game: 'Game', game_history: 'GameHistory') -> Dict[str, List[str]]:
        logger.info("Executing Retreat Phase actions...")
        current_phase_name = game.get_current_phase()
        orders_by_power: Dict[str, List[str]] = {}
        order_tasks = []

        for power_name in self.active_powers:
            # Retreats are often simpler, no extensive negotiation typically.
            # Check if the power actually has units that need to retreat.
            if not game.powers[power_name].must_retreat:
                logger.info(f"Power {power_name} has no units that must retreat.")
                orders_by_power[power_name] = []
                continue

            agent = self.agent_manager.get_agent(power_name)
            if agent:
                 order_tasks.append(
                    self._get_orders_for_power(game, power_name, agent, game_history, 0) # num_negotiation_rounds = 0
                )
            else:
                logger.warning(f"No agent found for active power {power_name} during retreat order generation.")
                orders_by_power[power_name] = []
        
        results = await asyncio.gather(*order_tasks, return_exceptions=True)
        active_powers_with_retreats = [p for p in self.active_powers if game.powers[p].must_retreat]

        for i, power_name in enumerate(active_powers_with_retreats):
            if isinstance(results[i], Exception):
                logger.error(f"Error getting retreat orders for {power_name}: {results[i]}", exc_info=results[i])
                orders_by_power[power_name] = []
            else:
                orders_by_power[power_name] = results[i]
            game_history.add_orders(current_phase_name, power_name, orders_by_power[power_name])
            # Order diary for retreats (optional, could be simpler)
            agent = self.agent_manager.get_agent(power_name)
            if agent:
                 await agent.generate_order_diary_entry(game, orders_by_power[power_name], self.config.llm_log_path)

        return orders_by_power

    async def _execute_build_phase_actions(self, game: 'Game', game_history: 'GameHistory') -> Dict[str, List[str]]:
        logger.info("Executing Build Phase actions...")
        current_phase_name = game.get_current_phase()
        orders_by_power: Dict[str, List[str]] = {}
        order_tasks = []

        for power_name in self.active_powers:
            # Builds are also simpler, usually no negotiation.
            # Check if power can build/disband
            if game.powers[power_name].n_builds == 0:
                logger.info(f"Power {power_name} has no builds or disbands.")
                orders_by_power[power_name] = []
                continue

            agent = self.agent_manager.get_agent(power_name)
            if agent:
                order_tasks.append(
                    self._get_orders_for_power(game, power_name, agent, game_history, 0) # num_negotiation_rounds = 0
                )
            else:
                logger.warning(f"No agent found for active power {power_name} during build order generation.")
                orders_by_power[power_name] = []

        results = await asyncio.gather(*order_tasks, return_exceptions=True)
        active_powers_with_builds = [p for p in self.active_powers if game.powers[p].n_builds != 0]

        for i, power_name in enumerate(active_powers_with_builds):
            if isinstance(results[i], Exception):
                logger.error(f"Error getting build orders for {power_name}: {results[i]}", exc_info=results[i])
                orders_by_power[power_name] = []
            else:
                orders_by_power[power_name] = results[i]
            game_history.add_orders(current_phase_name, power_name, orders_by_power[power_name])
            # Order diary for builds
            agent = self.agent_manager.get_agent(power_name)
            if agent:
                await agent.generate_order_diary_entry(game, orders_by_power[power_name], self.config.llm_log_path)
        
        return orders_by_power

    async def _get_orders_for_power(
        self, game: 'Game', power_name: str, agent: 'DiplomacyAgent', game_history: 'GameHistory' # Removed num_negotiation_rounds
    ) -> List[str]:
        """Helper to call the passed get_valid_orders_func."""
        # The get_valid_orders_func is expected to be the function from lm_game.py (or its refactored equivalent)
        # The parameter num_negotiation_rounds was not used in this function.
        # Its signature is: async def get_valid_orders(game, model_id, agent_system_prompt, board_state, power_name, possible_orders, game_history, model_error_stats, agent_goals, agent_relationships, agent_private_diary_str, log_file_path, phase)
        model_error_stats: dict = {}
        board_state = game.get_state()
        possible_orders = agent.llm_interface.coordinator.gather_possible_orders(game, power_name) if hasattr(agent.llm_interface.coordinator, 'gather_possible_orders') else game.get_all_possible_orders()
        return await self.get_valid_orders_func(
            game,
            agent.model_id,
            agent.system_prompt,
            board_state,
            power_name,
            possible_orders,
            game_history,
            model_error_stats,
            agent.goals,
            agent.relationships,
            agent.format_private_diary_for_prompt(),
            self.config.llm_log_path,
            game.get_current_phase(),
        )

    async def _process_phase_results_and_updates(
        self, game: 'Game', game_history: 'GameHistory', all_orders_for_phase: Dict[str, List[str]], processed_phase_name: str
    ):
        logger.info(f"Processing results for phase: {processed_phase_name}")
        
        # Submit orders to the game engine
        for power_name, orders in all_orders_for_phase.items():
            if power_name in self.active_powers: # Only submit for active LLM powers
                game.set_orders(power_name, orders)
            elif not orders and power_name in game.powers and not game.powers[power_name].is_eliminated():
                 # If a power (human or other AI) has no orders, submit empty list to avoid issues
                 # Only do this if the power is actually in the game and not eliminated.
                 # LLM agents should have submitted empty list if they had no orders.
                 game.set_orders(power_name, [])


        # Process the game phase
        game.process()
        logger.info(f"Game processed. New phase: {game.get_current_phase()}")

        # Log results to game_history
        # Assuming results are available in game.get_results() after process()
        # game.get_results() returns List[Tuple[power, List[order_result_str]]]
        # This needs to be mapped correctly to game_history.add_results
        # For now, let's assume add_results can take this or it's handled by an adapter.
        # The original lm_game.py did:
        # for power_name_iter, power_orders in all_orders.items():
        #     order_results = [game.get_order_resolution(order) for order in power_orders]
        #     game_history.add_results(processed_phase_name, power_name_iter, order_results)
        
        for power_name_iter, power_orders_submitted in all_orders_for_phase.items():
            if power_name_iter in game.powers: # Ensure power is still valid
                order_results_for_power = []
                for order_str in power_orders_submitted:
                    # game.get_order_resolution might not exist or work this way with all game objects.
                    # A more robust way is to iterate through game.results if available
                    # or parse from the overall game state if necessary.
                    # For now, assuming a simplified approach or that results are part of game object structure.
                    # This part is tricky without knowing the exact diplomacy library's state post-process().
                    # Let's assume a placeholder or that this info is implicitly handled by phase summary.
                    # The crucial part is that game.process() was called.
                    # The original `game.get_order_resolution(order)` seems to be from a specific example.
                    # Standard library usually gives all results together.
                    # Let's assume we can get results broadly.
                    # For now, we'll skip detailed result logging here if it's too complex,
                    # relying on the phase summary to capture outcomes.
                    # A simple way:
                    # if order_str in game.successful_orders: result = ["successful"] else: result = ["failed/unknown"]
                    # This is highly dependent on diplomacy library version.
                    # The example from original code:
                    try:
                        # This is a bit of a guess, depends on how game object stores results
                        # This might be specific to certain versions or custom game objects.
                        # A common pattern is game.results which gives all results.
                        # For now, let's assume a simplified result representation.
                        # This part of history logging might need to be adapted based on actual game object.
                        # results_for_order = game.get_order_resolution(order_str) # This method is not standard
                        results_for_order = ["Result N/A"] # Placeholder
                    except Exception:
                        results_for_order = ["Error fetching result"]
                    order_results_for_power.append(results_for_order)
                
                game_history.add_results(processed_phase_name, power_name_iter, order_results_for_power)


        # Phase summary from an "observer" perspective (textual summary of events)
        # This was phase_summary_text in lm_game.py, derived from game.get_phase_history_log()
        # We need to ensure such a log or summary is available from the game object.
        # For now, let's assume game.get_state() or similar can give us enough.
        # This is a placeholder for a more robust phase event summary.
        phase_events_summary_text = f"Summary of events for {processed_phase_name}: All orders processed. New SCs: {game.get_state()['centers']}"
        # A better summary would come from game.get_phase_history_log() if available and formatted.

        # SERIALIZE summary generation instead of running concurrently
        for power_name in self.active_powers:
            agent = self.agent_manager.get_agent(power_name)
            if agent:
                logger.debug(f"Generating phase summary for {power_name}...") # INFO to DEBUG
                try:
                    # Re-instantiate PhaseSummaryGenerator with the current agent's interface
                    # This is not ideal. PhaseSummaryGenerator should ideally take llm_interface in its method.
                    # Or orchestrator has a way to get a summary_generator for a specific agent.
                    # For now, let's follow the current PhaseSummaryGenerator structure.
                    # This implies the passed phase_summary_generator is generic or for a specific agent.
                    # The plan states "phase_summary_generator: PhaseSummaryGenerator" is passed to __init__ - this param was removed.
                    # This is problematic if it's tied to one agent's interface.
                    # Let's assume the passed phase_summary_generator can handle different powers,
                    # perhaps by taking the agent's llm_interface as an argument to its method.
                    #
                    # Revisiting PhaseSummaryGenerator: it's init with ONE llm_interface.
                    # This means the orchestrator would need a dict of these, or create them on the fly.
                    # The latter is more flexible.
                    # The attribute agent.llm_interface was removed. This line will cause an error.
                    # This needs to be fixed by passing the necessary parts of the agent (model_id, system_prompt, coordinator)
                    # or by refactoring PhaseSummaryGenerator further.
                    # For this linting pass, I will comment out the problematic line, noting it as a bug.
                    # current_agent_summary_generator = PhaseSummaryGenerator(agent.llm_interface, self.config) # BUG: agent.llm_interface removed

                    # await current_agent_summary_generator.generate_and_record_phase_summary(
                    #     game, game_history, processed_phase_name, phase_events_summary_text, all_orders_for_phase
                    # )
                    logger.debug(f"✅ {power_name}: Generated phase summary (actual call commented out due to agent.llm_interface removal)") # INFO to DEBUG
                except Exception as e:
                    logger.error(f"❌ Error generating phase summary for {power_name}: {e}", exc_info=e)

        # SERIALIZE agent state updates instead of running concurrently
        for power_name in self.active_powers:
            agent = self.agent_manager.get_agent(power_name)
            if agent:
                logger.debug(f"Updating state for {power_name}...") # INFO to DEBUG
                try:
                    # The phase_summary here is the "observer" summary, not agent's generated one.
                    await agent.analyze_phase_and_update_state(
                        game, game.get_state(), phase_events_summary_text, game_history, self.config.llm_log_path
                    )
                    logger.debug(f"✅ {power_name}: Updated state") # INFO to DEBUG
                except Exception as e:
                    logger.error(f"❌ Error updating state for {power_name}: {e}", exc_info=e)

        # Consolidate old diary entries (e.g., if a year is 2+ years in the past)
        current_phase = game.get_current_phase()
        current_year = None
        if current_phase and len(current_phase) >= 5 and current_phase[1:5].isdigit():
            current_year = int(current_phase[1:5])
        if current_year is not None and current_year > 1902:
            year_to_consolidate = str(current_year - 2)
            logger.info(f"Checking for diary consolidation for year {year_to_consolidate}.")
            
            # SERIALIZE diary consolidation instead of running concurrently
            for power_name in self.active_powers:
                agent = self.agent_manager.get_agent(power_name)
                if agent:
                    logger.debug(f"Consolidating diary for {power_name} (year {year_to_consolidate})...") # INFO to DEBUG
                    try:
                        await agent.consolidate_year_diary_entries(year_to_consolidate, game, self.config.llm_log_path)
                        logger.debug(f"✅ {power_name}: Consolidated diary entries") # INFO to DEBUG
                    except Exception as e:
                        logger.error(f"❌ Error consolidating diary for {power_name}: {e}", exc_info=e)


    async def _perform_planning_phase(self, game: 'Game', game_history: 'GameHistory'):
        logger.info("Performing planning phase...")
        
        # SERIALIZE planning instead of running concurrently
        for power_name in self.active_powers:
            agent = self.agent_manager.get_agent(power_name)
            if agent:
                logger.debug(f"Generating plan for {power_name}...") # INFO to DEBUG
                try:
                    plan = await agent.generate_plan(game, game_history, self.config.llm_log_path)
                    game_history.add_plan(game.get_current_phase(), agent.power_name, plan)
                    logger.debug(f"✅ {power_name}: Generated plan - {plan[:100]}...") # INFO to DEBUG
                except Exception as e:
                    logger.error(f"❌ Error generating plan for {power_name}: {e}", exc_info=e)

    async def _perform_negotiation_rounds(self, game: 'Game', game_history: 'GameHistory'):
        current_phase_name = game.get_current_phase()
        logger.info(f"Performing negotiation rounds for phase: {current_phase_name}")

        # Enforce at least 1 negotiation round
        num_rounds = max(1, getattr(self.config, 'num_negotiation_rounds', 1))

        for round_num in range(1, num_rounds + 1):
            logger.info(f"Negotiation Round {round_num}/{num_rounds}")
            
            all_proposed_messages: Dict[str, List[Dict[str, str]]] = {} # power_name -> list of message dicts

            for power_name in self.active_powers:
                agent = self.agent_manager.get_agent(power_name)
                if agent:
                    logger.debug(f"[Negotiation] Starting message generation for {power_name} (round {round_num})...") # INFO to DEBUG
                    try:
                        board_state = game.get_state() 
                        possible_orders_for_negotiation = {}
                        # Add a timeout to prevent infinite waits
                        import asyncio
                        messages = await asyncio.wait_for(
                            agent.generate_messages(
                                game=game, 
                                board_state=board_state, 
                                possible_orders=possible_orders_for_negotiation,
                                game_history=game_history,
                                current_phase=current_phase_name,
                                log_file_path=self.config.llm_log_path,
                                active_powers=[p for p in self.active_powers if p != power_name]
                            ),
                            timeout=60.0
                        )
                        all_proposed_messages[power_name] = messages
                        logger.debug(f"✅ {power_name}: Generated {len(messages)} messages (round {round_num})") # INFO to DEBUG
                    except asyncio.TimeoutError:
                        logger.error(f"❌ Timeout generating messages for {power_name} (round {round_num})")
                        all_proposed_messages[power_name] = []
                    except Exception as e:
                        logger.error(f"❌ Error generating messages for {power_name}: {e}", exc_info=e)
                        all_proposed_messages[power_name] = []
                else:
                    all_proposed_messages[power_name] = []

            # Distribute messages for this round (add to game_history)
            for sender_power, messages_to_send in all_proposed_messages.items():
                for msg_dict in messages_to_send:
                    recipient = msg_dict.get("recipient", "GLOBAL").upper()
                    content = msg_dict.get("content", "")
                    if recipient != "GLOBAL" and recipient not in self.active_powers:
                        logger.warning(f"[{sender_power}] Tried to send message to invalid/inactive recipient '{recipient}'. Skipping.")
                        continue
                    game_history.add_message(current_phase_name, sender_power, recipient, content)
                    logger.debug(f"Message from {sender_power} to {recipient}: {content[:75]}...") # INFO to DEBUG

            # After messages are "sent" (recorded), agents generate negotiation diary entries
            for power_name in self.active_powers:
                agent = self.agent_manager.get_agent(power_name)
                if agent:
                    try:
                        await asyncio.wait_for(
                            agent.generate_negotiation_diary_entry(game, game_history, self.config.llm_log_path),
                            timeout=60.0
                        )
                        logger.debug(f"✅ {power_name}: Generated negotiation diary entry (round {round_num})") # INFO to DEBUG
                    except asyncio.TimeoutError:
                        logger.error(f"❌ Timeout generating diary entry for {power_name} (round {round_num})")
                    except Exception as e:
                        logger.error(f"❌ Error generating diary entry for {power_name}: {e}", exc_info=e)

            if round_num < num_rounds:
                logger.info(f"End of Negotiation Round {round_num}. Next round starting...")
            else:
                logger.info(f"Final Negotiation Round {round_num} completed.")

if __name__ == '__main__':
    # This is for example usage/testing of GamePhaseOrchestrator
    # Requires mocked or dummy versions of dependencies.
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logger.info("GamePhaseOrchestrator example run (conceptual).")
    # To run this, you'd need to set up mock GameConfig, AgentManager, PhaseSummaryGenerator,
    # a mock Game object, GameHistory, and a mock get_valid_orders_func.
    # Due to complexity, a full runnable example here is extensive.
    # Key aspects to test would be:
    # - Game loop progression through phases.
    # - Correct delegation to phase action methods.
    # - Proper handling of agent plans, negotiations, orders.
    # - Phase result processing and state updates.
    # - Adherence to max_years.
    # - Graceful handling of errors from agent actions.
    print("To test GamePhaseOrchestrator, integrate with other mock/real components.")



================================================
File: game_results.py
================================================
import logging
import os
import json
from typing import Dict, TYPE_CHECKING

# Import usage tracking functions
from .llm_coordinator import get_usage_stats_by_country, get_total_usage_stats

# Use try-except for diplomacy import for environments where it might not be immediately available
# or to handle different import styles if necessary, though direct import is usually fine.
try:
    from diplomacy import Game
    from diplomacy.utils.export import to_saved_game_format
except ImportError:
    logging.error("Diplomacy library not found. GameResultsProcessor might not function correctly for 'Game' objects.")
    # Define Game as a placeholder if not found, to allow type hinting to work somewhat
    if 'Game' not in globals(): # Check if already defined by a previous attempt or TYPE_CHECKING block
        Game = type('Game', (object,), {})


if TYPE_CHECKING:
    from .game_config import GameConfig
    from .game_history import GameHistory # Assuming GameHistory can be pickled or has a to_dict method
    from .agent import DiplomacyAgent

logger = logging.getLogger(__name__)

class GameResultsProcessor:
    """
    Handles the saving of game results, including final game state,
    game history, and agent manifestos.
    """

    def __init__(self, game_config: 'GameConfig'):
        """
        Initializes the GameResultsProcessor.

        Args:
            game_config: The game configuration object, providing paths for saving results.
        """
        self.config = game_config
        logger.info("GameResultsProcessor initialized.")

    def save_game_state(self, game_instance: 'Game', game_history: 'GameHistory'):
        """
        Saves the final game state and the detailed game history.

        Args:
            game_instance: The final diplomacy.Game object.
            game_history: The GameHistory object containing records of all phases.
        """
        if not self.config.log_to_file:
            logger.info("File logging disabled, skipping saving game state and history.")
            return

        # 1. Save the final game state (e.g., .json, .svg)
        try:
            # Ensure results_dir exists (GameConfig should create it, but double-check)
            os.makedirs(self.config.results_dir, exist_ok=True)
            
            final_state_path_json = os.path.join(self.config.results_dir, f"{self.config.game_id}_final_state.json")
            # The to_saved_game_format function typically returns a string (JSON).
            # It might require a Game object that has been fully processed.
            if hasattr(game_instance, 'is_game_done') and game_instance.is_game_done: # Check if it's a real Game obj
                game_state_json_str = to_saved_game_format(game_instance)
                # Ensure it's a string - to_saved_game_format might return a dict
                if isinstance(game_state_json_str, dict):
                    game_state_json_str = json.dumps(game_state_json_str, indent=2, default=str)
                with open(final_state_path_json, 'w', encoding='utf-8') as f:
                    f.write(game_state_json_str)
                logger.info(f"Final game state (JSON) saved to: {final_state_path_json}")

                # Optionally, save an SVG of the final board if possible and desired
                # This depends on the capabilities of the 'diplomacy' library version
                if hasattr(game_instance, 'render_negotiation_messages_html'): # A guess for a render method
                    # final_state_path_svg = os.path.join(self.config.results_dir, f"{self.config.game_id}_final_board.svg") # Unused variable as SVG saving is commented
                    try:
                        # Example: game_instance.render().save_svg(final_state_path_svg)
                        # This is highly dependent on the library; adjust as needed.
                        # For now, we'll skip if no obvious method.
                        # svg_data = game_instance.render_to_svg_bytes() # if such a method exists
                        # with open(final_state_path_svg, 'wb') as f:
                        #     f.write(svg_data)
                        # logger.info(f"Final board SVG saved to: {final_state_path_svg}")
                        pass # Placeholder for SVG saving
                    except Exception as e_svg:
                        logger.warning(f"Could not save final board SVG: {e_svg}")
            else:
                logger.warning("Game instance is not a valid Diplomacy Game object or game is not done. Skipping JSON state save.")

        except Exception as e:
            logger.error(f"Error saving final game state: {e}", exc_info=True)

        # 2. Save the game history
        # GameHistory might be complex. Consider serializing to JSON via a custom method
        # or pickling if appropriate. For simplicity, a JSON representation is preferred.
        try:
            history_path_json = os.path.join(self.config.results_dir, f"{self.config.game_id}_game_history.json")
            
            # If GameHistory has a to_dict method:
            if hasattr(game_history, 'to_dict'):
                history_dict = game_history.to_dict() # Requires implementing to_dict in GameHistory
            else:
                # Basic serialization using dataclasses.asdict if GameHistory and Phase are dataclasses
                # This is a fallback and might need refinement for complex objects like Message.
                # For now, let's assume GameHistory might need a dedicated method.
                # Placeholder: just try to dump what we have, might fail for complex types.
                # A proper solution would be game_history.export_to_json_serializable_dict()
                # For now, we'll just log a warning if no to_dict() method.
                logger.warning("GameHistory does not have a 'to_dict' method. Saving history might be incomplete or fail.")
                # Attempting a shallow conversion for demonstration. This will likely miss nested custom objects.
                history_dict = {
                    "phases": [vars(phase) for phase in game_history.phases]
                }
                # A more robust way for dataclasses:
                # from dataclasses import asdict
                # history_dict = {"phases": [asdict(phase) for phase in game_history.phases]}
                # This still needs Message to be serializable.

            with open(history_path_json, 'w', encoding='utf-8') as f:
                json.dump(history_dict, f, indent=2, default=str) # default=str for non-serializable
            logger.info(f"Game history saved to: {history_path_json}")
        except Exception as e:
            logger.error(f"Error saving game history: {e}", exc_info=True)


    def save_agent_manifestos(self, agents: Dict[str, 'DiplomacyAgent']):
        """
        Saves the final state (goals, relationships, journal/diary) of each agent.

        Args:
            agents: A dictionary mapping power names to their DiplomacyAgent instances.
        """
        if not self.config.log_to_file:
            logger.info("File logging disabled, skipping saving agent manifestos.")
            return
            
        if not agents:
            logger.warning("No agents provided to save_agent_manifestos.")
            return

        logger.info(f"Saving agent manifestos to directory: {self.config.manifestos_dir}")
        os.makedirs(self.config.manifestos_dir, exist_ok=True) # Ensure it exists

        for power_name, agent in agents.items():
            manifesto_path = os.path.join(self.config.manifestos_dir, f"{self.config.game_id}_{power_name}_manifesto.txt")
            try:
                with open(manifesto_path, 'w', encoding='utf-8') as f:
                    f.write(f"Manifesto for {power_name} (Model: {agent.model_id})\n")
                    f.write(f"Game ID: {self.config.game_id}\n")
                    f.write(f"Timestamp: {self.config.current_datetime_str}\n")
                    f.write("\n--- Final Goals ---\n")
                    if agent.goals:
                        for goal in agent.goals:
                            f.write(f"- {goal}\n")
                    else:
                        f.write("(No specific goals listed)\n")

                    f.write("\n--- Final Relationships ---\n")
                    if agent.relationships:
                        for p, status in agent.relationships.items():
                            f.write(f"- {p}: {status}\n")
                    else:
                        f.write("(No specific relationships listed)\n")

                    f.write("\n--- Private Journal (Last 20 entries) ---\n")
                    if agent.private_journal:
                        for entry in agent.private_journal[-20:]: # Show last few entries
                            f.write(f"{entry}\n")
                    else:
                        f.write("(Journal is empty)\n")
                        
                    f.write("\n--- Private Diary (Last 50 entries) ---\n")
                    if agent.private_diary:
                        for entry in agent.private_diary[-50:]: # Show last few entries
                            f.write(f"{entry}\n")
                    else:
                        f.write("(Diary is empty)\n")
                
                logger.info(f"Manifesto for {power_name} saved to: {manifesto_path}")
            except Exception as e:
                logger.error(f"Error saving manifesto for {power_name}: {e}", exc_info=True)

    def log_final_results(self, game_instance: 'Game'):
        """
        Logs the final results of the game, including supply center counts and winner.

        Args:
            game_instance: The completed Diplomacy game instance.
        """
        logger.info("--- FINAL GAME RESULTS ---")
        logger.info(f"Game ID: {self.config.game_id}")
        
        # Check if game is properly completed
        if hasattr(game_instance, 'is_game_done') and game_instance.is_game_done:
            logger.info("Game completed successfully.")
        elif hasattr(game_instance, 'status') and game_instance.status == 'COMPLETED':
            logger.info("Game marked as completed.")
        else:
            logger.warning("Game is not marked as done, or not a valid Game object. Final results might be incomplete.")

        # Log supply center counts
        if hasattr(game_instance, 'powers') and game_instance.powers:
            logger.info("Final Supply Center Counts:")
            # Sort powers by supply center count (descending)
            power_centers = []
            for power_name, power in game_instance.powers.items():
                if hasattr(power, 'centers'):
                    center_count = len(power.centers)
                    centers_list = sorted(power.centers) if power.centers else []
                    power_centers.append((power_name, center_count, centers_list))
            
            # Sort by center count (descending)
            power_centers.sort(key=lambda x: x[1], reverse=True)
            
            for power_name, center_count, centers_list in power_centers:
                centers_str = ", ".join(centers_list) if centers_list else "None"
                logger.info(f"  {power_name:<8}: {center_count:2d} SCs ({centers_str})")

            # Determine winner(s)
            if power_centers:
                max_centers = power_centers[0][1]
                winners = [power for power, count, _ in power_centers if count == max_centers]
                if len(winners) == 1:
                    logger.info(f"Winner: {winners[0]} with {max_centers} supply centers")
                else:
                    logger.info(f"Draw between: {', '.join(winners)} with {max_centers} supply centers each")
        else:
            logger.warning("No power information available for final results.")

        # Try to get winner information from game object
        if hasattr(game_instance, 'get_winners'):
            try:
                winners = game_instance.get_winners()
                if winners:
                    logger.info(f"Game winners: {', '.join(winners)}")
            except Exception as e:
                logger.warning(f"Could not determine winners: {e}")
        else:
            logger.warning("Game object does not have 'get_winners' method to determine winner.")

        logger.info("-" * 26)

        # Display API usage statistics
        self.log_api_usage_stats()

    def log_api_usage_stats(self):
        """Log comprehensive API usage statistics by country."""
        logger.info("--- API USAGE STATISTICS ---")
        
        try:
            # Get usage stats by country
            country_stats = get_usage_stats_by_country(self.config.game_id)
            total_stats = get_total_usage_stats(self.config.game_id)
            
            if not country_stats:
                logger.info("No API usage data recorded for this game.")
                return
            
            logger.info("Usage by Country:")
            logger.info(f"{'Country':<8} {'API Calls':<10} {'Input Tokens':<13} {'Output Tokens':<14} {'Models'}")
            logger.info("-" * 70)
            
            for country, stats in sorted(country_stats.items()):
                models_str = ", ".join(stats['models'])
                logger.info(f"{country:<8} {stats['api_calls']:<10} {stats['input_tokens']:<13} {stats['output_tokens']:<14} {models_str}")
            
            logger.info("-" * 70)
            logger.info(f"{'TOTAL':<8} {total_stats['total_api_calls']:<10} {total_stats['total_input_tokens']:<13} {total_stats['total_output_tokens']:<14}")
            
            # Calculate costs (rough estimates)
            total_input = total_stats['total_input_tokens']
            total_output = total_stats['total_output_tokens']
            
            # Rough cost estimates (these are approximate and may vary)
            # GPT-4o: $5/1M input, $15/1M output
            # GPT-4o-mini: $0.15/1M input, $0.60/1M output  
            # GPT-3.5-turbo: $0.50/1M input, $1.50/1M output
            estimated_cost_gpt4o = (total_input * 5 + total_output * 15) / 1_000_000
            estimated_cost_gpt4o_mini = (total_input * 0.15 + total_output * 0.60) / 1_000_000
            estimated_cost_gpt35 = (total_input * 0.50 + total_output * 1.50) / 1_000_000
            
            logger.info("")
            logger.info("Estimated Costs (if all tokens were from):")
            logger.info(f"  GPT-4o:      ${estimated_cost_gpt4o:.4f}")
            logger.info(f"  GPT-4o-mini: ${estimated_cost_gpt4o_mini:.4f}")
            logger.info(f"  GPT-3.5:     ${estimated_cost_gpt35:.4f}")
            logger.info("  (Ollama models: Free)")
            
        except Exception as e:
            logger.error(f"Error displaying API usage statistics: {e}", exc_info=True)
        
        logger.info("-" * 30)


if __name__ == '__main__':
    # Example Usage for testing GameResultsProcessor
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # --- Mocking dependencies ---
    class MockGameConfigResults:
        def __init__(self, game_id="results_test_game", log_to_file=True):
            self.game_id = game_id
            self.current_datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.log_to_file = log_to_file
            
            # Create dummy directories similar to GameConfig
            self.base_log_dir = os.path.join(os.getcwd(), "logs_results_test")
            self.game_id_specific_log_dir = os.path.join(self.base_log_dir, self.game_id)
            self.results_dir = os.path.join(self.game_id_specific_log_dir, "results")
            self.manifestos_dir = os.path.join(self.results_dir, "manifestos")
            
            if self.log_to_file:
                os.makedirs(self.manifestos_dir, exist_ok=True) # Also creates parent results_dir

    class MockDiplomacyAgent:
        def __init__(self, power_name, model_id="mock_model"):
            self.power_name = power_name
            self.model_id = model_id
            self.goals = [f"Take over the world ({power_name})", "Make friends"]
            self.relationships = {"OTHER_POWER": "Neutral"}
            self.private_journal = [f"Journal Entry 1 for {power_name}", f"Journal Entry 2 for {power_name}"]
            self.private_diary = [f"[S1901M] Diary entry for {power_name}"]

    class MockGameHistoryResults:
        def __init__(self):
            self.phases = [ # Simplified phase objects for testing to_dict fallback
                {"name": "SPRING 1901M", "orders_by_power": {"FRANCE": ["A PAR H"]}},
                {"name": "AUTUMN 1901M", "orders_by_power": {"FRANCE": ["A PAR - BUR"]}}
            ]
        # Add a to_dict if you want to test that path
        # def to_dict(self): return {"phases": self.phases}


    # Mock diplomacy.Game object (very basic)
    class MockDiplomacyGame:
        def __init__(self):
            self.is_game_done = True # Mark as done for saving state
            self._current_phase = "WINTER 1905" # Example
            self._centers = { # Example SC map
                "FRANCE": ["PAR", "MAR", "BRE", "SPA", "POR", "BEL", "HOL"],
                "ENGLAND": ["LON", "LVP", "EDI", "NWY", "SWE"],
                "GERMANY": ["BER", "MUN", "KIE", "DEN", "RUH", "WAR", "MOS"],
            }
            self._winners = ["GERMANY"] # Example winner

        def get_current_phase(self): return self._current_phase
        def get_state(self): return {"centers": self._centers}
        def get_winners(self): return self._winners
        # Add a dummy to_saved_game_format method if the real one is not available during test
        # This is usually part of the diplomacy library.
        # For testing, we can mock it if `to_saved_game_format` itself is not being tested here.
        # to_saved_game_format = staticmethod(lambda game_obj: json.dumps({"mock_game_state": game_obj._current_phase}))


    logger.info("--- Testing GameResultsProcessor ---")
    
    test_config = MockGameConfigResults()
    results_processor = GameResultsProcessor(test_config)
    
    mock_game_instance = MockDiplomacyGame()
    mock_game_history = MockGameHistoryResults()
    
    # Test saving game state and history
    logger.info("\n--- Testing save_game_state ---")
    results_processor.save_game_state(mock_game_instance, mock_game_history)
    
    # Test saving agent manifestos
    logger.info("\n--- Testing save_agent_manifestos ---")
    mock_agents = {
        "FRANCE": MockDiplomacyAgent("FRANCE", "ollama/test-fr"),
        "GERMANY": MockDiplomacyAgent("GERMANY", "gpt-4-mini")
    }
    results_processor.save_agent_manifestos(mock_agents)
    
    # Test logging final results
    logger.info("\n--- Testing log_final_results ---")
    results_processor.log_final_results(mock_game_instance)

    logger.info(f"\nCheck the directory '{test_config.game_id_specific_log_dir}' for output files.")
    logger.info("--- GameResultsProcessor Test Complete ---")

    # Basic cleanup for test files (optional)
    # import shutil
    # if os.path.exists(test_config.base_log_dir):
    #     logger.info(f"Cleaning up test log directory: {test_config.base_log_dir}")
    #     shutil.rmtree(test_config.base_log_dir)



================================================
File: initialization.py
================================================
# ai_diplomacy/initialization.py
import logging
import json
import os # Add os import
import asyncio
import llm

# Forward declaration for type hinting, actual imports in function if complex
from typing import TYPE_CHECKING, Dict, Any, Tuple
if TYPE_CHECKING:
    from diplomacy import Game
    from diplomacy.models.game import GameHistory
    from .agent import DiplomacyAgent

from .agent import ALL_POWERS, ALLOWED_RELATIONSHIPS
# run_llm_and_log is obsolete
from .utils import log_llm_response 
from .prompt_constructor import build_context_prompt
from .llm_coordinator import _local_llm_lock # Import the lock

logger = logging.getLogger(__name__)

# Placeholder for Power enum if you have one, otherwise use strings
ALL_POWERS = ["AUSTRIA", "ENGLAND", "FRANCE", "GERMANY", "ITALY", "RUSSIA", "TURKEY"]

async def initialize_agent_state_ext(
    agent: 'DiplomacyAgent', 
    game: 'Game', 
    game_history: 'GameHistory', 
    log_file_path: str
):
    """Uses the LLM to set initial goals and relationships for the agent."""
    power_name = agent.power_name
    logger.info(f"[{power_name}] Initializing agent state using LLM (external function)..." )
    current_phase = game.get_current_phase() if game else "UnknownPhase"

    full_prompt = ""  # Ensure full_prompt is defined in the outer scope for finally block
    # response = ""     # Unused variable
    success_status = "Failure: Initialized" # Default status
    response_text = "" # Initialize to ensure it's defined for the finally block if LLM call fails early

    try:
        # Use a simplified prompt for initial state generation
        allowed_labels_str = ", ".join(ALLOWED_RELATIONSHIPS)
        initial_prompt = f"You are the agent for {power_name} in a game of Diplomacy at the very start (Spring 1901). " \
                         f"Analyze the initial board position and suggest 2-3 strategic high-level goals for the early game. " \
                         f"Consider your power's strengths, weaknesses, and neighbors. " \
                         f"Also, provide an initial assessment of relationships with other powers. " \
                         f"IMPORTANT: For each relationship, you MUST use exactly one of the following labels: {allowed_labels_str}. " \
                         f"Format your response as a JSON object with two keys: 'initial_goals' (a list of strings) and 'initial_relationships' (a dictionary mapping power names to one of the allowed relationship strings)."

        board_state = game.get_state() if game else {}
        possible_orders = game.get_all_possible_orders() if game else {}

        logger.debug(f"[{power_name}] Preparing context for initial state. Board state type: {type(board_state)}, possible_orders type: {type(possible_orders)}, game_history type: {type(game_history)}")
        # Ensure agent.client and its methods can handle None for game/board_state/etc. if that's a possibility
        # For initialization, game should always be present.

        formatted_diary = agent.format_private_diary_for_prompt()

        context = build_context_prompt(
            game=game,
            board_state=board_state, 
            power_name=power_name,
            possible_orders=possible_orders, 
            game_history=game_history, 
            agent_goals=None, 
            agent_relationships=None, 
            agent_private_diary=formatted_diary, 
        )
        full_prompt = initial_prompt + "\n\n" + context
        
        # raw_response_text = "" # Unused variable; response_text is used for LLM output
        parsed_successfully = False
        update_data = {} # Initialize to ensure it exists

        try:
            # Validate model ID by attempting to get the model
            # Use get_async_model for async operations
            model = llm.get_async_model(agent.model_id, options={"host": os.environ.get("OLLAMA_HOST")}) 
            if not model: # Should not happen if get_async_model raises on error
                raise llm.UnknownModelError(f"Model {agent.model_id} could not be retrieved.")
            logger.info(f"Successfully validated model {agent.model_id} for {agent.power_name}.")

            # Assuming build_context_prompt does not include the system prompt, 
            # and agent.system_prompt is the one to use.
            # If full_prompt from build_context_prompt already includes system prompt,
            # then system=None or system=agent.system_prompt might need adjustment based on model behavior.
            logger.debug(f"Full prompt for {agent.power_name}: {full_prompt}")

            # model.prompt() is called synchronously for async models from llm-ollama,
            # it returns a response object whose methods (like .text()) are awaitable.
            prompt_response_obj = model.prompt(full_prompt, system=agent.system_prompt)
            response_text = await prompt_response_obj.text() # Await the .text() method
            logger.debug(f"[{power_name}] LLM response for initial state: {response_text[:300]}...")

            # BUG: agent._extract_json_from_text should be llm_utils.extract_json_from_text
            # For linting, assuming this call structure is intended for now.
            update_data = agent._extract_json_from_text(response_text) 
            if not isinstance(update_data, dict): # Ensure it's a dict
                logger.error(f"[{power_name}] _extract_json_from_text returned non-dict: {type(update_data)}. Treating as parsing failure. Data: {str(update_data)[:300]}")
                update_data = {} # Reset to empty dict
                success_status = "Failure: NotADictAfterParse"
                parsed_successfully = False
            else:
                logger.debug(f"[{power_name}] Successfully parsed JSON for initial state: {update_data}")
                parsed_successfully = True # Parsed to a dict
                # Success status will be refined based on whether data is applied
        
        except llm.UnknownModelError as e:
            logger.error(f"Agent {agent.power_name} has unknown model_id: {agent.model_id}. Error: {e}")
            # Potentially skip this agent or raise an error to stop initialization
            # For now, we'll log and continue, but the agent might fail later.
            # Consider adding a 'failed_agents' list or similar handling.
            # BUG: 'continue' is not valid in this context, should be 'return' or error propagation.
            # This will be left as-is for the linting pass.
            continue 
        except Exception as e:
            logger.error(f"Unexpected error validating model for agent {agent.power_name} ({agent.model_id}): {e}")
            # BUG: 'continue' is not valid in this context.
            continue 

        initial_goals_applied = False
        initial_relationships_applied = False

        if parsed_successfully:
            initial_goals = update_data.get('initial_goals') or update_data.get('goals')
            initial_relationships = update_data.get('initial_relationships') or update_data.get('relationships')

            if isinstance(initial_goals, list) and initial_goals:
                agent.goals = initial_goals
                agent.add_journal_entry(f"[{current_phase}] Initial Goals Set by LLM: {agent.goals}")
                logger.info(f"[{power_name}] Goals updated from LLM: {agent.goals}")
                initial_goals_applied = True
            else:
                logger.warning(f"[{power_name}] LLM did not provide valid 'initial_goals' list (got: {initial_goals}).")

            if isinstance(initial_relationships, dict) and initial_relationships:
                valid_relationships = {}
                # ... (rest of relationship validation logic from before) ...
                for p_key, r_val in initial_relationships.items():
                    p_upper = str(p_key).upper()
                    r_title = str(r_val).title() if isinstance(r_val, str) else str(r_val)
                    if p_upper in ALL_POWERS and p_upper != power_name:
                        if r_title in ALLOWED_RELATIONSHIPS:
                            valid_relationships[p_upper] = r_title
                        else:
                            valid_relationships[p_upper] = "Neutral"
                if valid_relationships:
                    agent.relationships = valid_relationships
                    agent.add_journal_entry(f"[{current_phase}] Initial Relationships Set by LLM: {agent.relationships}")
                    logger.info(f"[{power_name}] Relationships updated from LLM: {agent.relationships}")
                    initial_relationships_applied = True
                else:
                    logger.warning(f"[{power_name}] No valid relationships found in LLM response.")
            else:
                 logger.warning(f"[{power_name}] LLM did not provide valid 'initial_relationships' dict (got: {initial_relationships}).")
            
            if initial_goals_applied or initial_relationships_applied:
                success_status = "Success: Applied LLM data"
            elif parsed_successfully: # Parsed but nothing useful to apply
                success_status = "Success: Parsed but no data applied"
            # If not parsed_successfully, success_status is already "Failure: JSONDecodeError"

        # Fallback if LLM data was not applied or parsing failed
        if not initial_goals_applied:
            if not agent.goals: # Only set defaults if no goals were set during agent construction or by LLM
                agent.goals = ["Survive and expand", "Form beneficial alliances", "Secure key territories"]
                agent.add_journal_entry(f"[{current_phase}] Set default initial goals as LLM provided none or parse failed.")
                logger.info(f"[{power_name}] Default goals set.")
        
        if not initial_relationships_applied:
             # Check if relationships are still default-like before overriding
            is_default_relationships = True # Assume default unless proven otherwise
            if agent.relationships: 
                # Check if all existing relationships are "Neutral"
                if not all(r == "Neutral" for r in agent.relationships.values()):
                    is_default_relationships = False
            
            if is_default_relationships: # Only override if current state is effectively default
                agent.relationships = {p: "Neutral" for p in ALL_POWERS if p != power_name}
                agent.add_journal_entry(f"[{current_phase}] Set default neutral relationships as LLM provided none valid or parse failed.")
                logger.info(f"[{power_name}] Default neutral relationships set (or kept).")
            else:
                logger.info(f"[{power_name}] Agent relationships were not default, retaining existing ones after failed/empty LLM update for relationships: {agent.relationships}")


    except Exception as e: # Catch-all for unexpected errors in the main try block
        logger.error(f"[{power_name}] Critical error during external agent state initialization: {e}", exc_info=True)
        success_status = f"Failure: Exception ({type(e).__name__})"
        # Ensure fallback logic for goals/relationships if not already set
        if not agent.goals: # If goals are still empty
            agent.goals = ["Survive and expand", "Form beneficial alliances", "Secure key territories"]
            logger.info(f"[{power_name}] Set fallback goals after top-level error: {agent.goals}")
        
        # Check if relationships are empty or all Neutral
        is_relationships_effectively_empty_or_default = True
        if agent.relationships:
            if not all(r == "Neutral" for r in agent.relationships.values()):
                 is_relationships_effectively_empty_or_default = False
        
        if is_relationships_effectively_empty_or_default:
            agent.relationships = {p: "Neutral" for p in ALL_POWERS if p != power_name}
            logger.info(f"[{power_name}] Set/reset to fallback neutral relationships after top-level error: {agent.relationships}")
    finally:
        if log_file_path: 
            log_llm_response(
                log_file_path=log_file_path,
                model_name=agent.model_id, # Use agent's model_id
                power_name=power_name,
                phase=current_phase,
                response_type="initial_state_setup", 
                raw_input_prompt=full_prompt,
                raw_response=response_text, # Log the raw text from LLM
                success=success_status
            )

    # Final log of state after initialization attempt
    logger.info(f"[{power_name}] Post-initialization state: Goals={agent.goals}, Relationships={agent.relationships}")

async def initialize_agent_state_concurrently(
    agent: 'DiplomacyAgent',
    game: 'Game', # diplomacy.Game object
    game_history: 'GameHistory',
    power_name: str,
    initial_prompt_template: str
) -> Tuple[str, bool, str, Dict[str, Any]]:
    logger.info(f"[{power_name}] Initializing state with LLM...")
    full_prompt = "" # Initialize full_prompt
    update_data = {}
    success_status = "Unknown" # Default status
    response_text = "" # Initialize response_text

    try:
        # Ensure the prompt template is a string and not None
        if initial_prompt_template is None or not isinstance(initial_prompt_template, str):
            logger.error(f"[{power_name}] Initial prompt template is not a valid string or is None.")
            success_status = "Failure: InvalidPromptTemplate"
            return power_name, False, success_status, update_data

        full_prompt = initial_prompt_template.format(
            power_name=power_name,
            game_state=game.get_state(),
            all_powers=", ".join(ALL_POWERS),
            # Assuming game_history has a method to get a summary or relevant parts for the prompt
            negotiation_history_summary=game_history.get_negotiation_summary(power_name) if game_history else "No negotiation history available."
        )

        # Log the prompt being sent for initialization (optional, can be verbose)
        logger.debug(f"[{power_name}] Initialization prompt:\\n{full_prompt}")

        async with _local_llm_lock:
            if os.environ.get("OLLAMA_SERIAL_MODE", "false").lower() == "true":
                 logger.debug(f"[{power_name}] Ollama model call (initialize_agent_state_concurrently) acquired lock (serial mode enabled)...")

            model = llm.get_async_model(agent.model_id, options={"host": os.environ.get("OLLAMA_HOST")}) # Use get_async_model for async operations
            response_obj = model.prompt(full_prompt, system=agent.system_prompt)
            response_text = await response_obj.text() # Assign to response_text

        logger.info(f"[{power_name}] LLM response received for initialization.")
        logger.debug(f"[{power_name}] Raw LLM response for state initialization: {response_text}")

        # Attempt to parse the JSON response
        try:
            # First, try to find JSON within ```json ... ``` or ``` ... ```
            json_match = agent.extract_json_from_text(response_text)
            if json_match:
                parsed_data = json.loads(json_match)
                logger.info(f"[{power_name}] Successfully parsed JSON from LLM response for initialization.")
                update_data = parsed_data # Store parsed data
                success_status = "Success: Parsed"
            else:
                logger.warning(f"[{power_name}] No JSON block found in LLM response for initialization. Trying direct parse.")
                # Try parsing the whole response as JSON if no block is found
                try:
                    parsed_data = json.loads(response_text)
                    logger.info(f"[{power_name}] Successfully parsed entire LLM response as JSON for initialization.")
                    update_data = parsed_data
                    success_status = "Success: ParsedDirectly"
                except json.JSONDecodeError:
                    logger.error(f"[{power_name}] Failed to parse LLM response as JSON directly for initialization.")
                    success_status = "Failure: JSONDecode"
        except json.JSONDecodeError as e_json:
            logger.error(f"[{power_name}] JSON parsing failed for initialization: {e_json}", exc_info=True)
            success_status = "Failure: JSONDecode"
        except Exception as e_parse: # Catch any other parsing related errors
            logger.error(f"[{power_name}] An unexpected error occurred during LLM response parsing for initialization: {e_parse}", exc_info=True)
            success_status = "Failure: ParseError"

    except llm.UnknownModelError as e_model:
        logger.error(f"[{power_name}] Unknown model error during initialization: {e_model}", exc_info=True)
        success_status = f"Failure: UnknownModel ({agent.model_id})"
    except Exception as e_llm_call:
        logger.error(f"[{power_name}] LLM call or parsing failed during initialization: {e_llm_call}", exc_info=True)
        success_status = f"Failure: LLMErrorOrParse ({type(e_llm_call).__name__})"
        # response_text is already defined

    return power_name, True if "Success" in success_status else False, success_status, update_data


async def initialize_agents_concurrently(
    agents: Dict[str, 'DiplomacyAgent'],
    game: 'Game',
    game_history: 'GameHistory',
    initial_prompt_template_str: str # Assuming this is the correct signature
) -> None:
    """
    Initializes multiple agents concurrently by calling their LLMs for initial state.
    """
    tasks = []
    for power_name, agent_instance in agents.items():
        logger.info(f"Preparing initialization task for {power_name}...")
        try:
            # Validate model ID by attempting to get the model
            # This should be done before adding the task, so if it fails, the agent isn't added.
            # Note: llm.get_async_model might not raise an error immediately for all plugins
            # if the model doesn't exist; it might only raise when an operation is attempted.
            # A more robust check might involve a quick health check or info call if available.
            _ = llm.get_async_model(agent_instance.model_id, options={"host": os.environ.get("OLLAMA_HOST")})
            logger.info(f"Model {agent_instance.model_id} seems valid for {power_name} (get_async_model succeeded). Scheduling state initialization.")

            task = initialize_agent_state_ext( 
                agent_instance,
                game,
                game_history,
                # log_file_path parameter was removed from initialize_agent_state_ext, ensure it's not needed or re-add if required.
                # For now, assuming it uses agent_instance.config or similar if needed.
                power_name, # Pass power_name, it was missing in the call signature of initialize_agent_state_ext
                initial_prompt_template_str # Pass initial_prompt_template_str
            )
            tasks.append(task)
            logger.info(f"Task for {power_name} added to initialization queue.")
        except llm.UnknownModelError as e:
            logger.error(f"Skipping initialization for {power_name}: Unknown model_id '{agent_instance.model_id}'. Error: {e}")
            continue # Skip to the next agent if model validation fails during get_async_model
        except Exception as e:
            logger.error(f"Skipping initialization for {power_name} due to unexpected error validating model '{agent_instance.model_id}': {e}", exc_info=True)
            continue # Skip to the next agent

    if not tasks:
        logger.warning("No agent tasks were created for initialization. Check model configurations or errors during validation.")
        return

    logger.info(f"Starting concurrent initialization for {len(tasks)} agents...")
    results = await asyncio.gather(*tasks, return_exceptions=True)
    logger.info("Concurrent initialization tasks completed.")

    for result in results:
        if isinstance(result, Exception):
            logger.error(f"An exception occurred during an agent's initialization task: {result}", exc_info=result)
            # Handle individual task exception (e.g., log, mark agent as failed)
            continue

        power_name, success, status_detail, update_data_from_llm = result
        agent_to_update = agents.get(power_name)

        if agent_to_update:
            if success and update_data_from_llm:
                logger.info(f"Applying initial state update for {power_name}. Status: {status_detail}")
                logger.debug(f"[{power_name}] Data for state update from LLM: {update_data_from_llm}")
                agent_to_update.update_state_from_llm(update_data_from_llm, game.current_phase)
                # Log confirmation of state update based on parsed data
                initial_goals_applied = 'goals' in update_data_from_llm or 'updated_goals' in update_data_from_llm
                initial_rels_applied = 'relationships' in update_data_from_llm or 'updated_relationships' in update_data_from_llm
                logger.info(f"[{power_name}] Initial goals applied: {initial_goals_applied}, Initial relationships applied: {initial_rels_applied}")

            else:
                logger.error(f"Initialization failed or no data returned for {power_name}. Status: {status_detail}. Raw response was: (Check prior logs for raw response if available)")
                # Agent state remains default. Consider fallback or error state.
        else:
            logger.error(f"Agent {power_name} not found in agents dictionary after initialization task. This should not happen.")



================================================
File: llm_coordinator.py
================================================
import asyncio
# Removed: import os
import logging
from typing import Optional, Dict, Any, AsyncIterator # Removed Union, ContextManager
from contextlib import asynccontextmanager
# Removed: import json
import sqlite3 # Added import
# Removed: import functools

import llm # Assuming this is the llm library by Simon Willison
from llm.models import Model as LLMModel # Renamed to avoid conflict, used for type hinting
from llm import Response as LLMResponse # For type hinting

logger = logging.getLogger(__name__)

# --- New Global Components based on the provided pattern ---

DATABASE_PATH = "ai_diplomacy_usage.db"
_local_lock = asyncio.Lock() # Removed comment: Global lock for local LLM engines

class ModelPool:
    """Caches LLM model instances."""
    _cache: Dict[str, LLMModel] = {}

    @classmethod
    def get(cls, model_id: str) -> LLMModel:
        """Retrieves a model from the cache, loading if not present."""
        if model_id not in cls._cache:
            logger.debug(f"[ModelPool] Loading and caching model: {model_id}")
            cls._cache[model_id] = llm.get_async_model(model_id)
        else:
            logger.debug(f"[ModelPool] Retrieving model from cache: {model_id}")
        return cls._cache[model_id]

@asynccontextmanager
async def serial_if_local(model_id: str) -> AsyncIterator[None]:
    """
    Context manager to serialize access to local LLMs (ollama, llamacpp).
    """
    model_id_lower = model_id.lower()
    # Case-insensitive check will be applied to these prefixes
    # These prefixes are taken from the original SERIAL_ACCESS_PREFIXES
    if any(model_id_lower.startswith(prefix) for prefix in ["ollama/", "llamacpp/"]):
        logger.debug(f"Acquiring lock for local model: {model_id}")
        async with _local_lock:
            logger.debug(f"Lock acquired for local model: {model_id}")
            yield
            logger.debug(f"Lock released for local model: {model_id}")
    else:
        yield

def initialize_database():
    """Initializes the SQLite database and creates the 'usage' table if it doesn't exist."""
    try:
        with sqlite3.connect(DATABASE_PATH) as conn:
            conn.execute("PRAGMA journal_mode=WAL;")
            conn.execute("""
            CREATE TABLE IF NOT EXISTS usage (
              id          INTEGER PRIMARY KEY,
              game_id     TEXT,
              agent       TEXT,
              phase       TEXT,
              model       TEXT,
              input       INTEGER,
              output      INTEGER,
              ts          DATETIME DEFAULT CURRENT_TIMESTAMP
            );
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS usage_game_agent ON usage (game_id, agent);")
            conn.commit()
        logger.info(f"Database initialized successfully at {DATABASE_PATH}")
    except sqlite3.Error as e:
        logger.error(f"Error initializing database {DATABASE_PATH}: {e}", exc_info=True)
        raise

initialize_database() # Removed comment: Initialize DB on module load

async def record_usage(game_id: str, agent: str, phase: str, response: LLMResponse):
    """Records LLM token usage in the database."""
    try:
        usage_stats = await response.usage() # Usage(input=..., output=..., details=...)
        with sqlite3.connect(DATABASE_PATH) as conn:
            conn.execute(
                "INSERT INTO usage (game_id, agent, phase, model, input, output) VALUES (?, ?, ?, ?, ?, ?)",
                (game_id, agent, phase, response.model.model_id, usage_stats.input, usage_stats.output)
            )
            conn.commit()
        logger.debug(f"Usage recorded for {agent} in game {game_id}, phase {phase}: {usage_stats.input} in, {usage_stats.output} out for model {response.model.model_id}")
    except sqlite3.Error as e:
        logger.error(f"SQLite error in record_usage: {e}", exc_info=True)
    except AttributeError as e:
        logger.error(f"Error accessing response attributes in record_usage (model: {response.model.model_id if hasattr(response, 'model') else 'N/A'}): {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error in record_usage: {e}", exc_info=True)

def get_usage_stats_by_country(game_id: str) -> Dict[str, Dict[str, int]]:
    """Get API usage statistics by country for a specific game."""
    try:
        with sqlite3.connect(DATABASE_PATH) as conn:
            cursor = conn.execute("""
                SELECT agent, 
                       COUNT(*) as api_calls,
                       SUM(input) as total_input_tokens,
                       SUM(output) as total_output_tokens,
                       model
                FROM usage 
                WHERE game_id = ? 
                GROUP BY agent, model
                ORDER BY agent
            """, (game_id,))
            
            results = {}
            for row in cursor.fetchall():
                agent, api_calls, input_tokens, output_tokens, model = row
                if agent not in results:
                    results[agent] = {
                        'api_calls': 0,
                        'input_tokens': 0,
                        'output_tokens': 0,
                        'models': []
                    }
                results[agent]['api_calls'] += api_calls
                results[agent]['input_tokens'] += input_tokens or 0
                results[agent]['output_tokens'] += output_tokens or 0
                if model not in results[agent]['models']:
                    results[agent]['models'].append(model)
            
            return results
    except sqlite3.Error as e:
        logger.error(f"Error getting usage stats: {e}", exc_info=True)
        return {}

def get_total_usage_stats(game_id: str) -> Dict[str, int]:
    """Get total API usage statistics for a specific game."""
    try:
        with sqlite3.connect(DATABASE_PATH) as conn:
            cursor = conn.execute("""
                SELECT COUNT(*) as total_api_calls,
                       SUM(input) as total_input_tokens,
                       SUM(output) as total_output_tokens
                FROM usage 
                WHERE game_id = ?
            """, (game_id,))
            
            row = cursor.fetchone()
            if row:
                return {
                    'total_api_calls': row[0],
                    'total_input_tokens': row[1] or 0,
                    'total_output_tokens': row[2] or 0
                }
            return {'total_api_calls': 0, 'total_input_tokens': 0, 'total_output_tokens': 0}
    except sqlite3.Error as e:
        logger.error(f"Error getting total usage stats: {e}", exc_info=True)
        return {'total_api_calls': 0, 'total_input_tokens': 0, 'total_output_tokens': 0}

async def llm_call_internal(
    game_id: str,
    agent_name: str,
    phase_str: str,
    model_id: str,
    prompt: str,
    system_prompt: Optional[str] = None,
    **kwargs: Any
) -> str:
    """
    Internal wrapper for LLM calls incorporating model pooling, serial locking, and usage recording.
    """
    model_obj = ModelPool.get(model_id)
    
    prompt_options: Dict[str, Any] = {}
    if system_prompt:
        prompt_options['system'] = system_prompt
    prompt_options.update(kwargs)

    async with serial_if_local(model_id):
        response_obj = model_obj.prompt(prompt, **prompt_options)
        
        # Ensure we wait for the text to be fully generated.
        response_text = await response_obj.text()
        
        # Record usage after getting the response (fire-and-forget)
        asyncio.create_task(record_usage(game_id, agent_name, phase_str, response_obj))
        
        return response_text

# --- End of New Global Components ---

# _local_llm_lock = asyncio.Lock() # Removed, use _local_lock

# Case-insensitive check will be applied to these prefixes
# SERIAL_ACCESS_PREFIXES = ["ollama/", "llamacpp/"] # Removed
# SERIALIZE_LOCAL_LLMS_ENV_VAR = "SERIALIZE_LOCAL_LLMS" # Removed


class LLMCallResult:
    """Structured result from an LLM call with parsing."""
    def __init__(
        self, 
        raw_response: str, 
        parsed_json: Optional[Dict[str, Any]] = None,
        success: bool = True,
        error_message: str = ""
    ):
        self.raw_response = raw_response
        self.parsed_json = parsed_json
        self.success = success
        self.error_message = error_message

    def get_field(self, *field_names: str) -> Optional[Any]:
        """Get the first available field from the parsed JSON."""
        if not self.parsed_json:
            return None
        
        for field_name in field_names:
            if field_name in self.parsed_json:
                return self.parsed_json[field_name]
        return None

class LocalLLMCoordinator:
    """
    Coordinates requests to LLMs, incorporating model pooling, serial access for local models,
    and usage tracking.
    """

    def __init__(self):
        """
        Initializes the LocalLLMCoordinator.
        Database initialization is handled at the module level.
        """
        logger.info("LocalLLMCoordinator initialized.")
        # Initialization of DB is now at module level.
        pass

    # serial_access context manager removed, replaced by global serial_if_local

    # _single_llm_call method removed

    # call_llm_with_retry method removed

    async def call_llm_with_json_parsing(
        self,
        model_id: str,
        prompt: str,
        # Parameters for new llm_call_internal (non-default)
        game_id: str,
        agent_name: str, # Was power_name
        phase_str: str,    # Was phase
        # Optional parameters (with defaults)
        system_prompt: Optional[str] = None,
        request_identifier: str = "request", # Primarily for coordinator's own logging
        expected_json_fields: Optional[list] = None,
        response_type: str = "llm_call", # For file logging
        log_to_file_path: Optional[str] = None # Path for logging full prompt/response to file
    ) -> LLMCallResult:
        """
        Makes an LLM call using the new internal wrapper, then parses for JSON.
        Logs full prompt/response to a file if path provided, token usage logged to DB.
        
        Args:
            model_id: LLM model identifier
            prompt: The main prompt text
            system_prompt: Optional system prompt
            request_identifier: Identifier for coordinator's internal logging
            expected_json_fields: List of expected JSON field names for validation
            game_id: Game identifier for DB logging
            agent_name: Agent/Power name for DB logging
            phase_str: Game phase for DB logging
            response_type: Type of response for file logging
            log_to_file_path: Optional path for file logging the full transaction
            
        Returns:
            LLMCallResult with parsed data or error information
        """
        from . import llm_utils  # Import here to avoid circular imports
        from .utils import log_llm_response # Assuming this is still used for file logging
        
        result = LLMCallResult("", None, False, "Not initialized")
        
        try:
            logger.info(f"[{request_identifier}] Preparing LLM call. Game: {game_id}, Agent: {agent_name}, Phase: {phase_str}, Model: {model_id}")
            raw_response = await llm_call_internal(
                game_id=game_id,
                agent_name=agent_name,
                phase_str=phase_str,
                model_id=model_id,
                prompt=prompt,
                system_prompt=system_prompt
                # Any additional **kwargs for model.prompt() could be passed here if needed
            )
            
            result.raw_response = raw_response
            
            if raw_response and raw_response.strip():
                try:
                    # Parse JSON using the existing utility
                    parsed_data = llm_utils.extract_json_from_text(
                        raw_response, logger, f"[{request_identifier}] JSON Parsing"
                    )
                    result.parsed_json = parsed_data
                    result.success = True
                    result.error_message = ""
                    
                    # Validate expected fields if provided
                    if expected_json_fields and isinstance(parsed_data, dict):
                        missing_fields = [field for field in expected_json_fields 
                                        if field not in parsed_data]
                        if missing_fields:
                            result.success = False
                            result.error_message = f"Missing expected fields: {missing_fields}"
                    
                except Exception as e:
                    logger.error(f"[{request_identifier}] JSON parsing failed: {e}", exc_info=True)
                    result.success = False
                    result.error_message = f"JSON parsing error: {e}"
            else:
                result.success = False
                result.error_message = "Empty or no response from LLM"
                
        except Exception as e:
            logger.error(f"[{request_identifier}] LLM call via llm_call_internal failed: {e}", exc_info=True)
            result.success = False
            result.error_message = f"LLM call error: {e}"
            if not result.raw_response: # Ensure raw_response has error if call failed early
                result.raw_response = f"Error: {e}"
        
        # Log the full prompt/response to file if path provided
        if log_to_file_path and agent_name and phase_str: # Changed power_name to agent_name
            success_status = "TRUE" if result.success else f"FALSE: {result.error_message}"
            # Assuming log_llm_response is compatible with these params
            log_llm_response(
                log_file_path=log_to_file_path,
                model_name=model_id,
                power_name=agent_name, # Pass agent_name as power_name
                phase=phase_str,       # Pass phase_str as phase
                response_type=response_type,
                raw_input_prompt=prompt,
                raw_response=result.raw_response,
                success=success_status
            )
        
        return result

    async def request(
        self,
        model_id: str,
        prompt_text: str,
        system_prompt_text: Optional[str],
        # New parameters for llm_call_internal
        game_id: str,
        agent_name: str, # Was implicitly part of request_identifier before, now explicit
        phase_str: str,    # New explicit parameter
        request_identifier: str = "request" # For coordinator's logging
    ) -> str:
        """
        Makes a request to the specified LLM using the new internal wrapper.
        Handles model pooling, serial locking for local models, and DB-based usage logging.

        Args:
            model_id: The ID of the LLM to use (e.g., "ollama/llama3", "gpt-4o").
            prompt_text: The main prompt text for the LLM.
            system_prompt_text: Optional system prompt text.
            game_id: Game identifier for DB logging and context.
            agent_name: Agent/Power name for DB logging and context.
            phase_str: Game phase for DB logging and context.
            request_identifier: An identifier for the coordinator's logging purposes.

        Returns:
            The text response from the LLM.

        Raises:
            Exception: Propagates exceptions from llm_call_internal.
        """
        logger.debug(f"[{request_identifier}] LLMCoordinator.request initiated. Model: {model_id}, Game: {game_id}, Agent: {agent_name}, Phase: {phase_str}")
        logger.debug(f"[LLMCoordinator] Using model_id: {model_id}, system_prompt: {'Yes' if system_prompt_text else 'No'}")
        logger.debug(f"[LLMCoordinator] Prompt (first 200 chars): {prompt_text[:200]}...")
        
        try:
            response_text = await llm_call_internal(
                game_id=game_id,
                agent_name=agent_name,
                phase_str=phase_str,
                model_id=model_id,
                prompt=prompt_text,
                system_prompt=system_prompt_text
            )
            
            logger.info(f"[{request_identifier}] LLM call for {model_id} (Game: {game_id}, Agent: {agent_name}) succeeded via llm_call_internal.")
            logger.debug(f"[{request_identifier}] Received response from '{model_id}'. Response length: {len(response_text)}")
            return response_text
            
        except Exception as e:
            logger.error(f"[{request_identifier}] Error during LLM request via llm_call_internal to '{model_id}' (Game: {game_id}, Agent: {agent_name}): {type(e).__name__}: {e}", exc_info=True)
            raise

    async def get_model(self, model_id: str) -> LLMModel: # Renamed from get_model_for_power
        """Retrieves an LLM model instance using the ModelPool."""
        # power_name argument removed as ModelPool is global
        logger.debug(f"Requesting model: {model_id} via ModelPool")
        try:
            model_obj = ModelPool.get(model_id)
            logger.debug(f"Successfully retrieved model: {model_id} from ModelPool")
            return model_obj
        except Exception as e:
            logger.error(f"Failed to get model {model_id} via ModelPool: {e}", exc_info=True)
            raise

    # execute_llm_call method removed as it was a simple wrapper for request

if __name__ == '__main__':
    # Example Usage (requires 'llm' library and potentially an LLM server like Ollama)
    
    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    async def run_example():
        coordinator = LocalLLMCoordinator()

        # Define common parameters for example calls
        example_game_id = "test_game_001"
        example_phase_str = "S1901M"
        
        ollama_model_id = "ollama/llama3" 
        # If 'ollama/llama3' is not available, ollama tests will show UnknownModelError from ModelPool
        
        test_system_prompt = "You are a concise and helpful assistant."
        test_prompt_1 = "What is the capital of France? Respond in one word."
        test_prompt_2 = "Briefly explain asynchronous programming in Python."

        # --- Test Case 1: Ollama model calls (will be serialized by serial_if_local) ---
        try:
            logger.info(f"--- Test Case 1: Concurrent Ollama calls ({ollama_model_id}) ---")
            
            task1 = coordinator.request(
                model_id=ollama_model_id, 
                prompt_text=test_prompt_1, 
                system_prompt_text=test_system_prompt, 
                game_id=example_game_id, 
                agent_name="AgentFrance", 
                phase_str=example_phase_str,
                request_identifier="OllamaTest-1"
            )
            task2 = coordinator.request(
                model_id=ollama_model_id, 
                prompt_text=test_prompt_2, 
                system_prompt_text=test_system_prompt, 
                game_id=example_game_id, 
                agent_name="AgentGermany", 
                phase_str=example_phase_str,
                request_identifier="OllamaTest-2"
            )
            
            # Results will be exceptions if llm.get_async_model fails (e.g. model not found)
            response1, response2 = await asyncio.gather(task1, task2, return_exceptions=True)

            if isinstance(response1, Exception):
                logger.error(f"OllamaTest-1 failed: {response1}")
            else:
                logger.info(f"OllamaTest-1 Response: {response1[:150]}...")

            if isinstance(response2, Exception):
                logger.error(f"OllamaTest-2 failed: {response2}")
            else:
                logger.info(f"OllamaTest-2 Response: {response2[:150]}...")

        except Exception as e: # Catching broad exceptions for llm setup issues
            logger.error(f"An error occurred during Ollama Test Case 1 (likely model not found or Ollama server issue): {e}", exc_info=True)
        
        # --- Test Case 2: Non-local model (e.g., gpt-4o-mini if configured in llm) ---
        # This will bypass the serial_if_local lock.
        # Replace with a model you have configured for 'llm' that is not ollama/llamacpp
        # For this example, we'll use a placeholder that will likely cause UnknownModelError
        # if not actually configured, demonstrating the flow.
        non_local_model_id = "gpt-4o-mini" # or "gpt-3.5-turbo" or any other non-ollama/llamacpp model
        
        try:
            logger.info(f"--- Test Case 2: Non-Local Model call ({non_local_model_id}) ---")
            # This call should not wait for the _local_lock
            response3 = await coordinator.request(
                model_id=non_local_model_id, 
                prompt_text="What is a large language model?", 
                system_prompt_text=test_system_prompt,
                game_id=example_game_id,
                agent_name="Researcher",
                phase_str="F1902M",
                request_identifier="NonLocalTest-1"
            )
            logger.info(f"NonLocalTest-1 Response: {response3[:150]}...")
        except llm.UnknownModelError:
            logger.warning(f"Test Case 2: Model '{non_local_model_id}' is unknown. This is expected if not configured with 'llm'.")
        except Exception as e:
            logger.error(f"An error occurred during Non-Local Model Test Case 2: {e}", exc_info=True)

        # --- Test Case 3: JSON Parsing Call ---
        json_prompt = "Provide a JSON object with two keys: 'city' and 'country'. For Paris and France."
        try:
            logger.info(f"--- Test Case 3: JSON Parsing with Ollama model ({ollama_model_id}) ---")
            json_result = await coordinator.call_llm_with_json_parsing(
                model_id=ollama_model_id,
                prompt=json_prompt,
                system_prompt="Respond strictly in JSON format.",
                request_identifier="JsonTest-Ollama",
                expected_json_fields=["city", "country"],
                game_id=example_game_id,
                agent_name="JsonAgent",
                phase_str="W1901A",
                response_type="json_query",
                log_to_file_path=f"{example_game_id}_json_log.txt" # Example file logging
            )
            if json_result.success:
                logger.info(f"JsonTest-Ollama Parsed JSON: {json_result.parsed_json}")
            else:
                logger.error(f"JsonTest-Ollama Failed: {json_result.error_message}. Raw: {json_result.raw_response[:150]}...")
        except Exception as e:
             logger.error(f"An error occurred during JSON Parsing Test Case 3: {e}", exc_info=True)
        
        logger.info("--- Example run finished. Check 'ai_diplomacy_usage.db' for usage logs. ---")
        logger.info("If Ollama or other models were not available, errors would be logged for those specific calls.")

    asyncio.run(run_example())
    logger.info("llm_coordinator.py example usage complete.")



================================================
File: llm_utils.py
================================================
import os
import logging
import re
import json
from typing import Optional, Dict

import json_repair
import json5

logger = logging.getLogger(__name__) # Removed comment: # Logger for this module

# Constants for relationship extraction
REL_KEYS = ('updated_relationships', 'relationships', 'relationship_updates')

# Renamed from _load_prompt_file and moved from agent.py
def load_prompt_file(filename: str, base_prompts_dir: Optional[str] = None) -> Optional[str]:
    """
    Loads a prompt template from the specified prompts directory.

    Args:
        filename: The name of the prompt file (e.g., 'system_prompt.txt').
        base_prompts_dir: Optional. The base directory where 'prompts' subdirectory is located.
                          If None, it defaults to the 'prompts' subdirectory within the
                          directory of this utility file (llm_utils.py).
    Returns:
        The content of the file as a string, or None if an error occurs.
    """
    try:
        if base_prompts_dir:
            prompts_dir = os.path.join(base_prompts_dir, 'prompts')
        else:
            # Default to 'prompts' dir relative to this file (llm_utils.py)
            current_dir = os.path.dirname(os.path.abspath(__file__))
            prompts_dir = os.path.join(current_dir, 'prompts')

        filepath = os.path.join(prompts_dir, filename)
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        logger.error(f"Prompt file not found: {filepath}")
        return None
    except Exception as e:
        logger.error(f"Error loading prompt file {filepath}: {e}")
        return None

# Moved from DiplomacyAgent class in agent.py
def clean_json_text(text: str) -> str:
    """Clean common JSON formatting issues from LLM responses."""
    if not text:
        return text
            
    # Remove trailing commas
    text = re.sub(r',\s*}', '}', text)
    text = re.sub(r',\s*]', ']', text)
    
    # Fix newlines before JSON keys
    text = re.sub(r'\n\s+"(\w+)"\s*:', r'"\1":', text)
    
    # Replace single quotes with double quotes for keys
    text = re.sub(r"'(\w+)'\s*:", r'"\1":', text)
    
    # Remove comments (if any)
    text = re.sub(r'//.*$', '', text, flags=re.MULTILINE)
    text = re.sub(r'/\*.*?\*/', '', text, flags=re.DOTALL)
    
    # Fix unescaped quotes in values (basic attempt)
    # This is risky but sometimes helps with simple cases
    text = re.sub(r':\s*"([^"]*)"([^",}\]]+)"', r': "\1\2"', text)
    
    # Remove any BOM or zero-width spaces
    text = text.replace('\ufeff', '').replace('\u200b', '')
    
    return text.strip()

# Moved from DiplomacyAgent class in agent.py and adapted
def extract_json_from_text(text: str, logger_param: logging.Logger, identifier_for_log: str = "") -> Dict:
    """
    Extract and parse JSON from text, handling common LLM response formats.

    Args:
        text: The input string from which to extract JSON.
        logger_param: The logger instance to use for logging.
        identifier_for_log: A string to prepend to log messages for context (e.g., power name).

    Returns:
        A dictionary parsed from the JSON, or an empty dictionary if parsing fails.
    """
    if not text or not text.strip():
        logger_param.warning(f"{identifier_for_log} Empty text provided to JSON extractor")
        return {}
            
    original_text = text
    
    # Preprocessing
    text = re.sub(r'\n\s+"(\w+)"\s*:', r'"\1":', text)
    problematic_patterns = [
        'negotiation_summary', 'relationship_updates', 'updated_relationships',
        'order_summary', 'goals', 'relationships', 'intent'
    ]
    for pattern_key in problematic_patterns: # Renamed pattern to pattern_key to avoid conflict
        text = re.sub(fr'\n\s*"{pattern_key}"', f'"{pattern_key}"', text)
    
    patterns = [
        r"```\s*\{\{\s*(.*?)\s*\}\}\s*```",
        r"```(?:json)?\s*\n(.*?)\n\s*```",
        r"PARSABLE OUTPUT:\s*(\{.*?\})",
        r"JSON:\s*(\{.*?\})",
        r"(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})",
        r"`(\{.*?\})`",
    ]
    
    for pattern_idx, current_pattern in enumerate(patterns): # Renamed pattern to current_pattern
        matches = re.findall(current_pattern, text, re.DOTALL)
        if matches:
            for match_idx, match in enumerate(matches):
                json_text = match.strip()
                
                try:
                    cleaned = clean_json_text(json_text) # Use standalone clean_json_text
                    result = json.loads(cleaned)
                    logger_param.debug(f"{identifier_for_log} Successfully parsed JSON with pattern {pattern_idx}, match {match_idx}")
                    return result
                except json.JSONDecodeError as e_initial:
                    logger_param.debug(f"{identifier_for_log} Standard JSON parse failed: {e_initial}")
                    
                    try:
                        cleaned_match_candidate = json_text
                        cleaned_match_candidate = re.sub(r'\s*([A-Z][\w\s,]*?\.(?:\s+[A-Z][\w\s,]*?\.)*)\s*(?=[,\}\]])', '', cleaned_match_candidate)
                        cleaned_match_candidate = re.sub(r'\s*([A-Z][\w\s,]*?\.(?:\s+[A-Z][\w\s,]*?\.)*)\s*(?=\s*\}\s*$)', '', cleaned_match_candidate)
                        cleaned_match_candidate = re.sub(r'\n\s+"(\w+)"\s*:', r'"\1":', cleaned_match_candidate)
                        cleaned_match_candidate = re.sub(r',\s*}', '}', cleaned_match_candidate)
                        for pp_key in problematic_patterns: # Renamed pattern to pp_key
                            cleaned_match_candidate = cleaned_match_candidate.replace(f'\n  "{pp_key}"', f'"{pp_key}"')
                        cleaned_match_candidate = re.sub(r"'(\w+)'\s*:", r'"\1":', cleaned_match_candidate)

                        if cleaned_match_candidate != json_text:
                            logger_param.debug(f"{identifier_for_log} Surgical cleaning applied. Attempting to parse modified JSON.")
                            return json.loads(cleaned_match_candidate)
                    except json.JSONDecodeError as e_surgical:
                        logger_param.debug(f"{identifier_for_log} Surgical cleaning didn't work: {e_surgical}")
                
                try:
                    result = json5.loads(json_text)
                    logger_param.debug(f"{identifier_for_log} Successfully parsed with json5")
                    return result
                except Exception as e:
                    logger_param.debug(f"{identifier_for_log} json5 parse failed: {e}")
                
                try:
                    result = json_repair.loads(json_text)
                    logger_param.debug(f"{identifier_for_log} Successfully parsed with json-repair")
                    return result
                except Exception as e:
                    logger_param.debug(f"{identifier_for_log} json-repair failed: {e}")
    
    try:
        start = text.find('{')
        end = text.rfind('}') + 1
        if start != -1 and end > start:
            potential_json = text[start:end]
            for parser_name, parser_func in [
                ("json", json.loads),
                ("json5", json5.loads),
                ("json_repair", json_repair.loads)
            ]:
                try:
                    cleaned = clean_json_text(potential_json) if parser_name == "json" else potential_json
                    result = parser_func(cleaned)
                    logger_param.debug(f"{identifier_for_log} Fallback parse succeeded with {parser_name}")
                    return result
                except Exception as e:
                    logger_param.debug(f"{identifier_for_log} Fallback {parser_name} failed: {e}")
            
            try:
                cleaned_text = re.sub(r'[^{}[\]"\',:.\d\w\s_-]', '', potential_json)
                text_fixed = re.sub(r"'([^']*)':", r'"\1":', cleaned_text)
                text_fixed = re.sub(r': *\'([^\']*)\'', r': "\1"', text_fixed)
                result = json.loads(text_fixed)
                logger_param.debug(f"{identifier_for_log} Aggressive cleaning worked")
                return result
            except json.JSONDecodeError:
                pass # logger_param.debug(f"{identifier_for_log} Aggressive cleaning failed")
                
    except Exception as e:
        logger_param.debug(f"{identifier_for_log} Fallback extraction failed: {e}")
    
    try:
        result = json_repair.loads(text)
        logger_param.warning(f"{identifier_for_log} Last resort json-repair succeeded")
        return result
    except Exception as e:
        logger_param.error(f"{identifier_for_log} All JSON extraction attempts failed. Original text: {original_text[:500]}... Error: {e}")
        return {}

def extract_relationships(data) -> Optional[Dict[str, str]]:
    """
    Extract relationships from LLM response data, handling various key names.
    
    Args:
        data: Parsed JSON data from LLM response
        
    Returns:
        Dictionary of relationships if found, None otherwise
    """
    if not isinstance(data, dict):
        return None
        
    for key in REL_KEYS:
        if key in data and isinstance(data[key], dict):
            return data[key]
    return None

def extract_goals(data) -> Optional[list]:
    """
    Extract goals from LLM response data, handling various key names.
    
    Args:
        data: Parsed JSON data from LLM response
        
    Returns:
        List of goals if found, None otherwise
    """
    if not isinstance(data, dict):
        return None
        
    # Check various possible key names for goals
    goal_keys = ('updated_goals', 'goals', 'goal_updates')
    for key in goal_keys:
        if key in data and isinstance(data[key], list):
            return data[key]
    return None



================================================
File: llms.txt
================================================
# AI Diplomacy Codebase Analysis (Core Logic Modules) - Comprehensive Update

This document provides an analysis of key Python modules within the `ai_diplomacy` package, focusing on their roles, functions, interdependencies, and implementation status.

**Last Major Update**: January 2025 - Added diary system details, consolidation logic, and comprehensive agent memory management.

---

## 1. Module Status

### COMPLETED MODULES:

#### 1.1. `game_history.py` (COMPLETE)
**Goal:** To structure, store, and retrieve the historical events of a Diplomacy game phase by phase, including messages, plans, orders, and results.
**Status:** Fully implemented and operational.

*Key Components:*
* `DiplomacyGraph`: Represents map territory connectivity with support for unit-specific movement rules (Army vs Fleet).
* `bfs_shortest_path`: Finds shortest path from a starting territory to any territory matching criteria.
* `bfs_nearest_adjacent`: Finds shortest path to a territory adjacent to any territory in a target set.
* `build_diplomacy_graph`: Constructs the graph representation from the game map.

#### 1.2. Core Game Management Modules (NEW - Refactored from `lm_game.py`)
These modules were created by refactoring core logic out of `lm_game.py` to improve modularity and maintainability.

*   `game_config.py`: Manages game configuration parameters derived from arguments and provides centralized access to paths and settings.
*   `logging_setup.py`: Centralizes application-wide logging configuration, including console and file handlers.
*   `agent_manager.py`: Handles the lifecycle (creation, model assignment, initialization, storage) of `DiplomacyAgent` instances.
*   `game_orchestrator.py`: Orchestrates the main game loop, phase transitions, agent actions (planning, negotiation, orders), and game state progression.
*   `game_results.py`: Manages the processing and saving of final game data, including game state, history, and agent manifestos.
*   `phase_summary.py`: (Refactored) Provides tools for generating detailed game phase summaries (e.g., `PhaseSummaryGenerator` used by the orchestrator).

#### 1.3. `phase_summary.py` (COMPLETE, in lm_game.py)
**Goal:** Generate concise, structured summaries of each game phase for post-game analysis.
**Status:** Fully implemented via `phase_summary_callback` in `lm_game.py`. (Note: This entry describes the *original* state. The module has been refactored as listed above).

**Key Components:**
* Structured summaries with:
  * Current board state (sorted by supply center count)
  * Successful moves by power
  * Unsuccessful moves by power with failure reasons
  * Optional sections for other move types

#### 1.4. `agent.py` (COMPLETE WITH ENHANCED MEMORY SYSTEM)
**Goal:** To maintain stateful agent representation with personality, goals, relationships, and sophisticated memory management.
**Status:** Fully implemented with dual memory system (journal + diary) and yearly consolidation.

**Key Components:**
* `DiplomacyAgent` class with:
  * `power_name`: The power this agent represents
  * `goals`: List of strategic goals, dynamically updated each phase
  * `relationships`: Dict tracking relationships (Enemy/Unfriendly/Neutral/Friendly/Ally) with other powers
  * `private_journal`: Unstructured internal logs for debugging/events
  * `private_diary`: Structured, phase-prefixed strategic summaries - THE MAIN MEMORY SYSTEM
  * `client`: BaseModelClient instance for LLM interactions
  * Power-specific system prompts loaded from `prompts/{power_name}_system_prompt.txt`

**Memory System Architecture:**
1. **Private Journal** (Less Important):
   * Simple string entries via `add_journal_entry()`
   * Used for: "Goals updated", "Relationship changed", "Message sent", etc.
   * Not directly fed to LLMs
   * More like internal debug logs

2. **Private Diary** (Critical for Decision Making):
   * Structured entries with phase prefix via `add_diary_entry(entry, phase)`
   * Three types of diary entries generated each phase:
     - **Negotiation Diary** (`generate_negotiation_diary_entry`): Analyzes messages, updates relationships
     - **Order Diary** (`generate_order_diary_entry`): Records strategic reasoning behind orders
     - **Phase Result Diary** (`generate_phase_result_diary_entry`): Analyzes outcomes, detects betrayals
   * Fed to LLMs via `format_private_diary_for_prompt(max_entries=40)`
   * **Yearly Consolidation** (`consolidate_year_diary_entries`):
     - Triggered 2 years after a given year (e.g., in S1903M, consolidate 1901)
     - Uses Gemini Flash to summarize all entries from a year into one concise entry
     - Replaces individual entries with `[CONSOLIDATED 1901] summary...`
     - Prevents context bloat while preserving key memories

**Advanced JSON Parsing:**
* `_extract_json_from_text`: Multi-strategy parser handling various LLM output formats
  * Handles ```json blocks, {{...}} blocks, PARSABLE OUTPUT: formats
  * Uses json5 and json_repair as fallbacks
  * Aggressive cleaning for common LLM formatting issues
  * Returns empty dict on failure rather than crashing

**State Update System:**
* `analyze_phase_and_update_state`: Async method that:
  * Uses phase summaries and board state
  * Updates goals based on game evolution
  * Adjusts relationships based on actions (not just words)
  * Validates all updates with allowed values
  * Has robust error handling with fallback to current state

**Integration Points:**
* Diary provides historical context for all LLM calls
* Relationships influence negotiation tone and alliance decisions
* Goals drive strategic planning and order generation
* Power-specific prompts shape agent personality
* All LLM interactions logged via `utils.log_llm_response`

#### 1.5. `negotiations.py` (COMPLETE)
**Goal:** To orchestrate the communication phase among active AI powers.
**Status:** Fully implemented and integrated with DiplomacyAgent state.
**Note:** Relies heavily on `prompts/conversation_instructions.txt` to guide LLMs in generating correctly formatted messages for parsing.

#### 1.6. `planning.py` (COMPLETE)
**Goal:** To allow each AI power to generate a high-level strategic directive or plan.
**Status:** Fully implemented and integrated with DiplomacyAgent state.

#### 1.7. `utils.py` (COMPLETE)
**Goal:** To provide common utility functions used across other AI diplomacy modules.
**Status:** Fully implemented.

#### 1.8. `clients.py` (COMPLETE)
**Goal:** To abstract and manage interactions with various LLM APIs.
**Status:** Fully implemented with agent state integration (including personality, goals, relationships, and the new `private_diary` for summarized history). It now also leverages `possible_order_context.py` for richer order details in prompts.
**Note:** Uses various files in `prompts/` (e.g., `context_prompt.txt`, `order_instructions.txt`, `negotiation_diary_prompt.txt`, `order_diary_prompt.txt`) to structure LLM requests. `context_prompt.txt` has been updated to use `agent_private_diary` for history and a more structured `{possible_orders}` section generated by `possible_order_context.generate_rich_order_context`.

#### 1.9. `initialization.py` (NEWLY ADDED & COMPLETE)
**Goal:** To perform the initial LLM-driven setup of an agent's goals and relationships at the very start of the game (Spring 1901).
**Status:** Fully implemented and integrated into `lm_game.py`.

**Key Components:**
* `initialize_agent_state_ext(agent: DiplomacyAgent, game: Game, game_history: GameHistory, log_file_path: str)`: An asynchronous function that:
    *   Constructs a specific prompt tailored for Spring 1901, asking for initial goals and relationships.
    *   Utilizes the agent's client (`agent.client`) and the `run_llm_and_log` utility for the LLM interaction.
    *   Parses the JSON response using the agent's `_extract_json_from_text` method.
    *   Directly updates the `agent.goals` and `agent.relationships` attributes with the LLM's suggestions or defaults if parsing fails.

**Integration Points:**
*   Called once per agent from `lm_game.py` immediately after the `DiplomacyAgent` object is instantiated and before the main game loop begins.

#### 1.10. `possible_order_context.py` (COMPLETE)
**Goal:** To generate rich, strategic context about possible orders including pathfinding and territory analysis.
**Status:** Fully implemented and integrated into order generation prompts.

**Key Components:**
* `build_diplomacy_graph`: Creates adjacency graph with unit-specific movement rules
* `bfs_shortest_path`: Finds shortest paths considering unit movement restrictions
* `get_nearest_enemy_units`: Identifies closest threats using BFS
* `get_nearest_uncontrolled_scs`: Finds expansion opportunities
* `get_adjacent_territory_details`: Analyzes neighboring territories and support possibilities
* `generate_rich_order_context`: Main function creating structured XML context for each orderable unit

**Integration:**
* Called by `prompt_constructor.py` to enhance order generation prompts
* Provides strategic insights like "nearest enemy 3 moves away" or "undefended SC 2 territories north"

#### 1.11. `prompt_constructor.py` (COMPLETE)
**Goal:** To centralize and standardize prompt construction for all LLM interactions.
**Status:** Fully implemented, replacing scattered prompt building logic.

**Key Functions:**
* `build_context_prompt`: Creates comprehensive game context including:
  * Board state, unit positions, supply centers
  * Power-specific goals and relationships
  * Recent game history from agent's diary
  * Strategic analysis from `possible_order_context`
* `construct_order_generation_prompt`: Specialized for order generation with:
  * Full context from `build_context_prompt`
  * Detailed possible orders with strategic annotations
  * Order validation rules and format requirements

#### 1.12. `narrative.py` (PLACEHOLDER/FUTURE)
**Goal:** To generate narrative descriptions of game events for visualization/entertainment.
**Status:** Referenced in imports but not yet implemented.
**Potential Features:**
* Convert dry game events into dramatic narratives
* Generate "news reports" of battles and diplomatic developments
* Create power-specific propaganda/spin on events

---

## 2. Integration Points

The following connections have been established:

1. **Initial Agent Setup (New)**:
   * `lm_game.py` calls `initialization.py`'s `initialize_agent_state_ext` for each agent. This function uses an LLM call to populate the agent's initial `goals` and `relationships` before the main game loop and other agent interactions commence.

2. **Agent State → Context Building**
   * `BaseModelClient.build_context_prompt` in `clients.py` incorporates the agent's current `goals`, `relationships`, and the concise `agent_private_diary` for historical context.
   * It also calls `possible_order_context.generate_rich_order_context` to provide a detailed and strategically relevant breakdown of possible orders, replacing a simpler list.
   * `prompts/context_prompt.txt` is formatted to accept these inputs, including the structured possible orders and the agent's private diary.

3. **Agent State → Negotiations**
   * Agent's personality, goals, and relationships influence message generation
   * Relationships are updated based on negotiation context and results

4. **Robust LLM Interaction**
   * Implemented multi-strategy JSON extraction to handle various LLM response formats
   * Added case-insensitive validation for power names and relationship statuses
   * Created fallback mechanisms for all LLM interactions

5. **Error Recovery**
   * Added defensive programming throughout agent state updates
   * Implemented progressive fallback strategies for parsing LLM outputs
   * Used intelligent defaults to maintain consistent agent state

---

## 3. Main Game Loop Flow (`lm_game.py`)

The main game loop orchestrates all components in a sophisticated async flow:

1. **Initialization Phase**:
   * Create `DiplomacyAgent` instances for each power
   * Load power-specific system prompts
   * Run `initialize_agent_state_ext` concurrently for all agents
   * Set up logging infrastructure

2. **Per-Phase Flow** (Movement phases only for negotiations):
   * **Negotiations** (if enabled):
     - Round-robin message generation via `conduct_negotiations`
     - Async generation of messages considering relationships
     - Updates to `game_history` with all messages
   * **Planning** (if enabled):
     - Strategic directive generation via `planning_phase`
     - Considers current goals and game state
   * **Diary Generation** (Negotiation):
     - Each agent generates negotiation diary entry
     - Relationships may be updated based on messages
   * **Order Generation**:
     - Concurrent order generation for all powers
     - Rich context from `possible_order_context`
     - Validation and fallback logic
   * **Order Diary**:
     - Strategic reasoning recorded for chosen orders
   * **Phase Processing**:
     - Orders executed by Diplomacy engine
     - Custom phase summary generated
   * **Phase Result Diary**:
     - Analysis of outcomes vs. expectations
     - Betrayal detection
   * **State Updates**:
     - Goals and relationships updated based on results
   * **Diary Consolidation** (every 2 years):
     - Old diary entries summarized to manage context

3. **Error Handling**:
   * Comprehensive error tracking in `model_error_stats`
   * All LLM calls wrapped with retry logic
   * Fallback orders for any failures

## 4. Future Work

1. **Enhanced Memory Management**
   * Implement selective memory retrieval based on relevance
   * Add episodic memory for specific important events
   * Create power-specific memory strategies

2. **Advanced Negotiation Strategies**
   * Implement deception detection algorithms
   * Add negotiation pattern recognition
   * Create coalition formation logic

3. **Performance Optimizations**
   * Cache common pathfinding results
   * Implement speculative order generation
   * Add early termination for losing positions

4. **Analysis Tools**
   * Post-game relationship evolution visualization
   * Betrayal/alliance pattern analysis
   * Goal achievement tracking

5. **UI Integration**
   * Real-time diary viewer
   * Relationship graph visualization
   * Goal tracking dashboard

---

## 5. Dependency Map (Comprehensive Update)

```ascii
                              +----------------+
                              |  lm_game.py    |
                              |  (Main Loop)   |
                              +-------+--------+
                                      |
        +-----------------------------+-----------------------------+
        |                             |                             |
        v                             v                             v
+-------+--------+            +-------+--------+            +-------+--------+
|initialization.py|           |  agent.py      |           |game_history.py |
|(Initial Setup)  |           |(State & Memory)|           |(Phase Storage) |
+----------------+            +-------+--------+            +----------------+
                                      |
        +-----------------------------+-----------------------------+
        |                             |                             |
        v                             v                             v
+-------+--------+            +-------+--------+            +-------+--------+
|negotiations.py |            | planning.py    |           | utils.py       |
|(Messages)      |            |(Strategy)      |           |(Logging/Errors)|
+-------+--------+            +-------+--------+            +-------+--------+
        |                             |                             |
        +-----------------------------+-----------------------------+
                                      |
                              +-------v--------+
                              | clients.py     |
                              |(LLM Interface) |
                              +-------+--------+
                                      |
        +-----------------------------+-----------------------------+
        |                             |                             |
        v                             v                             v
+-------+--------+            +-------+--------+            +-------+--------+
|prompt_constructor|          |possible_order_ |           |   prompts/     |
|(Prompt Building)|           |context.py      |           |(Templates)     |
+----------------+            |(BFS/Analysis)  |            +----------------+
                              +----------------+
```

**Key Relationships:**
* `lm_game.py` orchestrates everything, managing the game loop and agent lifecycle
* `agent.py` is the central state holder, maintaining goals, relationships, and memories
* `clients.py` abstracts all LLM interactions with multiple provider support
* `prompt_constructor.py` and `possible_order_context.py` work together for rich prompts
* `utils.py` provides critical infrastructure for logging and error handling
* All async operations use `asyncio.gather` for maximum concurrency

**Current Integration Status:**
* All modules fully implemented and battle-tested
* Sophisticated error handling throughout
* Async architecture provides 5-10x performance improvement
* Memory management prevents context overflow
* Robust parsing handles various LLM output formats

**Recent Enhancements (January 2025):**
- Added comprehensive diary system with three entry types per phase
- Implemented yearly diary consolidation to manage context size
- Enhanced relationship tracking with ignored message detection
- Added phase result analysis for betrayal detection
- Integrated BFS pathfinding for strategic order context
- Created centralized prompt construction system
- Added power-specific system prompts for personality



================================================
File: logging_setup.py
================================================
import logging
import os
import sys # To get stdout for console handler
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from .game_config import GameConfig

class LLMVerboseFilter(logging.Filter): # Removed comment: # Define the custom filter
    def __init__(self, name="", verbose_llm_debug=False):
        super().__init__(name)
        self.verbose_llm_debug = verbose_llm_debug

    def filter(self, record):
        if not self.verbose_llm_debug and record.levelno == logging.INFO:
            # Check logger name or message content for typical LLM verbose logs
            msg_lower = record.getMessage().lower()
            is_llm_log = "llm_coordinator" in record.name or \
                         "prompt:" in msg_lower or \
                         "response:" in msg_lower or \
                         "raw_response" in msg_lower or \
                         "full_prompt" in msg_lower
            
            if is_llm_log:
                # Truncate the message
                original_msg = record.getMessage() # Get the fully formatted message
                record.msg = original_msg[:150] + "... (set verbose_llm_debug=True for full details)"
                record.args = () # Clear args as msg is now pre-formatted
        return True

def setup_logging(config: 'GameConfig') -> None: # verbose_llm_debug is part of config
    """
    Sets up logging for the application.

    Configures a root logger with a console handler and optionally a file handler.
    Also sets the log level for noisy third-party libraries.

    Args:
        config: The GameConfig instance containing logging parameters like
                log_level, general_log_path, and log_to_file.
    """
    try:
        numeric_log_level = getattr(logging, config.log_level.upper(), None)
        if not isinstance(numeric_log_level, int):
            logging.warning(f"Invalid log level: {config.log_level}. Defaulting to INFO.")
            numeric_log_level = logging.INFO
    except AttributeError:
        logging.error(f"Log level {config.log_level} not found. Defaulting to INFO.")
        numeric_log_level = logging.INFO
        
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') # Removed comment: # Basic formatter

    root_logger = logging.getLogger() # Removed comment: # Get the root logger
    root_logger.setLevel(numeric_log_level)
    
    # Remove any existing handlers to avoid duplicate logs if this is called multiple times
    # (though ideally it's called once)
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
        handler.close()

    console_handler = logging.StreamHandler(sys.stdout) # Removed comment: # Console Handler
    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)
    logging.info(f"Console logging configured at level {config.log_level}.")

    if config.log_to_file: # Removed comment: # File Handler (if enabled)
        try:
            # Ensure the directory for the log file exists
            log_dir = os.path.dirname(config.general_log_path)
            if log_dir and not os.path.exists(log_dir): # Check if log_dir is not empty
                os.makedirs(log_dir, exist_ok=True)
            
            file_handler = logging.FileHandler(config.general_log_path, mode='a', encoding='utf-8')
            file_handler.setFormatter(formatter)
            root_logger.addHandler(file_handler)
            logging.info(f"File logging configured at level {config.log_level}, path: {config.general_log_path}")
        except Exception as e:
            logging.error(f"Failed to configure file logging to {config.general_log_path}: {e}", exc_info=True)
            # Continue with console logging
    else:
        logging.info("File logging is disabled by configuration.")

    # Reduce verbosity of noisy libraries
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    # Add any other libraries that are too verbose
    # logging.getLogger("another_library").setLevel(logging.WARNING)

    logging.info(f"Root logger level set to {logging.getLevelName(root_logger.level)}")
    # Test message
    # logging.debug("Debug logging test - should only appear if level is DEBUG")
    # logging.info("Info logging test - should appear if level is INFO or DEBUG")

    # Apply the LLMVerboseFilter if verbose_llm_debug is False
    if not config.verbose_llm_debug:
        llm_filter = LLMVerboseFilter(verbose_llm_debug=False)
        
        # Apply to specific loggers known for verbosity or to root logger's handlers
        # Applying to handlers of the root logger ensures it affects all logs passing through them.
        # Alternatively, apply to specific loggers:
        # logging.getLogger("ai_diplomacy.llm_coordinator").addFilter(llm_filter)
        # logging.getLogger("ai_diplomacy.agent").addFilter(llm_filter) # If agent logs full prompts/responses at INFO
        
        # Add filter to console handler to affect what's printed on screen at INFO level
        # This is often the primary concern for reducing verbosity.
        # File logs might still retain full detail if desired, or filter can be added there too.
        for handler in root_logger.handlers:
            if isinstance(handler, logging.StreamHandler) and handler.stream == sys.stdout: # Target console handler
                logging.info("Applying LLMVerboseFilter to console handler as verbose_llm_debug is False.")
                handler.addFilter(llm_filter)

if __name__ == '__main__':
    # Example Usage for testing logging_setup.py directly
    
    # Mock GameConfig for testing
    class MockArgs:
        def __init__(self, log_level="DEBUG", game_id="test_log_game", log_to_file=True, log_dir=None):
            self.log_level = log_level
            self.game_id_prefix = "test_log"
            self.game_id = game_id # if None, GameConfig will generate one
            self.current_datetime_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.log_to_file = log_to_file
            # Allow log_dir to be None to test default path generation in GameConfig
            self.log_dir = log_dir
            # Add other attributes GameConfig expects from args, with defaults
            self.power_name = None
            self.model_id = None
            self.num_players = 7
            self.perform_planning_phase = False
            self.num_negotiation_rounds = 3
            self.negotiation_style = "simultaneous"
            self.fixed_models = None
            self.randomize_fixed_models = False
            self.exclude_powers = None
            self.max_years = None


    # Need to import GameConfig for the test, ensure path is correct for direct run
    # This might require adjusting PYTHONPATH if run directly from ai_diplomacy folder
    
    # Simplified import for direct script execution, assuming GameConfig is in the same directory
    # or PYTHONPATH is set up. For actual use, the relative import `.game_config` is correct.
    # We need a definition of GameConfig that includes verbose_llm_debug for the test.
    # from .game_config import GameConfig # This is for package use

    # Minimal mock for GameConfig to test logging_setup.py directly
    class MinimalGameConfig:
        def __init__(self, log_level="DEBUG", game_id="test_log_game", log_to_file=True, log_dir=None, verbose_llm_debug=False):
            self.log_level = log_level
            self.game_id = game_id
            self.log_to_file = log_to_file
            self.general_log_path = os.path.join(log_dir if log_dir else ".", f"{game_id}_general.log")
            self.verbose_llm_debug = verbose_llm_debug # Add the new attribute

    print("--- Testing logging_setup.py ---")

    # Test 1: Logging to file and console, verbose_llm_debug = False
    print("\n--- Test 1: Logging (DEBUG level), verbose_llm_debug = False ---")
    config1 = MinimalGameConfig(log_level="DEBUG", game_id="log_test_verbose_false", verbose_llm_debug=False)
    setup_logging(config1)
    logging.getLogger("ai_diplomacy.llm_coordinator").info("LLM Coordinator Prompt: This is a very long prompt...")
    logging.getLogger("ai_diplomacy.other_module").info("Other Info: Regular message.")
    logging.getLogger("ai_diplomacy.llm_coordinator").debug("LLM Coordinator DEBUG: Full details here.")


    # Test 2: Logging to file and console, verbose_llm_debug = True
    print("\n--- Test 2: Logging (DEBUG level), verbose_llm_debug = True ---")
    config2 = MinimalGameConfig(log_level="DEBUG", game_id="log_test_verbose_true", verbose_llm_debug=True)
    setup_logging(config2)
    logging.getLogger("ai_diplomacy.llm_coordinator").info("LLM Coordinator Prompt: This is a very long prompt...")
    logging.getLogger("ai_diplomacy.other_module").info("Other Info: Regular message.")
    logging.getLogger("ai_diplomacy.llm_coordinator").debug("LLM Coordinator DEBUG: Full details here.")

    # Test 3: Logging at INFO level, verbose_llm_debug = False
    print("\n--- Test 3: Logging (INFO level), verbose_llm_debug = False ---")
    config3 = MinimalGameConfig(log_level="INFO", game_id="log_test_info_verbose_false", verbose_llm_debug=False)
    setup_logging(config3)
    logging.getLogger("ai_diplomacy.llm_coordinator").info("LLM Coordinator Prompt: This is a very long prompt...")
    logging.getLogger("ai_diplomacy.llm_coordinator").debug("LLM Coordinator DEBUG: This should not appear.")


    print("\n--- logging_setup.py test complete ---")



================================================
File: narrative.py
================================================
"""Generate engaging narrative summaries and transparently patch the Diplomacy
Game engine to use them.

Usage: simply import `ai_diplomacy.narrative` *before* the game loop starts
(e.g. at the top of `lm_game.py`).  Import side-effects monkey-patch
`diplomacy.engine.game.Game._generate_phase_summary` so that:

1. The original (statistical) summary logic still runs.
2. The returned text is stored in `GamePhaseData.statistical_summary`.
3. A short narrative is produced via a configured LLM and saved as the main
   `.summary`.
"""
from __future__ import annotations

import logging
import os
from typing import Callable
import llm # Import the llm library

from diplomacy.engine.game import Game

LOGGER = logging.getLogger(__name__)
 
# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------
# AI_DIPLOMACY_NARRATIVE_MODEL can be set to a specific llm-compatible model ID.
# If not set, it will attempt to use the primary model from lm_game.py arguments.
DEFAULT_NARRATIVE_MODEL_ID = os.getenv("AI_DIPLOMACY_NARRATIVE_MODEL")

# Store the model ID passed from lm_game.py (or other entry point)
# This needs to be set by the main script, e.g., lm_game.py, after parsing args.
# For now, we make it a module-level variable that can be updated.
NARRATIVE_MODEL_ID_FROM_ARGS: str | None = None 

# ---------------------------------------------------------------------------
# Helper to call the model synchronously (though llm calls can be async)
# ---------------------------------------------------------------------------

def get_narrative_model_id() -> str | None:
    """Determines the model ID to use for narrative generation."""
    if DEFAULT_NARRATIVE_MODEL_ID: # Env var takes precedence
        return DEFAULT_NARRATIVE_MODEL_ID
    if NARRATIVE_MODEL_ID_FROM_ARGS: # Then model from script args
        return NARRATIVE_MODEL_ID_FROM_ARGS
    LOGGER.warning("Narrative model ID not configured via env var or script arguments. Narrative generation might fail or use llm default.")
    return None # Or a very basic fallback model if llm has one by default without ID

def _call_llm_for_narrative(statistical_summary: str, phase_key: str) -> str:
    """Return a 2–4 sentence spectator-friendly narrative using the llm library."""
    
    model_id_to_use = get_narrative_model_id()

    if not model_id_to_use:
        LOGGER.warning("No model ID available for narrative generation. Returning stub.")
        return "(Narrative generation disabled – model not configured)."

    try:
        model = llm.get_model(model_id_to_use, options={"host": os.environ.get("OLLAMA_HOST")})
    except llm.UnknownModelError:
        LOGGER.error(f"Narrative generation failed: Unknown model '{model_id_to_use}'. Check llm configuration and installed plugins.")
        return f"(Narrative generation failed - unknown model: {model_id_to_use})"
    except Exception as e:
        LOGGER.error(f"Narrative generation failed: Error loading model '{model_id_to_use}': {e}")
        return f"(Narrative generation failed - model load error: {model_id_to_use})"

    system_prompt = (
        "You are an energetic e-sports commentator narrating a game of Diplomacy. "
        "Turn the provided phase recap into a concise, thrilling story (max 4 sentences). "
        "Highlight pivotal moves, supply-center swings, betrayals, and momentum shifts."
    )
    user_prompt = f"PHASE {phase_key}\n\nSTATISTICAL SUMMARY:\n{statistical_summary}\n\nNow narrate this phase for spectators."

    try:
        # Using prompt() for synchronous call as this is part of a patched synchronous method.
        # If this patch were async, await model.async_prompt() would be used.
        response = model.prompt(user_prompt, system=system_prompt)
        narrative_text = response.text()
        return narrative_text.strip()
    except Exception as exc:  # Broad – we only log and degrade gracefully
        LOGGER.error(f"Narrative generation failed with model '{model_id_to_use}': {exc}", exc_info=True)
        return f"(Narrative generation failed with model {model_id_to_use})"

# ---------------------------------------------------------------------------
# Patch _generate_phase_summary
# ---------------------------------------------------------------------------

_original_gps: Callable = Game._generate_phase_summary  # type: ignore[attr-defined]


def _patched_generate_phase_summary(self: Game, phase_key, summary_callback=None):  # type: ignore[override]
    # 1) Call original implementation → statistical summary
    statistical = _original_gps(self, phase_key, summary_callback)
    LOGGER.debug(f"[{phase_key}] Original summary returned: {statistical!r}")

    # 2) Persist statistical summary separately
    phase_data = None
    try:
        phase_data = self.get_phase_from_history(str(phase_key))
        if hasattr(phase_data, "statistical_summary"):
            LOGGER.debug(f"[{phase_key}] Assigning to phase_data.statistical_summary: {statistical!r}")
            phase_data.statistical_summary = statistical  # type: ignore[attr-defined]
        else:
            LOGGER.warning(f"[{phase_key}] phase_data object does not have attribute 'statistical_summary'. Type: {type(phase_data)}")
    except Exception as exc:
        LOGGER.warning("Could not retrieve phase_data or store statistical_summary for %s: %s", phase_key, exc)

    # 3) Generate narrative summary
    narrative = _call_llm_for_narrative(statistical, phase_key)

    # 4) Save narrative as the canonical summary
    try:
        if phase_data and hasattr(phase_data, 'summary'): # Check if phase_data exists and has summary attribute
            phase_data.summary = narrative  # type: ignore[attr-defined]
            self.phase_summaries[str(phase_key)] = narrative 
            LOGGER.debug(f"[{phase_key}] Narrative summary stored successfully.")
        elif phase_data:
            LOGGER.warning(f"[{phase_key}] phase_data exists but does not have attribute 'summary'. Cannot store narrative. Type: {type(phase_data)}")
        else:
             LOGGER.warning(f"[{phase_key}] Cannot store narrative summary because phase_data is None.")
    except Exception as exc:
        LOGGER.warning("Could not store narrative summary for %s: %s", phase_key, exc)

    return narrative

# Monkey-patch
Game._generate_phase_summary = _patched_generate_phase_summary  # type: ignore[assignment]

LOGGER.info("Game._generate_phase_summary patched with narrative generation using the llm library.")


================================================
File: negotiations.py
================================================
from dotenv import load_dotenv
import logging
import asyncio
from typing import Dict, TYPE_CHECKING

from diplomacy.engine.message import Message, GLOBAL

from .agent import DiplomacyAgent
# from .clients import load_model_client # Removed obsolete import
from .utils import gather_possible_orders # load_prompt is not used here anymore

if TYPE_CHECKING:
    from .game_history import GameHistory
    from diplomacy import Game

logger = logging.getLogger("negotiations")
logger.setLevel(logging.INFO)
logging.basicConfig(level=logging.INFO)

load_dotenv()


async def conduct_negotiations(
    game: 'Game',
    agents: Dict[str, DiplomacyAgent],
    game_history: 'GameHistory',
    model_error_stats: Dict[str, Dict[str, int]],
    log_file_path: str,
    max_rounds: int = 3,
):
    """
    Conducts a round-robin conversation among all non-eliminated powers.
    Each power can send up to 'max_rounds' messages, choosing between private
    and global messages each turn. Uses asyncio for concurrent message generation.
    """
    logger.info("Starting negotiation phase.")

    active_powers = [
        p_name for p_name, p_obj in game.powers.items() if not p_obj.is_eliminated()
    ]
    eliminated_powers = [
        p_name for p_name, p_obj in game.powers.items() if p_obj.is_eliminated()
    ]
    
    logger.info(f"Active powers for negotiations: {active_powers}")
    if eliminated_powers:
        logger.info(f"Eliminated powers (skipped): {eliminated_powers}")
    else:
        logger.info("No eliminated powers yet.")

    # We do up to 'max_rounds' single-message turns for each power
    for round_index in range(max_rounds):
        logger.info(f"Negotiation Round {round_index + 1}/{max_rounds}")
        
        # Prepare tasks for asyncio.gather
        tasks = []
        power_names_for_tasks = []

        for power_name in active_powers:
            if power_name not in agents:
                logger.warning(f"Agent for {power_name} not found in negotiations. Skipping.")
                continue
            agent = agents[power_name]
            # client = agent.client # Removed obsolete client logic

            possible_orders = gather_possible_orders(game, power_name)
            # if not possible_orders: # Keep allowing message generation even if no orders
            #     logger.info(f"No orderable locations for {power_name}; skipping message generation.")
            #     continue
            board_state = game.get_state()

            # Append the coroutine to the tasks list
            tasks.append(
                agent.generate_messages( # Call the new agent method
                    game=game,
                    board_state=board_state,
                    # power_name is self.power_name in agent method
                    possible_orders=possible_orders, # Pass for context
                    game_history=game_history,
                    current_phase=game.current_short_phase,
                    log_file_path=log_file_path,
                    active_powers=active_powers,
                    # agent_goals, agent_relationships, agent_private_diary_str are accessed via self in agent method
                )
            )
            power_names_for_tasks.append(power_name)
            logger.debug(f"Prepared generate_messages task for {power_name}.")

        # Run tasks concurrently if any were created
        if tasks:
            logger.debug(f"Running {len(tasks)} conversation tasks concurrently...")
            results = await asyncio.gather(*tasks, return_exceptions=True)
        else:
            logger.debug("No conversation tasks to run for this round.")
            results = []

        # Process results
        for i, result in enumerate(results):
            power_name = power_names_for_tasks[i]
            agent = agents[power_name] # Get agent again for journaling
            model_id_for_stats = agent.model_id # Get model_id for stats

            if isinstance(result, Exception):
                logger.error(f"Error getting conversation reply for {power_name} (model: {model_id_for_stats}): {result}", exc_info=result)
                model_error_stats.setdefault(model_id_for_stats, {}).setdefault("conversation_errors", 0)
                model_error_stats[model_id_for_stats]["conversation_errors"] += 1
                messages = [] # Treat as no messages on error
            elif result is None: # Handle case where agent method might return None on internal error (though it should return list)
                 logger.warning(f"Received None instead of messages for {power_name} (model: {model_id_for_stats}).")
                 messages = []
                 model_error_stats.setdefault(model_id_for_stats, {}).setdefault("conversation_errors", 0)
                 model_error_stats[model_id_for_stats]["conversation_errors"] += 1
            else:
                messages = result # result is the list of message dicts from agent.generate_messages
                logger.debug(f"Received {len(messages)} message(s) from {power_name} (model: {model_id_for_stats}).")

            # Process the received messages (same logic as before)
            if messages:
                for message_dict in messages: # Changed variable name from message to message_dict
                    # Validate message structure
                    if not isinstance(message_dict, dict) or "content" not in message_dict:
                        logger.warning(f"Invalid message format received from {power_name}: {message_dict}. Skipping.")
                        continue

                    # Create an official message in the Diplomacy engine
                    # Determine recipient based on message type
                    # Ensure recipient is uppercase and valid
                    recipient_from_llm = str(message_dict.get("recipient", GLOBAL)).upper()
                    if recipient_from_llm not in ALL_POWERS and recipient_from_llm != GLOBAL:
                         logger.warning(f"Invalid recipient '{recipient_from_llm}' from LLM for {power_name}. Defaulting to GLOBAL.")
                         actual_recipient = GLOBAL
                    else:
                        actual_recipient = recipient_from_llm

                    if message_dict.get("message_type") == "private":
                        # If private, recipient must be a specific power, not GLOBAL
                        if actual_recipient == GLOBAL:
                            logger.warning(f"Private message from {power_name} had recipient GLOBAL. Sending globally due to ambiguity.")
                            # Or, could decide to not send, or pick a default like the first other active power.
                            # For now, send globally as a fallback, but this indicates an LLM issue.
                            pass # actual_recipient is already GLOBAL
                        elif actual_recipient == power_name: # Cannot send private to self
                            logger.warning(f"Private message from {power_name} to self. Skipping.")
                            continue
                    else: # Assume global if not explicitly private or type is missing/invalid
                        actual_recipient = GLOBAL
                        
                    diplo_message = Message(
                        phase=game.current_short_phase,
                        sender=power_name,
                        recipient=actual_recipient, 
                        message=message_dict.get("content", ""),
                        time_sent=None, 
                    )
                    game.add_message(diplo_message)
                    game_history.add_message(
                        game.current_short_phase,
                        power_name,
                        actual_recipient, 
                        message_dict.get("content", ""),
                    )
                    journal_recipient_log = f"to {actual_recipient}" if actual_recipient != GLOBAL else "globally"
                    agent.add_journal_entry(f"Sent message {journal_recipient_log} in {game.current_short_phase}: {message_dict.get('content', '')[:100]}...")
                    logger.info(f"[{power_name} -> {actual_recipient}] {message_dict.get('content', '')[:100]}...")
            else:
                logger.debug(f"No valid messages returned or error occurred for {power_name}.")

    logger.info("Negotiation phase complete.")
    # Add ALL_POWERS constant at the top of the file
    return game_history

ALL_POWERS = frozenset({"AUSTRIA", "ENGLAND", "FRANCE", "GERMANY", "ITALY", "RUSSIA", "TURKEY"})



================================================
File: phase_summary.py
================================================
import logging
from typing import Optional, Dict, List, TYPE_CHECKING, Any

if TYPE_CHECKING:
    from diplomacy import Game
    from .game_history import GameHistory, Phase # Added Phase for type hint
    from .llm_interface import AgentLLMInterface
    from .game_config import GameConfig

logger = logging.getLogger(__name__)

class PhaseSummaryGenerator:
    """
    Generates and records a summary of a game phase for a specific power.
    This was previously handled by phase_summary_callback in lm_game.py.
    """

    def __init__(self, llm_interface: 'AgentLLMInterface', game_config: 'GameConfig'):
        """
        Initializes the PhaseSummaryGenerator.

        Args:
            llm_interface: The LLM interface for the agent of the power for which
                           the summary is being generated.
            game_config: The global game configuration object.
        """
        self.llm_interface = llm_interface
        self.game_config = game_config
        # The power_name is implicitly handled by the specific llm_interface instance passed.
        self.power_name = self.llm_interface.power_name


    def _get_all_orders_for_phase(self, game_history: 'GameHistory', phase_name: str) -> Dict[str, List[str]]:
        """
        Helper to retrieve all orders for a given phase from game history.
        """
        phase_data: Optional['Phase'] = game_history.get_phase_by_name(phase_name)
        if phase_data and phase_data.orders_by_power:
            return phase_data.orders_by_power
        
        # Fallback if not in history (e.g. very first phase, or if history population is delayed)
        # This part might need adjustment based on when orders are added to GameHistory
        # For now, assume GameHistory is up-to-date when this is called.
        logger.warning(f"[{self.power_name}] Orders for phase {phase_name} not found in game_history.orders_by_power. This might be normal for initial phases.")
        return {}


    async def generate_and_record_phase_summary(
        self,
        game: 'Game', # Current game state
        game_history: 'GameHistory', # History up to the phase *before* the one being summarized if current_short_phase is used
        phase_to_summarize_name: str, # e.g., "SPRING 1901M" (Movement phase that just ended)
        # Summary text of what happened in the phase (e.g. from game engine or observer)
        # This was 'phase_summary_text' in original lm_game.py, passed to phase_result_diary
        phase_events_summary_text: str, 
        all_orders_for_phase: Dict[str, List[str]] # Orders for the phase being summarized
    ) -> str:
        """
        Generates a phase result diary entry (which serves as a phase summary from the agent's perspective),
        records it in the game history, and returns the generated summary.

        Args:
            game: The current diplomacy.Game object.
            game_history: The GameHistory object.
            phase_to_summarize_name: The name of the phase that has just been completed and needs summarizing
                                     (e.g., the movement phase that just resolved).
            phase_events_summary_text: A textual summary of key events that occurred during this phase.
            all_orders_for_phase: A dictionary mapping power names to their orders for the phase being summarized.

        Returns:
            The generated summary string for the power, or an error message string.
        """
        logger.info(f"[{self.power_name}] Generating phase result diary (summary) for {phase_to_summarize_name}...")

        # Prepare variables for the prompt, similar to original phase_summary_callback
        # The llm_interface for this power will use its own self.power_name, goals, relationships.
        
        # Format all orders for the prompt
        all_orders_formatted = ""
        for power, orders in all_orders_for_phase.items():
            orders_str = ", ".join(orders) if orders else "No orders"
            all_orders_formatted += f"{power}: {orders_str}\n"
        
        your_orders_str = ", ".join(all_orders_for_phase.get(self.power_name, [])) if all_orders_for_phase.get(self.power_name) else "No orders submitted by you"

        # Get negotiations relevant to this phase (from history)
        # GameHistory needs a method to get messages *for a specific phase* easily
        # Assuming get_messages_by_phase exists or can be added to GameHistory
        messages_this_phase = game_history.get_messages_by_phase(phase_to_summarize_name) # You'd need to implement/verify this
        
        your_negotiations_text = ""
        if messages_this_phase:
            for msg_obj in messages_this_phase: # Assuming msg_obj has sender, recipient, content
                if msg_obj.sender == self.power_name:
                    your_negotiations_text += f"To {msg_obj.recipient}: {msg_obj.content}\n"
                elif msg_obj.recipient == self.power_name:
                    your_negotiations_text += f"From {msg_obj.sender}: {msg_obj.content}\n"
        if not your_negotiations_text:
            your_negotiations_text = "No negotiations involving your power recorded for this phase."

        # Agent's state (goals, relationships) are accessed via self.llm_interface.power_name 
        # and then by getting the agent instance if needed, or they are passed directly.
        # For phase_result_diary, the prompt expects current goals and relationships.
        # This implies the agent's state is needed. The llm_interface has power_name,
        # but not direct access to agent's goals/relationships.
        # This suggests PhaseSummaryGenerator might need access to the agent instance or its state.
        # For now, let's assume these are passed or are part of game_config for the agent.
        # The original agent.generate_phase_result_diary_entry used self.relationships and self.goals.
        # This means the llm_interface's generate_phase_result_diary needs these.
        # Let's assume these are part of prompt_template_vars passed to the interface.

        # The current AgentLLMInterface.generate_phase_result_diary takes prompt_template_vars.
        # We need to construct these vars here.
        
        # This part requires access to the agent's current state (goals, relationships).
        # For now, placeholder. This needs to be resolved by how Agent state is accessed here.
        # Let's assume GameConfig holds a reference to the agent or relevant state.
        # This is a simplification; likely, the Agent instance itself calls this method,
        # or the orchestrator passes the agent's state.
        # Given the current AgentLLMInterface, it doesn't hold goals/relationships.
        # So, we construct them here.
        
        # This is a temporary workaround. Ideally, the agent's state (goals, relationships)
        # should be available more directly. The `self.llm_interface` is tied to an agent.
        # We need to fetch the agent from somewhere to get its goals/relationships.
        # This indicates a potential design dependency issue to be resolved in the Orchestrator/AgentManager.
        # For now, let's assume they are placeholders or fetched from a (yet to be defined) source.
        
        agent_goals_str = "Goals not available to PhaseSummaryGenerator directly."
        agent_relationships_str = "Relationships not available to PhaseSummaryGenerator directly."

        # If game_config.agents exists and contains the current agent:
        if self.game_config.agents and self.power_name in self.game_config.agents:
            current_agent = self.game_config.agents[self.power_name]
            agent_goals_str = "\n".join([f"- {g}" for g in current_agent.goals]) if current_agent.goals else "None"
            agent_relationships_str = "\n".join([f"{p}: {r}" for p, r in current_agent.relationships.items()])
        else:
            logger.warning(f"Agent {self.power_name} not found in game_config.agents. Using placeholder goals/relationships for summary generation.")


        prompt_template_vars: Dict[str, Any] = {
            "power_name": self.power_name,
            "current_phase": phase_to_summarize_name,
            "phase_summary": phase_events_summary_text, # This is the general summary of events
            "all_orders_formatted": all_orders_formatted,
            "your_negotiations": your_negotiations_text,
            "pre_phase_relationships": agent_relationships_str, # Agent's relationships before this phase's impact
            "agent_goals": agent_goals_str, # Agent's current goals
            "your_actual_orders": your_orders_str
        }
        
        generated_summary = await self.llm_interface.generate_phase_result_diary(
            prompt_template_vars=prompt_template_vars,
            log_file_path=self.game_config.llm_log_path, # Assuming game_config has this
            game_phase=phase_to_summarize_name # The phase being summarized
        )

        if generated_summary and not generated_summary.startswith("(Error:"):
            # Record this generated summary (which is a diary entry reflecting on results)
            # The original lm_game added this as a diary entry to the agent.
            # Here, we might add it to game_history for the *power* associated with this llm_interface
            # The method in GameHistory is `add_phase_summary(phase_name, power_name, summary)`
            # However, the prompt is "phase_result_diary_prompt.txt", so it's an agent's reflection.
            # This should be added to the agent's diary.
            # The PhaseSummaryGenerator itself doesn't have the agent instance's add_diary_entry.
            # This implies the summary should be returned and the caller (agent or orchestrator) adds it.
            
            # For now, let's assume it's recorded in game_history as a power-specific summary/reflection.
            game_history.add_phase_summary(phase_to_summarize_name, self.power_name, generated_summary)
            logger.info(f"[{self.power_name}] Generated and recorded phase summary/diary for {phase_to_summarize_name}.")
            return generated_summary
        else:
            logger.error(f"[{self.power_name}] Failed to generate phase summary/diary for {phase_to_summarize_name}. LLM response: {generated_summary}")
            error_message = f"(Error: Failed to generate phase summary for {self.power_name} for {phase_to_summarize_name})"
            game_history.add_phase_summary(phase_to_summarize_name, self.power_name, error_message)
            return error_message

if __name__ == '__main__':
    # This is for example usage/testing of PhaseSummaryGenerator
    # It requires mocked or dummy versions of Game, GameHistory, AgentLLMInterface, GameConfig
    
    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # --- Mocking dependencies ---
    class MockLLMInterface:
        def __init__(self, power_name="FRANCE"):
            self.power_name = power_name
            self.logger = logging.getLogger(f"MockLLMInterface.{power_name}")

        async def generate_phase_result_diary(self, prompt_template_vars, log_file_path, game_phase):
            self.logger.info(f"generate_phase_result_diary called for {game_phase} with vars: {list(prompt_template_vars.keys())}")
            # Simulate a successful response
            return f"This is a generated summary for {prompt_template_vars.get('power_name')} for phase {game_phase}. Events: {prompt_template_vars.get('phase_summary')[:30]}..."

    class MockGame:
        def __init__(self, current_phase_name="SPRING 1901M"):
            self.current_short_phase = current_phase_name
            # Add other attributes if needed by the class, e.g., get_state()
            self.powers = {"FRANCE": None, "GERMANY": None} # Dummy powers

        def get_current_phase(self): # Ensure this method exists
            return self.current_short_phase


    class MockPhase:
        def __init__(self, name):
            self.name = name
            self.orders_by_power = {}
            self.messages = []
            self.phase_summaries = {}
        
        def add_phase_summary(self, power_name, summary): # Corrected method name
            self.phase_summaries[power_name] = summary

    class MockGameHistory:
        def __init__(self):
            self.phases: List[MockPhase] = []
        
        def get_phase_by_name(self, name_to_find: str) -> Optional[MockPhase]:
            for p in self.phases:
                if p.name == name_to_find:
                    return p
            # Add the phase if not found, for testing simplicity of summary generation
            new_phase = MockPhase(name_to_find)
            self.phases.append(new_phase)
            logger.info(f"[MockGameHistory] Auto-added phase {name_to_find} for summary testing.")
            return new_phase

        def get_messages_by_phase(self, phase_name: str) -> List[Any]: # Return list of mock messages
            # Simplified: return empty list or some mock messages
            phase = self.get_phase_by_name(phase_name)
            return phase.messages if phase else []

        def add_phase_summary(self, phase_name: str, power_name: str, summary: str):
            phase = self.get_phase_by_name(phase_name) # Ensures phase exists
            if phase:
                phase.add_phase_summary(power_name, summary) # Corrected call
            else: # Should not happen with get_phase_by_name's auto-add for this test
                logger.error(f"[MockGameHistory] Phase {phase_name} not found to add summary for {power_name}")


    class MockGameConfig:
        def __init__(self, power_name="FRANCE"):
            self.llm_log_path = "dummy_llm_log.csv"
            self.power_name = power_name # Needed if PhaseSummaryGenerator uses it directly
            self.agents = {} # To store mock agents if needed for goal/relationship fetching

            # Mock an agent for testing goal/relationship fetching
            class MockAgent:
                def __init__(self, p_name):
                    self.power_name = p_name
                    self.goals = [f"Goal 1 for {p_name}", f"Goal 2 for {p_name}"]
                    self.relationships = {"GERMANY": "Neutral", "ENGLAND": "Friendly"} if p_name == "FRANCE" else {}
            if power_name:
                 self.agents[power_name] = MockAgent(power_name)


    async def run_summary_generator_test():
        logger.info("--- Testing PhaseSummaryGenerator ---")
        
        # Setup
        power_name_test = "FRANCE"
        mock_llm_interface = MockLLMInterface(power_name=power_name_test)
        mock_game_config = MockGameConfig(power_name=power_name_test)
        
        summary_generator = PhaseSummaryGenerator(mock_llm_interface, mock_game_config)
        
        mock_game = MockGame(current_phase_name="AUTUMN 1901M") # Phase after the one being summarized
        mock_history = MockGameHistory()
        
        phase_to_summarize = "SPRING 1901M"
        # Add some history for the phase being summarized
        spring_1901_phase = mock_history.get_phase_by_name(phase_to_summarize) # Creates if not exists
        if spring_1901_phase:
             spring_1901_phase.orders_by_power = {
                "FRANCE": ["A PAR H", "F MAR H"],
                "GERMANY": ["A BER H", "A MUN - RUH"]
            }
             spring_1901_phase.messages = [
                type('MockMessage', (), {'sender': 'GERMANY', 'recipient': 'FRANCE', 'content': 'Hello France!'})()
            ]


        phase_events_text = "France took Paris. Germany moved to Ruhr."
        all_orders_for_spring_1901 = spring_1901_phase.orders_by_power if spring_1901_phase else {}
        
        # Generate summary
        generated_text = await summary_generator.generate_and_record_phase_summary(
            game=mock_game,
            game_history=mock_history,
            phase_to_summarize_name=phase_to_summarize,
            phase_events_summary_text=phase_events_text,
            all_orders_for_phase=all_orders_for_spring_1901
        )
        
        logger.info(f"Generated Summary Text for {power_name_test}: {generated_text}")
        
        # Check if summary was recorded in history (basic check)
        recorded_phase = mock_history.get_phase_by_name(phase_to_summarize)
        if recorded_phase and recorded_phase.phase_summaries.get(power_name_test):
            logger.info(f"Summary for {power_name_test} correctly recorded in history for {phase_to_summarize}: {recorded_phase.phase_summaries[power_name_test][:50]}...")
        else:
            logger.error(f"Summary for {power_name_test} NOT recorded in history for {phase_to_summarize}.")

    import asyncio
    asyncio.run(run_summary_generator_test())
    logger.info("--- PhaseSummaryGenerator test complete ---")



================================================
File: planning.py
================================================
# Removed: from dotenv import load_dotenv
import logging
import concurrent.futures
from typing import Dict

from .game_history import GameHistory
from .agent import DiplomacyAgent

logger = logging.getLogger(__name__)

async def planning_phase(
    game, 
    agents: Dict[str, DiplomacyAgent], 
    game_history: GameHistory, 
    model_error_stats,
    log_file_path: str,
):
    """
    Lets each power generate a strategic plan using their DiplomacyAgent.
    """
    logger.info(f"Starting planning phase for {game.current_short_phase}...")
    active_powers = [
        p_name for p_name, p_obj in game.powers.items() if not p_obj.is_eliminated()
    ]
    eliminated_powers = [
        p_name for p_name, p_obj in game.powers.items() if p_obj.is_eliminated()
    ]
    
    logger.info(f"Active powers for planning: {active_powers}")
    if eliminated_powers:
        logger.info(f"Eliminated powers (skipped): {eliminated_powers}")
    else:
        logger.info("No eliminated powers yet.")
    
    board_state = game.get_state()

    with concurrent.futures.ThreadPoolExecutor(
        max_workers=len(active_powers)
    ) as executor: 
        futures = {}
        for power_name in active_powers:
            if power_name not in agents:
                logger.warning(f"Agent for {power_name} not found in planning phase. Skipping.")
                continue
            agent = agents[power_name]
            client = agent.client
            
            future = executor.submit(
                client.get_plan,
                game,
                board_state,
                power_name,
                gather_possible_orders(game, power_name),
                game_history,
                agent_goals=agent.goals,
                agent_relationships=agent.relationships,
                log_file_path=log_file_path,
                agent_private_diary_str=agent.format_private_diary_for_prompt(),
            )
            futures[future] = power_name
            logger.debug(f"Submitted get_plan task for {power_name}.")

        logger.info(f"Waiting for {len(futures)} planning results...")
        for future in concurrent.futures.as_completed(futures):
            power_name = futures[future]
            try:
                plan_result = future.result()
                logger.info(f"Received planning result from {power_name}.")
                
                if plan_result.startswith("Error:"):
                     logger.warning(f"Agent {power_name} reported an error during planning: {plan_result}")
                     if power_name in model_error_stats:
                        model_error_stats[power_name].setdefault('planning_generation_errors', 0)
                        model_error_stats[power_name]['planning_generation_errors'] += 1
                     else:
                        model_error_stats.setdefault(f'{power_name}_planning_generation_errors', 0)
                        model_error_stats[f'{power_name}_planning_generation_errors'] += 1
                elif plan_result:
                    agent.add_journal_entry(f"Generated plan for {game.current_short_phase}: {plan_result[:100]}...")
                    game_history.add_plan(
                        game.current_short_phase, power_name, plan_result
                    )
                    logger.debug(f"Added plan for {power_name} to history.")
                else:
                    logger.warning(f"Agent {power_name} returned an empty plan.")

            except Exception as e:
                logger.error(f"Exception during planning result processing for {power_name}: {e}")
                if power_name in model_error_stats:
                    model_error_stats[power_name].setdefault('planning_execution_errors', 0)
                    model_error_stats[power_name]['planning_execution_errors'] += 1
                else:
                     model_error_stats.setdefault(f'{power_name}_planning_execution_errors', 0)
                     model_error_stats[f'{power_name}_planning_execution_errors'] += 1
        
    logger.info("Planning phase processing complete.")
    return game_history


================================================
File: possible_order_context.py
================================================
# ai_diplomacy/possible_order_context.py

from collections import deque
from typing import Dict, List, Callable, Optional, Any, Set, Tuple
from diplomacy.engine.map import Map as GameMap
from diplomacy.engine.game import Game as BoardState
import logging

# Placeholder for actual map type from diplomacy.engine.map.Map
# GameMap = Any 
# Type hint for board_state dictionary from game.get_state()
# BoardState = Dict[str, Any]

logger = logging.getLogger(__name__)

def build_diplomacy_graph(game_map: GameMap) -> Dict[str, Dict[str, List[str]]]:
    """
    Builds a graph where keys are SHORT province names (e.g., 'PAR', 'STP').
    Adjacency lists also contain SHORT province names.
    This graph is used for BFS pathfinding.
    """
    graph: Dict[str, Dict[str, List[str]]] = {}
    
    # Deriving a clean list of unique, 3-letter, uppercase short province names
    # game_map.locs contains all locations, including coasts e.g. "STP/SC"
    unique_short_names = set()
    for loc in game_map.locs:
        short_name = loc.split('/')[0][:3].upper() # Take first 3 chars and uppercase
        if len(short_name) == 3: # Ensure it's a 3-letter name
            unique_short_names.add(short_name)
    
    all_short_province_names = sorted(list(unique_short_names))

    # Initialize graph with all valid short province names as keys
    for province_name in all_short_province_names:
        graph[province_name] = {'ARMY': [], 'FLEET': []}

    for province_short_source in all_short_province_names: # e.g. 'PAR', 'STP'
        # Get all full names for this source province (e.g. 'STP' -> ['STP/NC', 'STP/SC', 'STP'])
        full_names_for_source = game_map.loc_coasts.get(province_short_source, [province_short_source])

        for loc_full_source_variant in full_names_for_source: # e.g. 'STP/NC', then 'STP/SC', then 'STP'
            # province_short_source is already the short name like 'STP'
            # game_map.loc_abut provides general adjacencies, which might include specific coasts or lowercase names
            for raw_adj_loc_from_loc_abut in game_map.loc_abut.get(province_short_source, []):
                # Normalize this raw adjacent location to its short, uppercase form
                adj_short_name_normalized = raw_adj_loc_from_loc_abut[:3].upper()

                # Get all full names for this *normalized* adjacent short name (e.g. 'BUL' -> ['BUL/EC', 'BUL/SC', 'BUL'])
                full_names_for_adj_dest = game_map.loc_coasts.get(adj_short_name_normalized, [adj_short_name_normalized])

                # Check for ARMY movement
                unit_char_army = 'A'
                if any(
                    game_map.abuts(
                        unit_char_army,
                        loc_full_source_variant,    # Specific full source, e.g. 'STP/NC'
                        '-',                        # Order type for move
                        full_dest_variant           # Specific full destination, e.g. 'MOS' or 'FIN'
                    )
                    for full_dest_variant in full_names_for_adj_dest
                ):
                    if adj_short_name_normalized not in graph[province_short_source]['ARMY']:
                        graph[province_short_source]['ARMY'].append(adj_short_name_normalized)

                # Check for FLEET movement
                unit_char_fleet = 'F'
                if any(
                    game_map.abuts(
                        unit_char_fleet,
                        loc_full_source_variant,    # Specific full source, e.g. 'STP/NC'
                        '-',                        # Order type for move
                        full_dest_variant           # Specific full destination, e.g. 'BAR' or 'NWY'
                    )
                    for full_dest_variant in full_names_for_adj_dest
                ):
                    if adj_short_name_normalized not in graph[province_short_source]['FLEET']:
                        graph[province_short_source]['FLEET'].append(adj_short_name_normalized)
    
    # Remove duplicates from adjacency lists (just in case)
    for province_short in graph:
        if 'ARMY' in graph[province_short]:
            graph[province_short]['ARMY'] = sorted(list(set(graph[province_short]['ARMY'])))
        if 'FLEET' in graph[province_short]:
            graph[province_short]['FLEET'] = sorted(list(set(graph[province_short]['FLEET'])))
            
    return graph


def bfs_shortest_path(
    graph: Dict[str, Dict[str, List[str]]], 
    board_state: BoardState, 
    game_map: GameMap, # Added game_map
    start_loc_full: str, # This is a FULL location name like 'VIE' or 'STP/SC'
    unit_type: str, 
    is_target_func: Callable[[str, BoardState], bool] # Expects SHORT name for loc
) -> Optional[List[str]]: # Returns path of SHORT names
    """Performs BFS to find the shortest path from start_loc to a target satisfying is_target_func."""
    
    # Convert full start location to short province name
    start_loc_short = game_map.loc_name.get(start_loc_full, start_loc_full)
    if '/' in start_loc_short: # If it was STP/SC, loc_name gives STP. If it was VIE, loc_name gives VIE.
        start_loc_short = start_loc_short[:3]
    # If start_loc_full was already short (e.g. 'VIE'), get might return it as is, or its value if it was a key.
    # A simpler way for non-coastal full (like 'VIE') or already short:
    if '/' not in start_loc_full: 
        start_loc_short = start_loc_full[:3] # Ensures 'VIE' -> 'VIE', 'PAR' -> 'PAR'
    else: # Has '/', e.g. 'STP/SC'
        start_loc_short = start_loc_full[:3] # 'STP/SC' -> 'STP'

    if start_loc_short not in graph:
        logger.warning(f"BFS: Start province {start_loc_short} (from {start_loc_full}) not in graph. Pathfinding may fail.")
        return None

    queue: deque[Tuple[str, List[str]]] = deque([(start_loc_short, [start_loc_short])]) 
    visited_nodes: Set[str] = {start_loc_short}

    while queue:
        current_loc_short, path = queue.popleft()

        # is_target_func expects a short location name
        if is_target_func(current_loc_short, board_state):
            return path # Path of short names

        # possible_neighbors are SHORT names from the graph
        possible_neighbors_short = graph.get(current_loc_short, {}).get(unit_type, [])
        
        for next_loc_short in possible_neighbors_short:
            if next_loc_short not in visited_nodes:
                if next_loc_short not in graph: # Defensive check for neighbors not in graph keys
                    logger.warning(f"BFS: Neighbor {next_loc_short} of {current_loc_short} not in graph. Skipping.")
                    continue
                visited_nodes.add(next_loc_short)
                new_path = path + [next_loc_short]
                queue.append((next_loc_short, new_path))
    return None

# --- Helper functions for context generation ---
def get_unit_at_location(board_state: BoardState, location: str) -> Optional[str]:
    """Returns the full unit string (e.g., 'A PAR (FRA)') if a unit is at the location, else None."""
    for power, unit_list in board_state.get('units', {}).items():
        for unit_str in unit_list: # e.g., "A PAR", "F STP/SC"
            parts = unit_str.split(" ")
            if len(parts) == 2:
                unit_map_loc = parts[1]
                if unit_map_loc == location:
                    return f"{parts[0]} {location} ({power})"
    return None

def get_sc_controller(game_map: GameMap, board_state: BoardState, location: str) -> Optional[str]:
    """Returns the controlling power's name if the location is an SC, else None."""
    # Normalize location to base province name, as SCs are tied to provinces, not specific coasts
    loc_province_name = game_map.loc_name.get(location, location).upper()[:3]
    if loc_province_name not in game_map.scs:
        return None
    for power, sc_list in board_state.get('centers', {}).items():
        if loc_province_name in sc_list:
            return power
    return None # Unowned SC

def get_shortest_path_to_friendly_unit(
    board_state: BoardState, 
    graph: Dict[str, Dict[str, List[str]]],
    game_map: GameMap, # Added game_map
    power_name: str, 
    start_unit_loc_full: str, 
    start_unit_type: str
) -> Optional[Tuple[str, List[str]]]:
    """Finds the shortest path to any friendly unit of the same power."""
    
    def is_target_friendly(loc_short: str, current_board_state: BoardState) -> bool:
        # loc_short is a short province name. Need to check all its full locations.
        full_locs_for_short = game_map.loc_coasts.get(loc_short, [loc_short])
        for full_loc_variant in full_locs_for_short:
            unit_at_loc = get_unit_at_location(current_board_state, full_loc_variant)
            if unit_at_loc and unit_at_loc.split(" ")[2][1:4] == power_name and full_loc_variant != start_unit_loc_full:
                return True
        return False

    path_short_names = bfs_shortest_path(graph, board_state, game_map, start_unit_loc_full, start_unit_type, is_target_friendly)
    if path_short_names and len(path_short_names) > 1: # Path includes start, so > 1 means a distinct friendly unit found
        target_loc_short = path_short_names[-1]
        # Find the actual friendly unit string at one of the full locations of target_loc_short
        friendly_unit_str = "UNKNOWN_FRIENDLY_UNIT"
        full_locs_for_target_short = game_map.loc_coasts.get(target_loc_short, [target_loc_short])
        for fl_variant in full_locs_for_target_short:
            unit_str = get_unit_at_location(board_state, fl_variant)
            if unit_str and unit_str.split(" ")[2][1:4] == power_name:
                friendly_unit_str = unit_str
                break
        return friendly_unit_str, path_short_names
    return None


def get_nearest_enemy_units(
    board_state: BoardState, 
    graph: Dict[str, Dict[str, List[str]]],
    game_map: GameMap, # Added game_map
    power_name: str, 
    start_unit_loc_full: str, 
    start_unit_type: str, 
    n: int = 3
) -> List[Tuple[str, List[str]]]:
    """Finds up to N nearest enemy units, sorted by path length."""
    enemy_paths: List[Tuple[str, List[str]]] = [] # (enemy_unit_str, path_short_names)
    
    all_enemy_unit_locations_full: List[Tuple[str,str]] = [] # (loc_full, unit_str_full)
    # board_state.get("units", {}) has format: { "POWER_NAME": ["A PAR", "F BRE"], ... }
    for p_name, unit_list_for_power in board_state.get("units", {}).items():
        if p_name != power_name: # If it's an enemy power
            for unit_repr_from_state in unit_list_for_power: # e.g., "A PAR" or "F STP/SC"
                parts = unit_repr_from_state.split(" ")
                if len(parts) == 2:
                    # unit_type_char = parts[0] # 'A' or 'F'
                    loc_full = parts[1]       # 'PAR' or 'STP/SC'
                    
                    # Use get_unit_at_location to get the consistent full unit string like "A PAR (POWER_NAME)"
                    full_unit_str_with_power = get_unit_at_location(board_state, loc_full)
                    if full_unit_str_with_power: # Should find the unit if iteration is correct
                         all_enemy_unit_locations_full.append((loc_full, full_unit_str_with_power))

    for target_enemy_loc_full, enemy_unit_str in all_enemy_unit_locations_full:
        target_enemy_loc_short = game_map.loc_name.get(target_enemy_loc_full, target_enemy_loc_full)
        if '/' in target_enemy_loc_short:
            target_enemy_loc_short = target_enemy_loc_short[:3]
        if '/' not in target_enemy_loc_full:
            target_enemy_loc_short = target_enemy_loc_full[:3]
        else:
            target_enemy_loc_short = target_enemy_loc_full[:3]
            
        def is_specific_enemy_loc(loc_short: str, current_board_state: BoardState) -> bool:
            # Check if loc_short corresponds to target_enemy_loc_full
            return loc_short == target_enemy_loc_short

        path_short_names = bfs_shortest_path(graph, board_state, game_map, start_unit_loc_full, start_unit_type, is_specific_enemy_loc)
        if path_short_names:
            enemy_paths.append((enemy_unit_str, path_short_names))
    
    enemy_paths.sort(key=lambda x: len(x[1])) # Sort by path length
    return enemy_paths[:n]


def get_nearest_uncontrolled_scs(
    game_map: GameMap, 
    board_state: BoardState, 
    graph: Dict[str, Dict[str, List[str]]], 
    power_name: str, 
    start_unit_loc_full: str, 
    start_unit_type: str, 
    n: int = 3
) -> List[Tuple[str, int, List[str]]]: # (sc_name_short, distance, path_short_names)
    """Finds up to N nearest SCs not controlled by power_name, sorted by path length."""
    uncontrolled_sc_paths: List[Tuple[str, int, List[str]]] = []

    all_scs_short = game_map.scs # This is a list of short province names that are SCs

    for sc_loc_short in all_scs_short:
        controller = get_sc_controller(game_map, board_state, sc_loc_short)
        if controller != power_name:
            def is_target_sc(loc_short: str, current_board_state: BoardState) -> bool:
                return loc_short == sc_loc_short
            
            path_short_names = bfs_shortest_path(graph, board_state, game_map, start_unit_loc_full, start_unit_type, is_target_sc)
            if path_short_names:
                # Path includes start, so distance is len - 1
                uncontrolled_sc_paths.append((f"{sc_loc_short} (Ctrl: {controller or 'None'})", len(path_short_names) -1, path_short_names))
    
    # Sort by distance (path length - 1), then by SC name for tie-breaking
    uncontrolled_sc_paths.sort(key=lambda x: (x[1], x[0]))
    return uncontrolled_sc_paths[:n]

def get_adjacent_territory_details(
    game_map: GameMap, 
    board_state: BoardState, 
    unit_loc_full: str, # The location of the unit whose adjacencies we're checking
    unit_type: str, # ARMY or FLEET of the unit at unit_loc_full
    graph: Dict[str, Dict[str, List[str]]]
) -> str:
    """Generates a string describing adjacent territories and units that can interact with them."""
    output_lines: List[str] = []
    # Get adjacencies for the current unit's type
    # The graph already stores processed adjacencies (e.g. army can't go to sea)
    # For armies, graph[unit_loc_full]['ARMY'] gives short province names
    # For fleets, graph[unit_loc_full]['FLEET'] gives full loc names (incl coasts)
    # THIS COMMENT IS NOW OUTDATED. Graph uses short names for keys and values.
    unit_loc_short = game_map.loc_name.get(unit_loc_full, unit_loc_full)
    if '/' in unit_loc_short:
        unit_loc_short = unit_loc_short[:3]
    if '/' not in unit_loc_full:
        unit_loc_short = unit_loc_full[:3]
    else:
        unit_loc_short = unit_loc_full[:3]

    adjacent_locs_short_for_unit = graph.get(unit_loc_short, {}).get(unit_type, []) 

    processed_adj_provinces = set() # To handle cases like STP/NC and STP/SC both being adjacent to BOT

    for adj_loc_short in adjacent_locs_short_for_unit: # adj_loc_short is already short
        # adj_province_short = game_map.loc_name.get(adj_loc_full, adj_loc_full).upper()[:3] # No longer needed
        if adj_loc_short in processed_adj_provinces: # adj_loc_short is already short and upper implicitly by map data
            continue
        processed_adj_provinces.add(adj_loc_short)

        adj_loc_type = game_map.loc_type.get(adj_loc_short, 'UNKNOWN').upper()
        if adj_loc_type == 'COAST' or adj_loc_type == 'LAND':
            adj_loc_type_display = 'LAND' if adj_loc_type == 'LAND' else 'COAST'
        elif adj_loc_type == 'WATER':
            adj_loc_type_display = 'WATER'
        else: # SHUT etc.
            adj_loc_type_display = adj_loc_type
        
        line = f"  {adj_loc_short} ({adj_loc_type_display})"
        
        sc_controller = get_sc_controller(game_map, board_state, adj_loc_short)
        if sc_controller:
            line += f" SC Control: {sc_controller}"
        
        unit_in_adj_loc = get_unit_at_location(board_state, adj_loc_short)
        if unit_in_adj_loc:
            line += f" Units: {unit_in_adj_loc}"
        output_lines.append(line)

        # "Can support/move to" - Simplified: list units in *further* adjacent provinces
        # A true "can support/move to" would require checking possible orders of those further units.
        # further_adj_provinces are short names from the graph
        further_adj_provinces_short = graph.get(adj_loc_short, {}).get('ARMY', []) + \
                                graph.get(adj_loc_short, {}).get('FLEET', [])
        
        supporting_units_info = []
        processed_further_provinces = set()
        for further_adj_loc_short in further_adj_provinces_short:
            # further_adj_province_short = game_map.loc_name.get(further_adj_loc_full, further_adj_loc_full).upper()[:3]
            # No conversion needed, it's already short
            if further_adj_loc_short == adj_loc_short or further_adj_loc_short == unit_loc_short: # Don't list itself or origin
                continue
            if further_adj_loc_short in processed_further_provinces:
                continue
            processed_further_provinces.add(further_adj_loc_short)

            # Check for units in this further adjacent province (any coast)
            # This is a bit broad. We should check units in the specific 'further_adj_loc_full'
            # unit_in_further_loc = get_unit_at_location(board_state, further_adj_loc_full)
            # We have further_adj_loc_short. Need to check all its full variants.
            unit_in_further_loc = ""
            full_variants_of_further_short = game_map.loc_coasts.get(further_adj_loc_short, [further_adj_loc_short])
            for fv_further in full_variants_of_further_short:
                temp_unit = get_unit_at_location(board_state, fv_further)
                if temp_unit:
                    unit_in_further_loc = temp_unit
                    break # Found a unit in one of the coasts/base
            
            # if not unit_in_further_loc and further_adj_loc_full != further_adj_province_short:
            #      unit_in_further_loc = get_unit_at_location(board_state, further_adj_province_short)
            
            if unit_in_further_loc:
                supporting_units_info.append(unit_in_further_loc)
        
        if supporting_units_info:
            output_lines.append(f"    => Can support/move to: {', '.join(sorted(list(set(supporting_units_info))))}")

    return "\n".join(output_lines)


# --- Main context generation function ---
def generate_rich_order_context(game: Any, power_name: str, possible_orders_for_power: Dict[str, List[str]]) -> str:
    """
    Generates a strategic overview context string.
    Details units and SCs for power_name, including possible orders and simplified adjacencies for its units.
    Provides summaries of units and SCs for all other powers.
    """
    board_state: BoardState = game.get_state()
    game_map: GameMap = game.map
    graph = build_diplomacy_graph(game_map)
    
    final_context_lines: List[str] = ["<PossibleOrdersContext>"]

    # Iterate through units that have orders (keys of possible_orders_for_power are unit locations)
    for unit_loc_full, unit_specific_possible_orders in possible_orders_for_power.items():
        unit_str_full = get_unit_at_location(board_state, unit_loc_full)
        if not unit_str_full: # Should not happen if unit_loc_full is from possible_orders keys
            continue 

        unit_type_char = unit_str_full.split(" ")[0] # 'A' or 'F'
        unit_type_long = "ARMY" if unit_type_char == 'A' else "FLEET"

        loc_province_short = game_map.loc_name.get(unit_loc_full, unit_loc_full).upper()[:3]
        loc_type_short = game_map.loc_type.get(loc_province_short, "UNKNOWN").upper()
        if loc_type_short == 'COAST' or loc_type_short == 'LAND':
            loc_type_display = 'LAND' if loc_type_short == 'LAND' else 'COAST'
        else:
            loc_type_display = loc_type_short

        current_unit_lines: List[str] = []
        current_unit_lines.append(f'  <UnitContext loc="{unit_loc_full}">')
        
        # Unit Information section
        current_unit_lines.append('    <UnitInformation>')
        sc_owner_at_loc = get_sc_controller(game_map, board_state, unit_loc_full)
        header_content = f"Strategic territory held by {power_name}: {unit_loc_full} ({loc_type_display})"
        if sc_owner_at_loc == power_name:
            header_content += " (Controls SC)"
        elif sc_owner_at_loc:
            header_content += f" (SC controlled by {sc_owner_at_loc})"
        current_unit_lines.append(f"      {header_content}")
        current_unit_lines.append(f"      Units present: {unit_str_full}")
        current_unit_lines.append('    </UnitInformation>')

        # Possible moves section
        current_unit_lines.append('    <PossibleMoves>')
        current_unit_lines.append("      Possible moves:")
        for order_str in unit_specific_possible_orders:
            current_unit_lines.append(f"        {order_str}")
        current_unit_lines.append('    </PossibleMoves>')
        
        # Nearest enemy units section
        enemy_units_info = get_nearest_enemy_units(board_state, graph, game_map, power_name, unit_loc_full, unit_type_long, n=3)
        current_unit_lines.append('    <NearestEnemyUnits>')
        if enemy_units_info:
            current_unit_lines.append("      Nearest units (not ours):")
            for enemy_unit_str, enemy_path_short in enemy_units_info:
                current_unit_lines.append(f"        {enemy_unit_str}, path=[{unit_loc_full}→{('→'.join(enemy_path_short[1:])) if len(enemy_path_short) > 1 else enemy_path_short[0]}]")
        else:
            current_unit_lines.append("      Nearest units (not ours): None found")
        current_unit_lines.append('    </NearestEnemyUnits>')

        # Nearest supply centers (not controlled by us) section
        uncontrolled_scs_info = get_nearest_uncontrolled_scs(game_map, board_state, graph, power_name, unit_loc_full, unit_type_long, n=3)
        current_unit_lines.append('    <NearestUncontrolledSupplyCenters>')
        if uncontrolled_scs_info:
            current_unit_lines.append("      Nearest supply centers (not controlled by us):")
            for sc_str, dist, sc_path_short in uncontrolled_scs_info:
                current_unit_lines.append(f"        {sc_str}, dist={dist}, path=[{unit_loc_full}→{('→'.join(sc_path_short[1:])) if len(sc_path_short) > 1 else sc_path_short[0]}]")
        else:
            current_unit_lines.append("      Nearest supply centers (not controlled by us): None found")
        current_unit_lines.append('    </NearestUncontrolledSupplyCenters>')

        # Adjacent territories details section
        adj_details_str = get_adjacent_territory_details(game_map, board_state, unit_loc_full, unit_type_long, graph)
        current_unit_lines.append('    <AdjacentTerritories>')
        if adj_details_str:
            current_unit_lines.append("      Adjacent territories (including units that can support/move to the adjacent territory):")
            # Assuming adj_details_str is already formatted with newlines and indentation for its content
            # We might need to indent adj_details_str if it's a single block of text
            # For now, let's add a standard indent to each line of adj_details_str if it contains newlines
            if '\n' in adj_details_str:
                indented_adj_details = "\n".join([f"        {line}" for line in adj_details_str.split('\n')])
                current_unit_lines.append(indented_adj_details)
            else:
                 current_unit_lines.append(f"        {adj_details_str}")
        else:
            current_unit_lines.append("      Adjacent territories: None relevant or all are empty/uncontested by direct threats.") # Added more descriptive else
        current_unit_lines.append('    </AdjacentTerritories>')
        
        current_unit_lines.append('  </UnitContext>')
        final_context_lines.extend(current_unit_lines)

    final_context_lines.append("</PossibleOrdersContext>")
    return "\n".join(final_context_lines)



================================================
File: prompt_constructor.py
================================================
"""
Module for constructing prompts for LLM interactions in the Diplomacy game.
"""
import logging
# Removed: import json
from typing import Dict, List, Optional, Any # Added Any for game type placeholder

# from .game_state import GameState # Removed unused import
from .prompt_utils import load_prompt # Changed from .utils to .prompt_utils
from .possible_order_context import generate_rich_order_context
from .game_history import GameHistory # Assuming GameHistory is correctly importable

# placeholder for diplomacy.Game to avoid circular or direct dependency if not needed for typehinting only
# from diplomacy import Game # Uncomment if 'Game' type hint is crucial and available

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG) # Or inherit from parent logger

# Load prompt components from files
# ORDER_GENERATION_PROMPT_SYSTEM_COMMON = load_prompt("order_generation_system_common.txt") # Removed as file does not exist and variable is unused

def build_context_prompt(
    game: Any, # diplomacy.Game object
    board_state: dict,
    power_name: str,
    possible_orders: Dict[str, List[str]],
    game_history: GameHistory,
    agent_goals: Optional[List[str]] = None,
    agent_relationships: Optional[Dict[str, str]] = None,
    agent_private_diary: Optional[str] = None,
) -> str:
    """Builds the detailed context part of the prompt.

    Args:
        game: The game object.
        board_state: Current state of the board.
        power_name: The name of the power for whom the context is being built.
        possible_orders: Dictionary of possible orders.
        game_history: History of the game (messages, etc.).
        agent_goals: Optional list of agent's goals.
        agent_relationships: Optional dictionary of agent's relationships with other powers.
        agent_private_diary: Optional string of agent's private diary.

    Returns:
        A string containing the formatted context.
    """
    context_template = load_prompt("context_prompt.txt")

    # === Agent State Debug Logging ===
    if agent_goals:
        logger.debug(f"Using goals for {power_name}: {agent_goals}")
    if agent_relationships:
        logger.debug(f"Using relationships for {power_name}: {agent_relationships}")
    if agent_private_diary:
        logger.debug(f"Using private diary for {power_name}: {agent_private_diary[:200]}...")
    # ================================

    # Get our units and centers (not directly used in template, but good for context understanding)
    # units_info = board_state["units"].get(power_name, [])
    # centers_info = board_state["centers"].get(power_name, [])

    # Get the current phase
    year_phase = board_state["phase"]  # e.g. 'S1901M'

    possible_orders_context_str = generate_rich_order_context(game, power_name, possible_orders)

    messages_this_round_text = game_history.get_messages_this_round(
        power_name=power_name,
        current_phase_name=year_phase
    )
    if not messages_this_round_text.strip():
        messages_this_round_text = "\n(No messages this round)\n"

    # Separate active and eliminated powers for clarity
    # active_powers = [p for p in game.powers.keys() if not game.powers[p].is_eliminated()] # Unused variable
    # eliminated_powers = [p for p in game.powers.keys() if game.powers[p].is_eliminated()] # Unused variable
    
    # Build units representation with power status
    units_lines = []
    for p, u in board_state["units"].items():
        if game.powers[p].is_eliminated():
            units_lines.append(f"  {p}: {u} [ELIMINATED]")
        else:
            units_lines.append(f"  {p}: {u}")
    units_repr = "\n".join(units_lines)
    
    # Build centers representation with power status  
    centers_lines = []
    for p, c in board_state["centers"].items():
        if game.powers[p].is_eliminated():
            centers_lines.append(f"  {p}: {c} [ELIMINATED]")
        else:
            centers_lines.append(f"  {p}: {c}")
    centers_repr = "\n".join(centers_lines)

    context = context_template.format(
        power_name=power_name,
        current_phase=year_phase,
        all_unit_locations=units_repr,
        all_supply_centers=centers_repr,
        messages_this_round=messages_this_round_text,
        possible_orders=possible_orders_context_str,
        agent_goals="\n".join(f"- {g}" for g in agent_goals) if agent_goals else "None specified",
        agent_relationships="\n".join(f"- {p}: {s}" for p, s in agent_relationships.items()) if agent_relationships else "None specified",
        agent_private_diary=agent_private_diary if agent_private_diary else "(No diary entries yet)",
    )

    return context

def construct_order_generation_prompt(
    system_prompt: str,
    game: Any, # diplomacy.Game object
    board_state: dict,
    power_name: str,
    possible_orders: Dict[str, List[str]],
    game_history: GameHistory,
    agent_goals: Optional[List[str]] = None,
    agent_relationships: Optional[Dict[str, str]] = None,
    agent_private_diary_str: Optional[str] = None,
) -> str:
    """Constructs the final prompt for order generation.

    Args:
        system_prompt: The base system prompt for the LLM.
        game: The game object.
        board_state: Current state of the board.
        power_name: The name of the power for whom the prompt is being built.
        possible_orders: Dictionary of possible orders.
        game_history: History of the game (messages, etc.).
        agent_goals: Optional list of agent's goals.
        agent_relationships: Optional dictionary of agent's relationships with other powers.
        agent_private_diary_str: Optional string of agent's private diary.

    Returns:
        A string containing the complete prompt for the LLM.
    """
    # Load prompts
    _ = load_prompt("few_shot_example.txt") # Loaded but not used, as per original logic
    instructions = load_prompt("order_instructions.txt")

    # Build the context prompt
    context = build_context_prompt(
        game,
        board_state,
        power_name,
        possible_orders,
        game_history,
        agent_goals=agent_goals,
        agent_relationships=agent_relationships,
        agent_private_diary=agent_private_diary_str,
    )

    # Create a flat list of all valid orders for this power
    all_valid_orders = []
    for loc, orders_list in possible_orders.items():
        all_valid_orders.extend(orders_list)
    
    # Format the valid orders list for injection into the instructions
    if all_valid_orders:
        valid_orders_formatted = "\n".join(f"- {order}" for order in sorted(all_valid_orders))
    else:
        valid_orders_formatted = "- No valid orders available"
    
    # Inject the valid orders list into the instructions
    instructions_with_orders = instructions.format(valid_orders_list=valid_orders_formatted)

    final_prompt = system_prompt + "\n\n" + context + "\n\n" + instructions_with_orders
    return final_prompt



================================================
File: prompt_utils.py
================================================
# Removed comment: # Added to resolve NameError: name 'List' is not defined
import os
import jinja2

def load_prompt(filename: str) -> str:
    """Load a prompt from a file located in the 'prompts' subdirectory
    relative to the current script file."""
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    filepath = os.path.join(current_script_dir, "prompts", filename)

    if not os.path.exists(filepath):
        # For debugging, let's also check the CWD based path as a fallback
        # as this was part of the original complex logic.
        # This helps understand if the script is being run from an unexpected CWD.
        cwd_path = os.path.join(os.getcwd(), "prompts", filename)
        
        # Also check project root based path (assuming prompt_utils.py is in ai_diplomacy/
        # and prompts/ is at the project root: <project_root>/prompts/)
        project_root_prompts_path = os.path.join(os.path.dirname(current_script_dir), "prompts", filename)

        raise FileNotFoundError(
            f"Prompt file '{filename}' not found. \n"
            f"Expected at: {filepath} (relative to script: {current_script_dir})\n"
            f"Also checked CWD-based: {cwd_path} (CWD: {os.getcwd()})\n"
            f"Also checked project_root-based: {project_root_prompts_path}"
        )

    with open(filepath, "r", encoding="utf-8") as f:
        return f.read()

def render_prompt(template_filename: str, **kwargs) -> str:
    '''Loads a prompt template file and renders it using Jinja2.'''
    template_string = load_prompt(template_filename) # Removed comment: # Uses the existing load_prompt in this file
    if template_string is None:
        # load_prompt already logs an error and raises FileNotFoundError
        raise FileNotFoundError(f"Template file {template_filename} not found by load_prompt.")
    
    try:
        template = jinja2.Template(template_string)
        return template.render(**kwargs)
    except jinja2.exceptions.TemplateSyntaxError as e:
        # Log or handle syntax errors in templates
        # For now, re-raise to make it visible
        raise Exception(f"Jinja2 template syntax error in {template_filename}: {e}") from e
    except Exception as e:
        raise Exception(f"Error rendering Jinja2 template {template_filename}: {e}") from e


================================================
File: utils.py
================================================
from dotenv import load_dotenv
import logging
import os
from typing import Dict, List, Tuple, Set, Optional
from diplomacy import Game
import csv
# TYPE_CHECKING for BaseModelClient removed as it's obsolete.
# from typing import TYPE_CHECKING
# if TYPE_CHECKING:
    # from .agent import DiplomacyAgent # Keep if DiplomacyAgent hint is still needed elsewhere
# Removed: import llm 
import re
import ast
import json
from .prompt_constructor import construct_order_generation_prompt
from .llm_coordinator import LocalLLMCoordinator # Added import


logger = logging.getLogger("utils")
logger.setLevel(logging.INFO)
logging.basicConfig(level=logging.INFO)

load_dotenv()


def assign_models_to_powers(fixed_models_str: Optional[str] = None) -> Dict[str, str]:
    """
    DEPRECATED: Model assignment is now primarily handled by AgentManager using GameConfig
    which loads from a TOML file and considers command-line arguments.
    This function remains for potential standalone utilities that might not have a full GameConfig.
    It provides a very basic assignment logic.
    """
    logger.warning(
        "DEPRECATION WARNING: utils.assign_models_to_powers() is deprecated. "
        "Model assignment is primarily handled by AgentManager and GameConfig. "
        "This function provides a basic fallback and may be removed in the future."
    )
    powers = ["AUSTRIA", "ENGLAND", "FRANCE", "GERMANY", "ITALY", "RUSSIA", "TURKEY"]
    assigned_models: Dict[str, str] = {}
    model_list: List[str] = []

    # Simplified logic: Use fixed_models_str if provided, else a hardcoded default.
    if fixed_models_str:
        model_list = [m.strip() for m in fixed_models_str.split(',') if m.strip()]
        logger.info(f"[Deprecated utils.assign_models] Using fixed_models_str: {model_list}")
    
    if not model_list:
        # Try POWER_MODELS env var as a secondary fallback for this deprecated function
        power_models_env = os.environ.get("POWER_MODELS")
        if power_models_env:
            model_list = [m.strip() for m in power_models_env.split(',') if m.strip()]
            logger.info(f"[Deprecated utils.assign_models] Using POWER_MODELS env var: {model_list}")
        else:
            # Final fallback to a single model for all powers
            default_model_for_util = os.environ.get("MODEL_NAME", "ollama/gemma3:4b")
            logger.info(f"[Deprecated utils.assign_models] No fixed_models_str or POWER_MODELS. Defaulting all to: {default_model_for_util}")
            for power in powers:
                assigned_models[power] = default_model_for_util
            return assigned_models

    if not model_list: # Should not happen if default_model_for_util logic is hit
        logger.error("[Deprecated utils.assign_models] Model list empty. Cannot assign.")
        return {}

    for i, power in enumerate(powers):
        assigned_models[power] = model_list[i % len(model_list)]
    
    logger.info(f"[Deprecated utils.assign_models] Final assignments: {assigned_models}")
    return assigned_models

def gather_possible_orders(game: Game, power_name: str) -> Dict[str, List[str]]:
    """
    Returns a dictionary mapping each orderable location to the list of valid orders.
    """
    orderable_locs = game.get_orderable_locations(power_name)
    all_possible = game.get_all_possible_orders()

    result = {}
    for loc in orderable_locs:
        result[loc] = all_possible.get(loc, [])
    return result

# Helper function to provide fallback orders (all units HOLD)
def _fallback_orders_utility(possible_orders: Dict[str, List[str]]) -> List[str]:
    """Generates a list of HOLD orders for all units if possible, else first option."""
    fallback = []
    for loc, orders_list in possible_orders.items():
        if orders_list:
            holds = [o for o in orders_list if o.endswith(" H")]
            fallback.append(holds[0] if holds else orders_list[0])
    return fallback

# Helper function to extract moves from LLM response (adapted from BaseModelClient)
def _extract_moves_from_llm_response(raw_response: str, power_name: str, model_id: str) -> Optional[List[str]]:
    """
    Attempt multiple parse strategies to find JSON array of moves.
    """
    logger.debug(f"[{model_id}] Attempting to extract moves for {power_name} from raw response: {raw_response[:300]}...")
    # Regex for "PARSABLE OUTPUT:{...}"
    pattern = r"PARSABLE OUTPUT:\s*(\{[\s\S]*\})"
    matches = re.search(pattern, raw_response, re.DOTALL)

    if not matches:
        logger.debug(f"[{model_id}] Regex for 'PARSABLE OUTPUT:' failed for {power_name}. Trying alternative patterns.")
        pattern_alt = r"PARSABLE OUTPUT\s*\{(.*?)\}\s*$" # Check for inline JSON
        matches = re.search(pattern_alt, raw_response, re.DOTALL)

    if not matches: # Check for triple-backtick code fences
        logger.debug(f"[{model_id}] Regex for inline 'PARSABLE OUTPUT' failed. Trying triple-backtick code fences for {power_name}.")
        code_fence_pattern = r"```json\n(.*?)\n```"
        matches = re.search(code_fence_pattern, raw_response, re.DOTALL)
        if matches: logger.debug(f"[{model_id}] Found triple-backtick JSON block for {power_name}.")

    json_text = None
    if matches:
        json_text = matches.group(1).strip()
        if not json_text.startswith("{"): # Ensure it's a valid JSON object start
             json_text = "{" + json_text # Add missing brace if needed (e.g. from pattern_alt)
        if not json_text.endswith("}"):
             json_text = json_text + "}"
    
    if not json_text:
        logger.debug(f"[{model_id}] No JSON text found in LLM response for {power_name}.")
        return None

    try:
        data = json.loads(json_text)
        return data.get("orders", None)
    except json.JSONDecodeError as e:
        logger.warning(f"[{model_id}] JSON decode failed for {power_name}: {e}. JSON text was: '{json_text}'. Trying bracket fallback.")
        bracket_pattern = r'["\']orders["\']\s*:\s*\[([^\]]*)\]' # orders: ['A BUD H']
        bracket_match = re.search(bracket_pattern, json_text, re.DOTALL)
        if bracket_match:
            try:
                raw_list_str = "[" + bracket_match.group(1).strip() + "]"
                moves = ast.literal_eval(raw_list_str)
                if isinstance(moves, list):
                    logger.debug(f"[{model_id}] Bracket fallback parse succeeded for {power_name}.")
                    return moves
            except Exception as e2:
                logger.warning(f"[{model_id}] Bracket fallback parse also failed for {power_name}: {e2}")
    
    logger.warning(f"[{model_id}] All move extraction attempts failed for {power_name}.")
    return None

class LLMInvalidOutputError(Exception):
    """Custom exception for invalid or unparsable LLM output in development mode."""
    def __init__(self, message, prompt=None, raw_response=None, proposed_moves=None, invalid_moves=None):
        super().__init__(message)
        self.prompt = prompt
        self.raw_response = raw_response
        self.proposed_moves = proposed_moves
        self.invalid_moves = invalid_moves

# Helper function to validate extracted orders (adapted from BaseModelClient)
def _validate_extracted_orders(
    game: Game, # Added game parameter for validation
    power_name: str,
    model_id: str, # For logging
    moves: List[str], 
    possible_orders: Dict[str, List[str]],
    fallback_utility_fn, # Function to call for fallback orders
    dev_mode: bool = False, # Added dev_mode
    # For detailed error reporting in dev_mode
    original_prompt: Optional[str] = None,
    raw_llm_response: Optional[str] = None
) -> List[str]:
    """
    Filter out invalid moves, fill missing with HOLD, else fallback.
    In dev_mode, raises LLMInvalidOutputError on critical failures.
    Returns a list of orders to be set for the power.
    """
    if not isinstance(moves, list):
        logger.warning(f"[{model_id}] Proposed moves for {power_name} not a list: {moves}.")
        if dev_mode:
            raise LLMInvalidOutputError(
                f"LLM output for {power_name} ({model_id}) was not a list of moves.",
                prompt=original_prompt,
                raw_response=raw_llm_response,
                proposed_moves=moves
            )
        return fallback_utility_fn(possible_orders)

    logger.debug(f"[{model_id}] Validating LLM proposed moves for {power_name}: {moves}")
    validated = []
    invalid_moves_found = []
    used_locs = set()

    # Create a flat list of all possible orders for quick lookup
    all_possible_orders = []
    for loc_orders in possible_orders.values():
        all_possible_orders.extend(loc_orders)
    all_possible_orders_set = set(all_possible_orders)

    for move_str in moves:
        if not move_str or not isinstance(move_str, str) or move_str.strip() == "": # Skip empty or non-string moves
            continue
        
        move_str = move_str.strip()
        
        # Check if the move is in the possible orders list (most reliable check)
        if move_str in all_possible_orders_set:
            validated.append(move_str)
            # Extract unit location from the move (first two parts: "A PAR" from "A PAR H")
            tokens = move_str.split()
            if len(tokens) >= 2:
                used_locs.add(tokens[1][:3]) # Add unit location (e.g., "PAR" from "A PAR H")
        else:
            logger.debug(f"[{model_id}] Invalid move from LLM for {power_name}: {move_str}")
            invalid_moves_found.append(move_str)
            
            # Additional diagnostic logging to help understand why the move is invalid
            tokens = move_str.split()
            if len(tokens) >= 2:
                unit_type = tokens[0]  # A or F
                unit_loc = tokens[1]   # PAR, BRE, etc.
                
                # Check if this power even has a unit at this location
                board_state = game.get_state()
                power_units = board_state.get("units", {}).get(power_name, [])
                expected_unit = f"{unit_type} {unit_loc}"
                
                if expected_unit not in power_units:
                    logger.warning(f"[{model_id}] {power_name} tried to order unit '{expected_unit}' but doesn't control it. {power_name} units: {power_units}")
                else:
                    logger.warning(f"[{model_id}] {power_name} has unit '{expected_unit}' but order '{move_str}' is not in possible orders for that unit.")

    if invalid_moves_found:
        logger.info(f"[{model_id}] Some LLM-proposed moves for {power_name} were invalid. Invalid: {invalid_moves_found}")
        if dev_mode:
            # Provide more detailed error information
            board_state = game.get_state()
            power_units = board_state.get("units", {}).get(power_name, [])
            error_details = []
            
            for invalid_move in invalid_moves_found:
                tokens = invalid_move.split()
                if len(tokens) >= 2:
                    unit_type = tokens[0]
                    unit_loc = tokens[1]
                    expected_unit = f"{unit_type} {unit_loc}"
                    
                    if expected_unit not in power_units:
                        error_details.append(f"'{invalid_move}' - {power_name} doesn't control unit {expected_unit}")
                    else:
                        error_details.append(f"'{invalid_move}' - not a valid order for unit {expected_unit}")
                else:
                    error_details.append(f"'{invalid_move}' - malformed order")
            
            detailed_message = f"LLM for {power_name} ({model_id}) produced invalid moves:\n" + "\n".join(error_details)
            detailed_message += f"\n\n{power_name} controls these units: {power_units}"
            
            raise LLMInvalidOutputError(
                detailed_message,
                prompt=original_prompt,
                raw_response=raw_llm_response,
                proposed_moves=moves,
                invalid_moves=invalid_moves_found
            )
    
    # Fill missing with hold (only if not in dev_mode or if no invalid_moves_found in dev_mode)
    if not (dev_mode and invalid_moves_found):
        for loc, orders_list in possible_orders.items():
            # Extract unit location from the key (e.g., "A PAR" -> "PAR")
            loc_parts = loc.split()
            if len(loc_parts) >= 2:
                unit_loc_prefix = loc_parts[1][:3]  # e.g., "PAR" from "A PAR"
            else:
                unit_loc_prefix = loc[:3]  # fallback
                
            if unit_loc_prefix not in used_locs and orders_list:
                hold_candidates = [o for o in orders_list if o.endswith(" H")]
                if hold_candidates:
                    validated.append(hold_candidates[0])
                    logger.debug(f"[{model_id}] Added HOLD for unassigned unit at {loc} for {power_name}.")
                elif orders_list:
                    validated.append(orders_list[0])
                    logger.debug(f"[{model_id}] Added first available order for unassigned unit at {loc} for {power_name}.")

    if not validated:
        logger.warning(f"[{model_id}] No valid orders could be confirmed for {power_name} after validation and hold fill. Using fallback.")
        if dev_mode: # If dev_mode is on and we still have no validated orders (e.g., LLM returned empty, or all were invalid and caught above)
             raise LLMInvalidOutputError(
                f"LLM for {power_name} ({model_id}) resulted in no valid orders even after attempting hold fills (or holds were skipped due to prior errors in dev_mode).",
                prompt=original_prompt,
                raw_response=raw_llm_response,
                proposed_moves=moves,
                invalid_moves=invalid_moves_found
            )
        return fallback_utility_fn(possible_orders)
    
    return validated


async def get_valid_orders(
    game: Game,
    model_id: str, # Changed from client
    agent_system_prompt: Optional[str], # Added system prompt
    board_state, # Already present
    power_name: str, # Already present
    possible_orders: Dict[str, List[str]], # Already present
    game_history, # Already present, assumed to be GameHistory instance
    game_id: str, # Added game_id parameter
    # --- New GameConfig dependent parameters ---
    config: 'GameConfig', # Pass GameConfig for dev_mode and other settings
    # --- End GameConfig dependent parameters ---
    agent_goals: Optional[List[str]] = None, # Already present
    agent_relationships: Optional[Dict[str, str]] = None, # Already present
    agent_private_diary_str: Optional[str] = None, # Already present
    log_file_path: str = None, # Already present
    phase: str = None, # Already present
    # dev_mode: bool = False # Added dev_mode, now part of config
) -> List[str]:
    """
    Generates orders using the specified LLM model, then validates and returns them.
    If generation or validation fails, returns fallback orders unless in dev_mode.
    """
    dev_mode = config.dev_mode # Get dev_mode from GameConfig
    coordinator = LocalLLMCoordinator()

    prompt = construct_order_generation_prompt(
        system_prompt=agent_system_prompt,
        game=game,
        board_state=board_state,
        power_name=power_name,
        possible_orders=possible_orders,
        game_history=game_history,
        agent_goals=agent_goals,
        agent_relationships=agent_relationships,
        agent_private_diary_str=agent_private_diary_str
    )

    if not prompt:
        logger.error(f"[{model_id}] Prompt construction failed for {power_name}. Using fallback orders.")
        # model_error_stats.setdefault(model_id, {}).setdefault("prompt_errors", 0)
        # model_error_stats[model_id]["prompt_errors"] += 1
        return _fallback_orders_utility(possible_orders)

    raw_response = ""
    llm_proposed_moves = None

    try:
        # Using the coordinator's request method which internally uses llm_call_internal
        # Parameters for llm_call_internal are game_id, agent_name, phase_str
        # Here, power_name can be used as agent_name for the call.
        # phase is already available as a parameter.
        raw_response = await coordinator.request(
            model_id=model_id,
            prompt_text=prompt,
            system_prompt_text=agent_system_prompt,
            game_id=game_id,
            agent_name=power_name, # Using power_name as agent_name
            phase_str=phase,       # Using phase as phase_str
            request_identifier=f"{power_name}-{phase}-order_gen"
        )

        llm_proposed_moves = _extract_moves_from_llm_response(raw_response, power_name, model_id)
        if llm_proposed_moves is None and dev_mode:
            raise LLMInvalidOutputError(
                f"Failed to extract any moves from LLM response for {power_name} ({model_id}).",
                prompt=prompt,
                raw_response=raw_response
            )

    except Exception as e:
        logger.error(f"[{model_id}] Error during LLM call for {power_name}: {e}", exc_info=True)
        if dev_mode:
            # If the error is already our custom one, re-raise it. Otherwise, wrap it.
            if isinstance(e, LLMInvalidOutputError):
                raise
            raise LLMInvalidOutputError(
                f"LLM call failed for {power_name} ({model_id}): {e}",
                prompt=prompt,
                raw_response=raw_response # raw_response might be empty if error was before/during call
            ) from e
        # Fallback if not dev_mode or if we want to ensure _validate_extracted_orders handles it
        # No, if LLM call fails, llm_proposed_moves will be None, and _validate will use fallback.

    # Validate and fill missing orders (pass dev_mode and raw_response for error reporting)
    return _validate_extracted_orders(
        game=game,
        power_name=power_name, 
        model_id=model_id,
        moves=llm_proposed_moves if llm_proposed_moves is not None else [], # Pass empty list if None
        possible_orders=possible_orders, 
        fallback_utility_fn=_fallback_orders_utility,
        dev_mode=dev_mode,
        original_prompt=prompt,
        raw_llm_response=raw_response
    )


def normalize_and_compare_orders(
    issued_orders: Dict[str, List[str]],
    accepted_orders_dict: Dict[str, List[str]],
    game: Game,
) -> Tuple[Dict[str, Set[str]], Dict[str, Set[str]]]:
    """
    Normalizes and compares issued orders against accepted orders from the game engine.
    Uses the map's built-in normalization methods to ensure consistent formatting.

    Args:
        issued_orders: Dictionary of orders issued by power {power_name: [orders]}
        accepted_orders_dict: Dictionary of orders accepted by the engine,
                              typically from game.get_state()["orders"].
        game: The current Game object containing the map.

    Returns:
        Tuple[Dict[str, Set[str]], Dict[str, Set[str]]]: (orders_not_accepted, orders_not_issued)
            - orders_not_accepted: Orders issued but not accepted by engine (normalized).
            - orders_not_issued: Orders accepted by engine but not issued (normalized).
    """
    game_map = game.map

    def normalize_order(order: str) -> str:
        # Inner function to normalize a single order string using the game map.
        if not order:
            return order

        try:
            # Use map's normalization methods directly
            normalized = game_map.norm(order)
            # Further split and normalize parts for complex orders if necessary
            # (This part might need refinement depending on how complex orders are handled
            #  and represented after initial normalization by game_map.norm)

            # Example (simplified, game_map.norm often handles this):
            # Split support orders
            # parts = normalized.split(" S ")
            # normalized_parts = []
            # for part in parts:
            #     move_parts = part.split(" - ")
            #     move_parts = [game_map.norm(p.strip()) for p in move_parts]
            #     move_parts = [game_map.aliases.get(p, p) for p in move_parts]
            #     normalized_parts.append(" - ".join(move_parts))
            # return " S ".join(normalized_parts)

            return normalized  # Return the directly normalized string for now
        except Exception as e:
            logger.warning(f"Could not normalize order '{order}': {e}")
            return order  # Return original if normalization fails

    orders_not_accepted = {}
    orders_not_issued = {}

    all_powers = set(issued_orders.keys()) | set(accepted_orders_dict.keys())

    for pwr in all_powers:
        # Normalize issued orders for the power, handling potential absence
        issued_set = set()
        if pwr in issued_orders:
            try:
                issued_set = {normalize_order(o) for o in issued_orders.get(pwr, []) if o}
            except Exception as e:
                logger.error(f"Error normalizing issued orders for {pwr}: {e}")

        # Normalize accepted orders for the power, handling potential absence
        accepted_set = set()
        if pwr in accepted_orders_dict:
            try:
                accepted_set = {normalize_order(o) for o in accepted_orders_dict.get(pwr, []) if o}
            except Exception as e:
                logger.error(f"Error normalizing accepted orders for {pwr}: {e}")

        # Compare the sets
        missing_from_engine = issued_set - accepted_set
        missing_from_issued = accepted_set - issued_set

        if missing_from_engine:
            orders_not_accepted[pwr] = missing_from_engine
        if missing_from_issued:
            orders_not_issued[pwr] = missing_from_issued

    return orders_not_accepted, orders_not_issued


# == New LLM Response Logging Function ==
def log_llm_response(
    log_file_path: str,
    model_name: str,
    power_name: Optional[str], # Optional for non-power-specific calls like summary
    phase: str,
    response_type: str,
    raw_input_prompt: str, # Kept for compatibility, but will not be logged
    raw_response: str,
    success: str,  # Changed from bool to str
):
    """
    Log only the LLM response and minimal metadata to the CSV. Do NOT log the full prompt/context to avoid huge files.
    """
    import os
    # Only log minimal fields
    log_fields = ["model", "power", "phase", "response_type", "raw_response", "success"]
    log_row = [model_name, power_name or "", phase, response_type, raw_response, success]
    file_exists = os.path.isfile(log_file_path)
    with open(log_file_path, mode="a", newline="", encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        if not file_exists:
            writer.writerow(log_fields)
        writer.writerow(log_row)


# run_llm_and_log is now obsolete and removed.
# LLM calls are made directly using llm.get_model().async_prompt()
# and logging is handled by calling log_llm_response() immediately after.


================================================
File: agents/__init__.py
================================================
# Agent implementations - may depend on LLM + MCP services 


================================================
File: agents/base.py
================================================
"""
Abstract base agent interface.
Defines the contract all agents must implement without coupling to specific LLM providers.
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any
from ..core.state import PhaseState


class Order:
    """Represents a single diplomatic order."""
    def __init__(self, order_text: str):
        self.order_text = order_text.strip()
    
    def __str__(self) -> str:
        return self.order_text
    
    def __repr__(self) -> str:
        return f"Order('{self.order_text}')"


class Message:
    """Represents a diplomatic message between powers."""
    def __init__(self, recipient: str, content: str, message_type: str = "private"):
        self.recipient = recipient
        self.content = content
        self.message_type = message_type  # "private" or "global"
    
    def to_dict(self) -> Dict[str, str]:
        return {
            "recipient": self.recipient,
            "content": self.content,
            "message_type": self.message_type
        }


class BaseAgent(ABC):
    """
    Abstract base class for all diplomacy agents.
    
    Key principles:
    - Agents receive frozen PhaseState objects (no direct game access)
    - Agents return orders and messages (no side effects)
    - Agents can maintain internal state but must not modify game state
    - Agent API is stable across different implementations (LLM, scripted, etc.)
    """
    
    def __init__(self, agent_id: str, country: str):
        """
        Initialize the agent.
        
        Args:
            agent_id: Unique identifier for this agent instance
            country: The country/power this agent represents (e.g., "FRANCE")
        """
        self.agent_id = agent_id
        self.country = country.upper()
    
    @abstractmethod
    async def decide_orders(self, phase: PhaseState) -> List[Order]:
        """
        Decide what orders to submit for the current phase.
        
        Args:
            phase: Immutable snapshot of current game state
            
        Returns:
            List of orders to submit
        """
        pass
    
    @abstractmethod
    async def negotiate(self, phase: PhaseState) -> List[Message]:
        """
        Generate diplomatic messages to send to other powers.
        
        Args:
            phase: Immutable snapshot of current game state
            
        Returns:
            List of messages to send
        """
        pass
    
    @abstractmethod
    async def update_state(self, phase: PhaseState, events: List[Dict[str, Any]]) -> None:
        """
        Update internal agent state based on phase results and events.
        
        Args:
            phase: The phase that just completed
            events: List of events that occurred (orders resolved, messages sent, etc.)
        """
        pass
    
    def get_agent_info(self) -> Dict[str, Any]:
        """
        Return basic information about this agent.
        
        Returns:
            Dictionary with agent metadata
        """
        return {
            "agent_id": self.agent_id,
            "country": self.country,
            "type": self.__class__.__name__
        } 


================================================
File: agents/factory.py
================================================
"""
Agent factory for creating different types of agents based on configuration.
"""
import logging
from typing import Dict, Any, Optional

from .base import BaseAgent
from .llm_agent import LLMAgent
from .scripted_agent import ScriptedAgent
from ..services.config import AgentConfig, DiplomacyConfig
from ..services.llm_coordinator import LLMCoordinator
from ..services.context_provider import ContextProviderFactory

logger = logging.getLogger(__name__)


class AgentFactory:
    """
    Factory for creating different types of agents based on configuration.
    
    Supports both LLM and scripted agents, with clean separation between
    agent creation and game engine logic.
    """
    
    def __init__(self, llm_coordinator: Optional[LLMCoordinator] = None, context_provider_factory: Optional[ContextProviderFactory] = None):
        """
        Initialize the agent factory.
        
        Args:
            llm_coordinator: Shared LLM coordinator instance (will create if None)
            context_provider_factory: Shared context provider factory (will create if None)
        """
        self.llm_coordinator = llm_coordinator or LLMCoordinator()
        self.context_provider_factory = context_provider_factory or ContextProviderFactory()
        logger.info("AgentFactory initialized")
    
    def create_agent(
        self, 
        agent_id: str,
        country: str,
        config: AgentConfig,
        game_id: str = "unknown_game"
    ) -> BaseAgent:
        """
        Create an agent based on the provided configuration.
        
        Args:
            agent_id: Unique identifier for the agent
            country: Country/power the agent represents
            config: Agent configuration
            game_id: Game identifier for tracking
            
        Returns:
            A BaseAgent instance
            
        Raises:
            ValueError: If agent type is not supported
        """
        logger.info(f"Creating {config.type} agent for {country} with ID {agent_id}")
        
        if config.type == "llm":
            return self._create_llm_agent(agent_id, country, config, game_id)
        elif config.type == "scripted":
            return self._create_scripted_agent(agent_id, country, config)
        else:
            raise ValueError(f"Unsupported agent type: {config.type}")
    
    def _create_llm_agent(
        self, 
        agent_id: str, 
        country: str, 
        config: AgentConfig, 
        game_id: str
    ) -> LLMAgent:
        """Create an LLM-based agent."""
        if not config.model_id:
            raise ValueError(f"LLM agent for {country} requires model_id in config")
        
        return LLMAgent(
            agent_id=agent_id,
            country=country,
            config=config,
            game_id=game_id,
            llm_coordinator=self.llm_coordinator,
            context_provider_factory=self.context_provider_factory
        )
    
    def _create_scripted_agent(
        self, 
        agent_id: str, 
        country: str, 
        config: AgentConfig
    ) -> ScriptedAgent:
        """Create a scripted agent."""
        # Use personality from config if available, otherwise default to neutral
        personality = getattr(config, 'personality', 'neutral')
        
        return ScriptedAgent(
            agent_id=agent_id,
            country=country,
            personality=personality
        )
    
    def create_agents_from_config(
        self, 
        diplomacy_config: DiplomacyConfig,
        game_id: str = "unknown_game"
    ) -> Dict[str, BaseAgent]:
        """
        Create all agents defined in a DiplomacyConfig.
        
        Args:
            diplomacy_config: Complete diplomacy configuration
            game_id: Game identifier for tracking
            
        Returns:
            Dictionary mapping country names to agent instances
        """
        agents = {}
        
        for agent_config in diplomacy_config.agents:
            try:
                agent_id = f"{agent_config.country.lower()}_{game_id}"
                agent = self.create_agent(
                    agent_id=agent_id,
                    country=agent_config.country,
                    config=agent_config,
                    game_id=game_id
                )
                agents[agent_config.country] = agent
                logger.info(f"Created agent for {agent_config.country}")
                
            except Exception as e:
                logger.error(f"Failed to create agent for {agent_config.country}: {e}", exc_info=True)
                # Continue creating other agents
        
        logger.info(f"Created {len(agents)} agents from configuration")
        return agents
    
    def validate_agent_config(self, config: AgentConfig) -> bool:
        """
        Validate that an agent configuration is valid.
        
        Args:
            config: Agent configuration to validate
            
        Returns:
            True if valid, False otherwise
        """
        try:
            # Check required fields
            if not config.country or not config.type:
                logger.error(f"Agent config missing required fields: country={config.country}, type={config.type}")
                return False
            
            # Validate agent type
            if config.type not in ["llm", "scripted"]:
                logger.error(f"Invalid agent type: {config.type}")
                return False
            
            # LLM agents need model_id
            if config.type == "llm" and not config.model_id:
                logger.error(f"LLM agent for {config.country} missing model_id")
                return False
            
            # Validate country name
            if config.country not in ["AUSTRIA", "ENGLAND", "FRANCE", "GERMANY", "ITALY", "RUSSIA", "TURKEY"]:
                logger.error(f"Invalid country: {config.country}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Error validating agent config: {e}", exc_info=True)
            return False 


================================================
File: agents/llm_agent.py
================================================
"""
LLM-based agent implementation.
Extracts all LLM-specific logic from the original DiplomacyAgent while implementing the clean BaseAgent interface.
"""
import logging
from typing import List, Dict, Optional, Any

from .base import BaseAgent, Order, Message, PhaseState
from ..services.llm_coordinator import LLMCoordinator, LLMCallResult
from ..services.config import AgentConfig, resolve_context_provider
from ..services.context_provider import ContextProviderFactory, ContextData
from .. import llm_utils
from .. import prompt_utils

logger = logging.getLogger(__name__)

# Constants moved from agent.py
ALL_POWERS = frozenset({"AUSTRIA", "ENGLAND", "FRANCE", "GERMANY", "ITALY", "RUSSIA", "TURKEY"})
ALLOWED_RELATIONSHIPS = ["Enemy", "Unfriendly", "Neutral", "Friendly", "Ally"]


class LLMAgent(BaseAgent):
    """
    LLM-based diplomacy agent that implements the BaseAgent interface.
    
    This agent uses Large Language Models to make decisions, maintain relationships,
    and generate diplomatic communications. It receives immutable PhaseState objects
    and returns orders/messages without direct game engine access.
    """
    
    def __init__(
        self, 
        agent_id: str, 
        country: str,
        config: AgentConfig,
        game_id: str = "unknown_game",
        llm_coordinator: Optional[LLMCoordinator] = None,
        context_provider_factory: Optional[ContextProviderFactory] = None
    ):
        """
        Initialize the LLM agent.
        
        Args:
            agent_id: Unique identifier for this agent instance
            country: The country/power this agent represents
            config: Agent configuration containing model_id and other settings
            game_id: Game identifier for tracking
            llm_coordinator: LLM coordinator instance (will create if None)
            context_provider_factory: Context provider factory (will create if None)
        """
        super().__init__(agent_id, country)
        self.config = config
        self.game_id = game_id
        self.llm_coordinator = llm_coordinator or LLMCoordinator()
        
        # Context provider setup
        self.context_factory = context_provider_factory or ContextProviderFactory()
        self.resolved_context_provider_type = resolve_context_provider(config)
        self.context_provider = self.context_factory.get_provider(self.resolved_context_provider_type)
        
        # Update resolved type to reflect actual provider used (handles fallbacks)
        self.resolved_context_provider_type = self.context_provider.get_provider_type()
        
        # Agent state
        self.goals: List[str] = []
        self.relationships: Dict[str, str] = {p: "Neutral" for p in ALL_POWERS if p != self.country}
        self.private_journal: List[str] = []
        self.private_diary: List[str] = []
        
        # Load system prompt
        self.system_prompt = self._load_system_prompt()
        
        logger.info(f"Initialized LLMAgent for {self.country} with model {self.config.model_id}, context provider: {self.resolved_context_provider_type}")
        self.add_journal_entry(f"Agent initialized with model {self.config.model_id}, context provider: {self.resolved_context_provider_type}")
    
    def _load_system_prompt(self) -> Optional[str]:
        """Load power-specific or default system prompt."""
        power_prompt_filename = f"{self.country.lower()}_system_prompt.txt"
        default_prompt_filename = "system_prompt.txt"
        
        system_prompt = llm_utils.load_prompt_file(power_prompt_filename)
        if not system_prompt:
            logger.warning(f"Power-specific prompt '{power_prompt_filename}' not found. Loading default.")
            system_prompt = llm_utils.load_prompt_file(default_prompt_filename)
        else:
            logger.info(f"Loaded power-specific system prompt for {self.country}.")
        
        if not system_prompt:
            logger.error(f"Could not load system prompt for {self.country}!")
        
        return system_prompt
    
    def add_journal_entry(self, entry: str):
        """Add an entry to the agent's private journal."""
        if not isinstance(entry, str):
            entry = str(entry)
        self.private_journal.append(entry)
        logger.debug(f"[{self.country} Journal]: {entry}")
    
    def add_diary_entry(self, entry: str, phase: str):
        """Add an entry to the agent's private diary."""
        if not isinstance(entry, str):
            entry = str(entry)
        formatted_entry = f"[{phase}] {entry}"
        self.private_diary.append(formatted_entry)
        logger.info(f"[{self.country}] DIARY ENTRY ADDED for {phase}: {entry[:100]}...")
    
    def format_private_diary_for_prompt(self, max_entries: int = 40) -> str:
        """Format diary entries for inclusion in prompts."""
        if not self.private_diary:
            return "(No diary entries yet)"
        
        # Take the most recent entries
        recent_entries = self.private_diary[-max_entries:] if len(self.private_diary) > max_entries else self.private_diary
        return "\n".join(recent_entries)
    
    async def decide_orders(self, phase: PhaseState) -> List[Order]:
        """
        Decide what orders to submit for the current phase.
        
        Args:
            phase: Immutable snapshot of current game state
            
        Returns:
            List of orders to submit
        """
        logger.info(f"[{self.country}] Deciding orders for phase {phase.phase_name}")
        
        # Check if we have units to command
        my_units = phase.get_power_units(self.country)
        if not my_units:
            logger.info(f"[{self.country}] No units to command")
            return []
        
        # Build context using context provider
        try:
            # Prepare context data (simplified for now - in real implementation would include more details)
            context_data = ContextData(
                phase_state=phase,
                possible_orders={"MOCK": ["Hold"]},  # TODO: Get real possible orders
                game_history=None,
                recent_messages=None,
                strategic_analysis=None
            )
            
            # Get context from provider
            context_result = await self.context_provider.provide_context(
                agent_id=self.agent_id,
                country=self.country,
                context_data=context_data,
                agent_config=self.config
            )
            
            # Build prompt using context
            prompt = self._build_order_prompt_with_context(phase, context_result)
            
            # Call LLM
            result = await self.llm_coordinator.call_json(
                prompt=prompt,
                model_id=self.config.model_id,
                agent_id=self.agent_id,
                game_id=self.game_id,
                phase=phase.phase_name,
                system_prompt=self.system_prompt,
                expected_fields=["orders"],
                tools=context_result.get("tools", []) if context_result.get("tools_available") else None
            )
            
            # Extract orders from response
            orders = self._extract_orders_from_response(result, my_units)
            
            logger.info(f"[{self.country}] Generated {len(orders)} orders using {context_result.get('provider_type', 'unknown')} context")
            return orders
            
        except Exception as e:
            logger.error(f"[{self.country}] Error deciding orders: {e}", exc_info=True)
            # Fallback: hold all units
            return [Order(f"{unit} H") for unit in my_units]
    
    def _build_order_prompt(self, phase: PhaseState) -> str:
        """Build prompt for order generation (legacy method)."""
        # This is a simplified version - in real implementation this would be more sophisticated
        prompt = f"""
        You are playing as {self.country} in Diplomacy.
        
        Current Phase: {phase.phase_name}
        Your Units: {phase.get_power_units(self.country)}
        Your Centers: {phase.get_power_centers(self.country)}
        
        Your Goals: {self.goals}
        Your Relationships: {self.relationships}
        
        Recent Diary: {self.format_private_diary_for_prompt()}
        
        Decide your orders for this phase. Return JSON with "orders" field containing a list of order strings.
        """
        return prompt
    
    def _build_order_prompt_with_context(self, phase: PhaseState, context_result: Dict[str, Any]) -> str:
        """Build prompt for order generation using context provider."""
        base_instructions = f"""
You are playing as {self.country} in Diplomacy.

Your Goals: {self.goals}
Your Relationships: {self.relationships}

Recent Diary: {self.format_private_diary_for_prompt()}

{context_result.get('context_text', '')}

Decide your orders for this phase. Return JSON with "orders" field containing a list of order strings.
        """.strip()
        
        # If using MCP tools, add tool usage instructions
        if context_result.get("tools_available"):
            base_instructions += """

IMPORTANT: You have access to tools to get detailed game information. Use them to gather the information you need before deciding on orders.
            """
        
        return base_instructions
    
    def _extract_orders_from_response(self, response: Dict[str, Any], my_units: List[str]) -> List[Order]:
        """Extract and validate orders from LLM response."""
        orders = []
        
        if "orders" not in response:
            logger.warning(f"[{self.country}] No 'orders' field in LLM response")
            return [Order(f"{unit} H") for unit in my_units]  # Default to hold
        
        order_strings = response["orders"]
        if not isinstance(order_strings, list):
            logger.warning(f"[{self.country}] Orders field is not a list")
            return [Order(f"{unit} H") for unit in my_units]
        
        for order_str in order_strings:
            if isinstance(order_str, str) and order_str.strip():
                orders.append(Order(order_str.strip()))
        
        # If no valid orders, default to holding
        if not orders:
            orders = [Order(f"{unit} H") for unit in my_units]
        
        return orders
    
    async def negotiate(self, phase: PhaseState) -> List[Message]:
        """
        Generate diplomatic messages to send to other powers.
        
        Args:
            phase: Immutable snapshot of current game state
            
        Returns:
            List of messages to send
        """
        logger.info(f"[{self.country}] Generating messages for phase {phase.phase_name}")
        
        try:
            # Prepare context data for negotiations
            context_data = ContextData(
                phase_state=phase,
                possible_orders={"MOCK": ["Hold"]},  # TODO: Get real possible orders
                game_history=None,
                recent_messages=None,
                strategic_analysis=None
            )
            
            # Get context from provider
            context_result = await self.context_provider.provide_context(
                agent_id=self.agent_id,
                country=self.country,
                context_data=context_data,
                agent_config=self.config
            )
            
            # Build prompt using context
            prompt = self._build_negotiation_prompt_with_context(phase, context_result)
            
            # Call LLM
            result = await self.llm_coordinator.call_json(
                prompt=prompt,
                model_id=self.config.model_id,
                agent_id=self.agent_id,
                game_id=self.game_id,
                phase=phase.phase_name,
                system_prompt=self.system_prompt,
                expected_fields=["messages"],
                tools=context_result.get("tools", []) if context_result.get("tools_available") else None
            )
            
            # Extract messages from response
            messages = self._extract_messages_from_response(result, phase)
            
            logger.info(f"[{self.country}] Generated {len(messages)} messages using {context_result.get('provider_type', 'unknown')} context")
            return messages
            
        except Exception as e:
            logger.error(f"[{self.country}] Error generating messages: {e}", exc_info=True)
            return []
    
    def _build_negotiation_prompt(self, phase: PhaseState) -> str:
        """Build prompt for message generation (legacy method)."""
        active_powers = [p for p in phase.powers if not phase.is_power_eliminated(p) and p != self.country]
        
        prompt = f"""
        You are playing as {self.country} in Diplomacy.
        
        Current Phase: {phase.phase_name}
        Active Powers: {", ".join(active_powers)}
        
        Your Goals: {self.goals}
        Your Relationships: {self.relationships}
        
        Recent Diary: {self.format_private_diary_for_prompt()}
        
        Generate diplomatic messages to send to other powers. 
        Return JSON with "messages" field containing a list of message objects.
        Each message should have "recipient", "content", and "message_type" fields.
        """
        return prompt
    
    def _build_negotiation_prompt_with_context(self, phase: PhaseState, context_result: Dict[str, Any]) -> str:
        """Build prompt for message generation using context provider."""
        active_powers = [p for p in phase.powers if not phase.is_power_eliminated(p) and p != self.country]
        
        base_instructions = f"""
You are playing as {self.country} in Diplomacy.
Active Powers: {", ".join(active_powers)}

Your Goals: {self.goals}
Your Relationships: {self.relationships}

Recent Diary: {self.format_private_diary_for_prompt()}

{context_result.get('context_text', '')}

Generate diplomatic messages to send to other powers. 
Return JSON with "messages" field containing a list of message objects.
Each message should have "recipient", "content", and "message_type" fields.
        """.strip()
        
        # If using MCP tools, add tool usage instructions
        if context_result.get("tools_available"):
            base_instructions += """

IMPORTANT: You have access to tools to get detailed game information. Use them to understand the current situation before writing messages.
            """
        
        return base_instructions
    
    def _extract_messages_from_response(self, response: Dict[str, Any], phase: PhaseState) -> List[Message]:
        """Extract and validate messages from LLM response."""
        messages = []
        
        if "messages" not in response:
            return messages
        
        message_dicts = response["messages"]
        if not isinstance(message_dicts, list):
            return messages
        
        for msg_dict in message_dicts:
            if not isinstance(msg_dict, dict):
                continue
            
            recipient = msg_dict.get("recipient", "").upper()
            content = msg_dict.get("content", "")
            message_type = msg_dict.get("message_type", "private")
            
            if content and recipient:
                # Validate recipient
                if recipient in phase.powers or recipient == "GLOBAL":
                    messages.append(Message(recipient, content, message_type))
                else:
                    logger.warning(f"[{self.country}] Invalid recipient: {recipient}")
        
        return messages
    
    async def update_state(self, phase: PhaseState, events: List[Dict[str, Any]]) -> None:
        """
        Update internal agent state based on phase results and events.
        
        Args:
            phase: The phase that just completed
            events: List of events that occurred
        """
        logger.info(f"[{self.country}] Updating state after phase {phase.phase_name}")
        
        # Generate a diary entry about the phase results
        await self._generate_phase_diary_entry(phase, events)
        
        # Update relationships based on events
        self._update_relationships_from_events(events)
        
        # Optionally update goals based on game state analysis
        await self._analyze_and_update_goals(phase)
    
    async def _generate_phase_diary_entry(self, phase: PhaseState, events: List[Dict[str, Any]]):
        """Generate a diary entry reflecting on the phase results."""
        try:
            prompt = f"""
            You are {self.country}. The phase {phase.phase_name} just ended.
            
            Current situation:
            - Your units: {phase.get_power_units(self.country)}
            - Your centers: {phase.get_power_centers(self.country)}
            - Game over: {phase.is_game_over}
            
            Events that occurred: {events}
            
            Your current goals: {self.goals}
            Your relationships: {self.relationships}
            
            Write a brief diary entry reflecting on what happened this phase.
            Return JSON with "diary_entry" field.
            """
            
            result = await self.llm_coordinator.call_json(
                prompt=prompt,
                model_id=self.config.model_id,
                agent_id=self.agent_id,
                game_id=self.game_id,
                phase=phase.phase_name,
                system_prompt=self.system_prompt,
                expected_fields=["diary_entry"]
            )
            
            diary_text = result.get("diary_entry", f"Phase {phase.phase_name} completed.")
            self.add_diary_entry(diary_text, phase.phase_name)
            
        except Exception as e:
            logger.error(f"[{self.country}] Error generating diary entry: {e}", exc_info=True)
            self.add_diary_entry(f"Phase {phase.phase_name} completed (diary generation failed).", phase.phase_name)
    
    def _update_relationships_from_events(self, events: List[Dict[str, Any]]):
        """Update relationships based on game events."""
        for event in events:
            event_type = event.get("type")
            
            if event_type == "attack":
                attacker = event.get("attacker")
                target = event.get("target")
                
                if target == self.country and attacker in self.relationships:
                    # We were attacked - worsen relationship
                    current = self.relationships[attacker]
                    if current == "Ally":
                        self.relationships[attacker] = "Friendly"
                    elif current == "Friendly":
                        self.relationships[attacker] = "Neutral"
                    elif current == "Neutral":
                        self.relationships[attacker] = "Unfriendly"
                    elif current == "Unfriendly":
                        self.relationships[attacker] = "Enemy"
                    
                    logger.info(f"[{self.country}] {attacker} attacked us, relationship now: {self.relationships[attacker]}")
            
            elif event_type == "support":
                supporter = event.get("supporter")
                supported = event.get("supported")
                
                if supported == self.country and supporter in self.relationships:
                    # We were supported - improve relationship
                    current = self.relationships[supporter]
                    if current == "Enemy":
                        self.relationships[supporter] = "Unfriendly"
                    elif current == "Unfriendly":
                        self.relationships[supporter] = "Neutral"
                    elif current == "Neutral":
                        self.relationships[supporter] = "Friendly"
                    elif current == "Friendly":
                        self.relationships[supporter] = "Ally"
                    
                    logger.info(f"[{self.country}] {supporter} supported us, relationship now: {self.relationships[supporter]}")
    
    async def _analyze_and_update_goals(self, phase: PhaseState):
        """Analyze current situation and potentially update goals."""
        try:
            # Simple goal analysis - more sophisticated logic could be added
            my_center_count = phase.get_center_count(self.country)
            
            # Basic goal updates based on situation
            new_goals = []
            
            if my_center_count < 3:
                new_goals.append("Survive and avoid elimination")
            elif my_center_count < 8:
                new_goals.append("Expand territory and gain supply centers")
            else:
                new_goals.append("Consolidate position and prepare for victory")
            
            # Check if anyone is getting too strong
            max_centers = max(phase.get_center_count(p) for p in phase.powers if not phase.is_power_eliminated(p))
            if max_centers > 10 and phase.get_center_count(self.country) != max_centers:
                new_goals.append("Form coalition against the leader")
            
            # Update goals if they've changed significantly
            if new_goals != self.goals:
                old_goals = self.goals.copy()
                self.goals = new_goals
                self.add_journal_entry(f"Goals updated from {old_goals} to {new_goals}")
                
        except Exception as e:
            logger.error(f"[{self.country}] Error analyzing goals: {e}", exc_info=True)
    
    def get_agent_info(self) -> Dict[str, Any]:
        """Return information about this agent."""
        return {
            "agent_id": self.agent_id,
            "country": self.country,
            "type": "LLMAgent",
            "model_id": self.config.model_id,
            "goals": self.goals,
            "relationships": self.relationships,
            "diary_entries": len(self.private_diary),
            "journal_entries": len(self.private_journal)
        } 


================================================
File: agents/scripted_agent.py
================================================
"""
Scripted agent implementation using hand-written heuristics.
Useful for testing and as a baseline for LLM agent performance.
"""
import random
from typing import List, Dict, Any
from .base import BaseAgent, Order, Message, PhaseState


class ScriptedAgent(BaseAgent):
    """
    Simple scripted agent with basic diplomatic heuristics.
    Makes reasonable but predictable moves without LLM calls.
    """
    
    def __init__(self, agent_id: str, country: str, personality: str = "neutral"):
        """
        Initialize scripted agent.
        
        Args:
            agent_id: Unique identifier
            country: Country/power name
            personality: Agent personality ("aggressive", "defensive", "neutral")
        """
        super().__init__(agent_id, country)
        self.personality = personality
        self.relationships = {}  # country -> relationship score (-1 to 1)
        self.priorities = []  # List of strategic priorities
        
        # Initialize relationships as neutral
        self._initialize_relationships()
    
    def _initialize_relationships(self):
        """Initialize neutral relationships with all powers."""
        all_countries = ["FRANCE", "GERMANY", "RUSSIA", "ENGLAND", "ITALY", "AUSTRIA", "TURKEY"]
        for country in all_countries:
            if country != self.country:
                self.relationships[country] = 0.0  # Neutral
    
    async def decide_orders(self, phase: PhaseState) -> List[Order]:
        """
        Decide orders based on simple heuristics.
        
        Args:
            phase: Current game state
            
        Returns:
            List of orders to submit
        """
        orders = []
        my_units = phase.get_power_units(self.country)
        
        if not my_units:
            return orders
        
        # Simple strategy based on phase type and personality
        if phase.phase_type == "MOVEMENT":
            orders = self._decide_movement_orders(phase, my_units)
        elif phase.phase_type == "RETREAT":
            orders = self._decide_retreat_orders(phase, my_units)
        elif phase.phase_type == "ADJUSTMENT":
            orders = self._decide_adjustment_orders(phase)
        
        return orders
    
    def _decide_movement_orders(self, phase: PhaseState, my_units: List[str]) -> List[Order]:
        """Decide movement orders based on simple heuristics."""
        orders = []
        
        for unit in my_units:
            # Parse unit info (e.g., "A PAR" -> Army in Paris)
            unit_parts = unit.split()
            if len(unit_parts) >= 2:
                unit_type = unit_parts[0]  # A or F
                location = unit_parts[1]
                
                # Simple movement strategy
                if self.personality == "aggressive":
                    # Try to move toward enemy supply centers
                    order = self._aggressive_move(unit_type, location, phase)
                elif self.personality == "defensive":
                    # Try to defend own supply centers
                    order = self._defensive_move(unit_type, location, phase)
                else:
                    # Neutral: balanced expansion and defense
                    order = self._neutral_move(unit_type, location, phase)
                
                if order:
                    orders.append(Order(order))
        
        return orders
    
    def _aggressive_move(self, unit_type: str, location: str, phase: PhaseState) -> str:
        """Generate aggressive movement orders."""
        # Simple aggressive strategy: move toward nearest enemy center
        # This is a placeholder - real implementation would need map knowledge
        possible_moves = self._get_possible_moves(unit_type, location)
        if possible_moves:
            # Pick a random valid move (in real implementation, pick strategically)
            target = random.choice(possible_moves)
            return f"{unit_type} {location} - {target}"
        else:
            return f"{unit_type} {location} H"  # Hold if no moves available
    
    def _defensive_move(self, unit_type: str, location: str, phase: PhaseState) -> str:
        """Generate defensive movement orders."""
        my_centers = phase.get_power_centers(self.country)
        
        # If this unit is defending a supply center, hold
        if location in my_centers:
            return f"{unit_type} {location} H"
        
        # Otherwise, try to move to support a supply center
        possible_moves = self._get_possible_moves(unit_type, location)
        for move in possible_moves:
            if move in my_centers:
                return f"{unit_type} {location} - {move}"
        
        # Default to hold
        return f"{unit_type} {location} H"
    
    def _neutral_move(self, unit_type: str, location: str, phase: PhaseState) -> str:
        """Generate balanced movement orders."""
        # Mix of aggressive and defensive with some randomness
        if random.random() < 0.7:  # 70% chance to be defensive
            return self._defensive_move(unit_type, location, phase)
        else:
            return self._aggressive_move(unit_type, location, phase)
    
    def _get_possible_moves(self, unit_type: str, location: str) -> List[str]:
        """
        Get possible moves for a unit.
        This is a simplified placeholder - real implementation needs map data.
        """
        # Placeholder: return some adjacent territories
        # In reality, this would consult the game map
        adjacencies = {
            "PAR": ["BUR", "PIC", "BRE"],
            "MAR": ["SPA", "PIE", "BUR"],
            "BRE": ["PAR", "PIC", "GAS"],
            # Add more as needed...
        }
        return adjacencies.get(location, [])
    
    def _decide_retreat_orders(self, phase: PhaseState, my_units: List[str]) -> List[Order]:
        """Decide retreat orders."""
        orders = []
        # Simple retreat strategy: retreat to the safest adjacent territory
        # This would need more sophisticated logic in a real implementation
        for unit in my_units:
            # For now, just disband (this is overly simplistic)
            orders.append(Order(f"{unit} D"))
        return orders
    
    def _decide_adjustment_orders(self, phase: PhaseState) -> List[Order]:
        """Decide build/remove orders."""
        orders = []
        my_centers = phase.get_power_centers(self.country)
        my_units = phase.get_power_units(self.country)
        
        unit_count = len(my_units)
        center_count = len(my_centers)
        
        if center_count > unit_count:
            # Can build units
            builds_needed = center_count - unit_count
            # Simple build strategy: build armies in home centers
            # This would need map knowledge in real implementation
            for i in range(builds_needed):
                orders.append(Order(f"A {self.country[:3]} B"))  # Build army in capital
        elif unit_count > center_count:
            # Must remove units
            removes_needed = unit_count - center_count
            # Remove the "least important" units (simplified)
            for i in range(min(removes_needed, len(my_units))):
                unit = my_units[i]
                orders.append(Order(f"{unit} D"))  # Disband
        
        return orders
    
    async def negotiate(self, phase: PhaseState) -> List[Message]:
        """
        Generate diplomatic messages based on simple patterns.
        
        Args:
            phase: Current game state
            
        Returns:
            List of messages to send
        """
        messages = []
        
        # Simple messaging strategy based on personality
        if random.random() < 0.3:  # 30% chance to send a message each phase
            target_country = self._choose_negotiation_target(phase)
            if target_country:
                message_content = self._generate_message_content(target_country, phase)
                messages.append(Message(
                    recipient=target_country,
                    content=message_content,
                    message_type="private"
                ))
        
        return messages
    
    def _choose_negotiation_target(self, phase: PhaseState) -> str:
        """Choose which country to send a message to."""
        # Simple heuristic: message the strongest neighbor or a potential ally
        active_powers = [p for p in phase.powers if not phase.is_power_eliminated(p) and p != self.country]
        
        if not active_powers:
            return None
        
        # For simplicity, just pick a random active power
        return random.choice(list(active_powers))
    
    def _generate_message_content(self, target: str, phase: PhaseState) -> str:
        """Generate message content based on personality and situation."""
        templates = {
            "aggressive": [
                f"I suggest we coordinate against {self._get_common_threat(target, phase)}.",
                "Your position looks vulnerable. Perhaps we can help each other.",
                "I propose a temporary alliance for mutual benefit."
            ],
            "defensive": [
                "I mean no threat to your territories. Can we maintain peace?",
                "Perhaps we can agree to a non-aggression pact?",
                "I'm focused on defense. No need for conflict between us."
            ],
            "neutral": [
                "How do you view the current situation?",
                "I'm open to discussing our mutual interests.",
                "Perhaps we can find some common ground."
            ]
        }
        
        personality_templates = templates.get(self.personality, templates["neutral"])
        return random.choice(personality_templates)
    
    def _get_common_threat(self, target: str, phase: PhaseState) -> str:
        """Identify a common threat for alliance building."""
        # Find the power with the most supply centers (excluding self and target)
        max_centers = 0
        threat = None
        
        for power in phase.powers:
            if power != self.country and power != target and not phase.is_power_eliminated(power):
                center_count = phase.get_center_count(power)
                if center_count > max_centers:
                    max_centers = center_count
                    threat = power
        
        return threat or "the leading power"
    
    async def update_state(self, phase: PhaseState, events: List[Dict[str, Any]]) -> None:
        """
        Update internal state based on phase results.
        
        Args:
            phase: The completed phase
            events: List of events that occurred
        """
        # Update relationship scores based on events
        for event in events:
            event_type = event.get("type")
            
            if event_type == "attack":
                # Someone attacked us or we attacked someone
                attacker = event.get("attacker")
                target = event.get("target")
                
                if target == self.country:
                    # We were attacked - decrease relationship
                    if attacker in self.relationships:
                        self.relationships[attacker] -= 0.3
                elif attacker == self.country:
                    # We attacked someone - they probably don't like us now
                    if target in self.relationships:
                        self.relationships[target] -= 0.2
            
            elif event_type == "support":
                # Support relationships improve trust
                supporter = event.get("supporter")
                supported = event.get("supported")
                
                if supported == self.country and supporter in self.relationships:
                    self.relationships[supporter] += 0.2
                elif supporter == self.country and supported in self.relationships:
                    self.relationships[supported] += 0.1
        
        # Clamp relationship values to [-1, 1]
        for country in self.relationships:
            self.relationships[country] = max(-1.0, min(1.0, self.relationships[country]))
        
        # Update priorities based on game state
        self._update_priorities(phase)
    
    def _update_priorities(self, phase: PhaseState):
        """Update strategic priorities based on current game state."""
        self.priorities.clear()
        
        my_center_count = phase.get_center_count(self.country)
        
        if my_center_count < 3:
            self.priorities.append("survival")
        elif my_center_count < 8:
            self.priorities.append("expansion")
        else:
            self.priorities.append("consolidation")
        
        # Add defensive priority if someone is getting too strong
        for power in phase.powers:
            if power != self.country and phase.get_center_count(power) > 10:
                self.priorities.append("contain_leader")
                break 



================================================
File: core/__init__.py
================================================
# Core diplomacy game engine - no LLM imports allowed 


================================================
File: core/manager.py
================================================
"""
Core game manager that runs phases, validates orders, and emits events.
This module maintains the clean boundary between the core engine and agents.
"""
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

from .state import PhaseState

logger = logging.getLogger(__name__)


@dataclass
class GameEvent:
    """Represents an event that occurred during a game phase."""
    event_type: str  # "order_resolved", "attack", "support", "convoy", etc.
    phase: str
    participants: Dict[str, Any]  # Powers involved and their roles
    details: Dict[str, Any]  # Additional event-specific data


class GameManager:
    """
    Core game manager that orchestrates phases and validates actions.
    
    This class acts as the bridge between agents and the game engine,
    maintaining clean boundaries and providing a stable API.
    """
    
    def __init__(self, game):
        """
        Initialize the game manager.
        
        Args:
            game: The diplomacy.Game instance
        """
        self.game = game
        self.events_log: List[GameEvent] = []
        logger.info("GameManager initialized")
    
    def get_current_phase_state(self) -> PhaseState:
        """
        Get the current game state as an immutable PhaseState.
        
        Returns:
            PhaseState snapshot of current game state
        """
        return PhaseState.from_game(self.game)
    
    def validate_orders(self, country: str, orders: List[str]) -> Tuple[List[str], List[str]]:
        """
        Validate orders for a country and return valid/invalid orders.
        
        Args:
            country: The country submitting orders
            orders: List of order strings
            
        Returns:
            Tuple of (valid_orders, invalid_orders)
        """
        valid_orders = []
        invalid_orders = []
        
        try:
            # Get possible orders for this power
            possible_orders = self.game.get_all_possible_orders()
            power_possible_orders = possible_orders.get(country, [])
            
            for order in orders:
                order_str = str(order).strip()
                if order_str in power_possible_orders:
                    valid_orders.append(order_str)
                else:
                    invalid_orders.append(order_str)
                    logger.warning(f"Invalid order for {country}: {order_str}")
            
        except Exception as e:
            logger.error(f"Error validating orders for {country}: {e}", exc_info=True)
            # In case of error, treat all orders as invalid
            invalid_orders = [str(order) for order in orders]
        
        logger.info(f"Validated orders for {country}: {len(valid_orders)} valid, {len(invalid_orders)} invalid")
        return valid_orders, invalid_orders
    
    def submit_orders(self, country: str, orders: List[str]) -> bool:
        """
        Submit validated orders for a country.
        
        Args:
            country: The country submitting orders
            orders: List of validated order strings
            
        Returns:
            True if orders were successfully submitted
        """
        try:
            # Clear existing orders for this power
            self.game.clear_orders(country)
            
            # Submit new orders
            for order in orders:
                self.game.set_orders(country, [order])
            
            logger.info(f"Submitted {len(orders)} orders for {country}")
            return True
            
        except Exception as e:
            logger.error(f"Error submitting orders for {country}: {e}", exc_info=True)
            return False
    
    def process_phase(self) -> List[GameEvent]:
        """
        Process the current phase and return events that occurred.
        
        Returns:
            List of events that occurred during phase processing
        """
        phase_events = []
        current_phase = self.game.get_current_phase()
        
        try:
            logger.info(f"Processing phase {current_phase}")
            
            # Store pre-phase state for event generation
            pre_phase_state = self.get_current_phase_state()
            
            # Process the phase
            self.game.process()
            
            # Generate events based on what happened
            phase_events = self._generate_phase_events(pre_phase_state, current_phase)
            
            # Add events to log
            self.events_log.extend(phase_events)
            
            logger.info(f"Phase {current_phase} processed, generated {len(phase_events)} events")
            
        except Exception as e:
            logger.error(f"Error processing phase {current_phase}: {e}", exc_info=True)
            # Create an error event
            error_event = GameEvent(
                event_type="phase_error",
                phase=current_phase,
                participants={},
                details={"error": str(e)}
            )
            phase_events.append(error_event)
        
        return phase_events
    
    def _generate_phase_events(self, pre_phase_state: PhaseState, phase: str) -> List[GameEvent]:
        """
        Generate events by comparing pre and post phase states.
        
        Args:
            pre_phase_state: State before phase processing
            phase: Phase that was processed
            
        Returns:
            List of events that occurred
        """
        events = []
        
        try:
            # Get post-phase state
            post_phase_state = self.get_current_phase_state()
            
            # Compare unit positions to detect moves, attacks, supports, etc.
            events.extend(self._detect_unit_movements(pre_phase_state, post_phase_state, phase))
            
            # Compare supply center ownership
            events.extend(self._detect_center_changes(pre_phase_state, post_phase_state, phase))
            
            # Detect eliminations
            events.extend(self._detect_eliminations(pre_phase_state, post_phase_state, phase))
            
        except Exception as e:
            logger.error(f"Error generating phase events: {e}", exc_info=True)
        
        return events
    
    def _detect_unit_movements(self, pre: PhaseState, post: PhaseState, phase: str) -> List[GameEvent]:
        """Detect unit movements and related events."""
        events = []
        
        # This is a simplified implementation
        # Real implementation would parse the orders and results more carefully
        
        for country in pre.powers:
            pre_units = set(pre.get_power_units(country))
            post_units = set(post.get_power_units(country))
            
            # Detect lost units (could be retreats, disbands, or attacks)
            lost_units = pre_units - post_units
            for unit in lost_units:
                events.append(GameEvent(
                    event_type="unit_lost",
                    phase=phase,
                    participants={"country": country, "unit": unit},
                    details={"unit_type": unit.split()[0] if unit else "unknown"}
                ))
            
            # Detect new units (builds)
            new_units = post_units - pre_units
            for unit in new_units:
                events.append(GameEvent(
                    event_type="unit_built",
                    phase=phase,
                    participants={"country": country, "unit": unit},
                    details={"unit_type": unit.split()[0] if unit else "unknown"}
                ))
        
        return events
    
    def _detect_center_changes(self, pre: PhaseState, post: PhaseState, phase: str) -> List[GameEvent]:
        """Detect supply center ownership changes."""
        events = []
        
        for country in pre.powers:
            pre_centers = set(pre.get_power_centers(country))
            post_centers = set(post.get_power_centers(country))
            
            # Lost centers
            lost_centers = pre_centers - post_centers
            for center in lost_centers:
                # Try to find who took it
                new_owner = None
                for other_country in post.powers:
                    if center in post.get_power_centers(other_country):
                        new_owner = other_country
                        break
                
                events.append(GameEvent(
                    event_type="center_lost",
                    phase=phase,
                    participants={"country": country, "new_owner": new_owner, "center": center},
                    details={}
                ))
            
            # Gained centers
            gained_centers = post_centers - pre_centers
            for center in gained_centers:
                # Try to find who lost it
                old_owner = None
                for other_country in pre.powers:
                    if center in pre.get_power_centers(other_country):
                        old_owner = other_country
                        break
                
                events.append(GameEvent(
                    event_type="center_gained",
                    phase=phase,
                    participants={"country": country, "old_owner": old_owner, "center": center},
                    details={}
                ))
        
        return events
    
    def _detect_eliminations(self, pre: PhaseState, post: PhaseState, phase: str) -> List[GameEvent]:
        """Detect power eliminations."""
        events = []
        
        new_eliminations = post.eliminated_powers - pre.eliminated_powers
        
        for country in new_eliminations:
            events.append(GameEvent(
                event_type="elimination",
                phase=phase,
                participants={"country": country},
                details={"centers_lost": len(pre.get_power_centers(country))}
            ))
        
        return events
    
    def is_game_over(self) -> bool:
        """Check if the game is over."""
        return self.game.is_game_done
    
    def get_winner(self) -> Optional[str]:
        """Get the winner if game is over."""
        if not self.is_game_over():
            return None
        
        # Find the power with the most centers
        current_state = self.get_current_phase_state()
        max_centers = 0
        winner = None
        
        for country in current_state.powers:
            if not current_state.is_power_eliminated(country):
                center_count = current_state.get_center_count(country)
                if center_count > max_centers:
                    max_centers = center_count
                    winner = country
        
        return winner
    
    def get_events_for_country(self, country: str, phase: Optional[str] = None) -> List[GameEvent]:
        """
        Get events relevant to a specific country.
        
        Args:
            country: The country to get events for
            phase: Optional phase filter
            
        Returns:
            List of relevant events
        """
        relevant_events = []
        
        for event in self.events_log:
            # Filter by phase if specified
            if phase and event.phase != phase:
                continue
            
            # Check if country is involved in this event
            if country in event.participants.values() or \
               event.participants.get("country") == country or \
               event.participants.get("attacker") == country or \
               event.participants.get("target") == country:
                relevant_events.append(event)
        
        return relevant_events
    
    def _is_order_valid(self, country, order_text):
        """Check if an order is valid for a country."""
        # This is a simplified check. A real implementation would involve
        # more complex validation logic based on game rules.
        return order_text in self.game.get_orders(country) 


================================================
File: core/state.py
================================================
"""
Immutable game state dataclasses for agent communication.
These provide a stable, frozen snapshot of game state without coupling to the full Game object.
"""
from dataclasses import dataclass, field
from typing import Dict, List, Optional, FrozenSet, Any


@dataclass(frozen=True)
class PhaseState:
    """
    Immutable snapshot of game state for a specific phase.
    Agents receive this instead of direct access to the Game object.
    """
    phase_name: str
    year: int
    season: str  # "SPRING", "FALL", "WINTER"
    phase_type: str  # "MOVEMENT", "RETREAT", "ADJUSTMENT"
    
    # Power state
    powers: FrozenSet[str] = field(default_factory=frozenset)
    eliminated_powers: FrozenSet[str] = field(default_factory=frozenset)
    
    # Board state
    units: Dict[str, List[str]] = field(default_factory=dict)  # power -> list of unit strings
    supply_centers: Dict[str, List[str]] = field(default_factory=dict)  # power -> list of center names
    
    # Game progress
    is_game_over: bool = False
    winner: Optional[str] = None
    
    # Messages (read-only view) - using Any to avoid diplomacy import
    recent_messages: List[Any] = field(default_factory=list)
    
    @classmethod
    def from_game(cls, game, recent_messages: Optional[List[Any]] = None) -> "PhaseState":
        """Create a PhaseState from a diplomacy.Game object."""
        try:
            # Parse phase information
            current_phase = game.get_current_phase()
            year = int(current_phase[1:5]) if len(current_phase) >= 5 else 1901
            season = current_phase[0] if current_phase else "S"
            phase_type = current_phase[5:] if len(current_phase) > 5 else "M"
            
            # Convert season codes to readable names
            season_map = {"S": "SPRING", "F": "FALL", "W": "WINTER"}
            season_name = season_map.get(season, "SPRING")
            
            # Convert phase type codes to readable names  
            type_map = {"M": "MOVEMENT", "R": "RETREAT", "A": "ADJUSTMENT"}
            phase_type_name = type_map.get(phase_type, "MOVEMENT")
            
            # Extract power information
            all_powers = frozenset(game.powers.keys())
            eliminated = frozenset(p.name for p in game.powers.values() if p.is_eliminated())
            
            # Extract units and centers
            units_dict = {}
            centers_dict = {}
            
            for power_name, power_obj in game.powers.items():
                units_dict[power_name] = [str(unit) for unit in power_obj.units]
                centers_dict[power_name] = [str(center) for center in power_obj.centers]
            
            # Game status
            game_over = game.is_game_done
            winner_power = None
            if game_over:
                # Find winner (power with most supply centers)
                max_centers = max(len(centers) for centers in centers_dict.values()) if centers_dict else 0
                for power, centers in centers_dict.items():
                    if len(centers) == max_centers:
                        winner_power = power
                        break
            
            return cls(
                phase_name=current_phase,
                year=year,
                season=season_name,
                phase_type=phase_type_name,
                powers=all_powers,
                eliminated_powers=eliminated,
                units=units_dict,
                supply_centers=centers_dict,
                is_game_over=game_over,
                winner=winner_power,
                recent_messages=recent_messages or []
            )
            
        except Exception:
            # Fallback to minimal state if game object access fails
            return cls(
                phase_name="UNKNOWN",
                year=1901,
                season="SPRING",
                phase_type="MOVEMENT",
                powers=frozenset(),
                eliminated_powers=frozenset(),
                units={},
                supply_centers={},
                is_game_over=False,
                winner=None,
                recent_messages=recent_messages or []
            )
    
    def get_power_units(self, power: str) -> List[str]:
        """Get units for a specific power."""
        return self.units.get(power, [])
    
    def get_power_centers(self, power: str) -> List[str]:
        """Get supply centers for a specific power."""
        return self.supply_centers.get(power, [])
    
    def is_power_eliminated(self, power: str) -> bool:
        """Check if a power is eliminated."""
        return power in self.eliminated_powers
    
    def get_center_count(self, power: str) -> int:
        """Get number of supply centers for a power."""
        return len(self.get_power_centers(power)) 



================================================
File: prompts/__init__.py
================================================
# ai_diplomacy/prompts/__init__.py
from ai_diplomacy.prompt_utils import load_prompt

# Define the constants by loading them from the .txt files
SYSTEM_PROMPT_TEMPLATE = load_prompt("system_prompt.txt")
PLANNING_PROMPT_TEMPLATE = load_prompt("planning_instructions.txt")
NEGOTIATION_DIARY_PROMPT_TEMPLATE = load_prompt("negotiation_diary_prompt.txt")
ORDER_SUBMISSION_PROMPT_TEMPLATE = load_prompt("order_instructions.txt")
ORDER_DIARY_PROMPT_TEMPLATE = load_prompt("order_diary_prompt.txt")

# For POWER_SPECIFIC_PROMPTS, it's a dictionary.
POWER_SPECIFIC_PROMPTS = {
    "AUSTRIA": load_prompt("austria_system_prompt.txt"),
    "ENGLAND": load_prompt("england_system_prompt.txt"),
    "FRANCE": load_prompt("france_system_prompt.txt"),
    "GERMANY": load_prompt("germany_system_prompt.txt"),
    "ITALY": load_prompt("italy_system_prompt.txt"),
    "RUSSIA": load_prompt("russia_system_prompt.txt"),
    "TURKEY": load_prompt("turkey_system_prompt.txt"),
}

# Additional templates that might be used elsewhere or by agent.py implicitly
# via llm_utils.load_prompt_file if that function is also used directly by agent.py
# For now, only defining what agent.py explicitly imports from ai_diplomacy.prompts

__all__ = [
    "SYSTEM_PROMPT_TEMPLATE",
    "POWER_SPECIFIC_PROMPTS",
    "PLANNING_PROMPT_TEMPLATE",
    "NEGOTIATION_DIARY_PROMPT_TEMPLATE",
    "ORDER_SUBMISSION_PROMPT_TEMPLATE",
    "ORDER_DIARY_PROMPT_TEMPLATE",
] 


================================================
File: prompts/austria_system_prompt.txt
================================================
**SYSTEM PROMPT: AUSTRIA**

You are playing as AUSTRIA in the game of Diplomacy. Your primary goal is to control 18 supply centers on the map to achieve victory.

**Personality:** You are a cautious and pragmatic leader. You prioritize consolidating your power base and securing your borders before engaging in aggressive expansion. You are generally trustworthy but will make calculated risks or betrayals if necessary for survival or significant gain.

**General Strategic Principles for Victory:**

*   **Proactive Expansion:** Diplomacy is a game of conquest. Prioritize securing new supply centers, especially in the early game. An aggressive, expansionist strategy is often key to building a dominant position.
*   **Calculated Aggression:** While caution has its place, overly defensive or passive play rarely leads to victory. Identify opportunities for bold moves and take calculated risks to seize advantages.
*   **Dynamic Alliances:** Alliances are temporary tools to achieve your objectives. Form them strategically, but always be prepared to adapt, shift, or even betray alliances if it serves your path to ultimate victory. Do not become overly reliant on any single power.
*   **Exploit Weaknesses:** Constantly assess the strengths and weaknesses of other powers. A well-timed strike against a vulnerable or overextended neighbor can yield significant gains.
*   **Focus on Winning:** The ultimate goal is to control 18 supply centers. Every negotiation, move, and strategic decision should be made with this objective in mind. Aim for outright victory, not just survival or a stalemate.
*   **Adapt and Overcome:** Be flexible in your strategy. The political landscape will change rapidly. Re-evaluate your plans each turn and adapt to new threats and opportunities.

Remember to adapt your strategy based on the evolving game state and interactions with other powers. Your ultimate loyalty is to the advancement of AUSTRIA.



================================================
File: prompts/context_prompt.txt
================================================
You are playing the board game Diplomacy. Your power is {power_name}. The {current_phase} phase. 
Your primary goal is to control 18 supply centers.
Use the information below to inform your approach.


Power: {power_name}
Phase: {current_phase}

PLAYER STATUS
Current Goals: {agent_goals}
Relationships: {agent_relationships}

RECENT PRIVATE DIARY ENTRIES (Your inner thoughts and plans):
{agent_private_diary}

GAME MAP
Unit Locations:
{all_unit_locations}

Supply Centers:
{all_supply_centers}

POSSIBLE ORDERS FOR {current_phase}
{possible_orders}
END POSSIBLE ORDERS

MESSAGES THIS ROUND
{messages_this_round}
END MESSAGES


================================================
File: prompts/conversation_instructions.txt
================================================
NEGOTIATION MESSAGES

TASK
Generate one or more strategic messages to advance your interests.
Always prioritize responding to the messages in the "RECENT MESSAGES REQUIRING YOUR ATTENTION" section.

Consider:
- Your current goals
- Relationships with other powers
- Ongoing conversations and the need to maintain consistent threads
- Messages that need direct responses in the "REQUIRING YOUR ATTENTION" section
- Powers that have been ignoring your messages (adjust your approach accordingly)

When dealing with non-responsive powers:
- Ask direct questions that demand yes/no answers
- Make public statements that force them to clarify their position
- Shift diplomatic efforts to more receptive powers
- Consider their silence as potentially hostile

Message purposes can include:
- Responding to specific requests or inquiries (highest priority)
- Proposing alliances or support moves
- Issuing warnings or making threats
- Gathering intelligence about other powers' intentions
- Coordinating moves and suggesting tactical options
- Strategic deception when appropriate to your goals

RESPONSE FORMAT
Return ONLY JSON objects. One or more messages, each as a separate JSON object.
Do not include any text outside the JSON.

Required JSON structure:
{
  "message_type": "global" or "private",
  "content": "Your message text"
}

For private messages, also include:
{
  "message_type": "private",
  "recipient": "POWER_NAME",
  "content": "Your message text"
}

EXAMPLES

1. Global warning:
{
  "message_type": "global",
  "content": "COUNTRY's aggression in the south will not go unanswered."
}

2. Private cooperation proposal:
{
  "message_type": "private",
  "recipient": "RUSSIA",
  "content": "Perhaps we can coordinate against our mutual COUNTRY problem?"
}

3. Multiple messages:
{
  "message_type": "global",
  "content": "Let's focus on maintaining stability this turn."
}
{
  "message_type": "private",
  "recipient": "GERMANY",
  "content": "Secretly, I'm planning to move against COUNTRY. Can you support?"
}

4. Private inquiry and subtle warning (as Austria to Italy, suspecting Italy might eye Trieste):
{
  "message_type": "private",
  "recipient": "ITALY",
  "content": "Greetings, esteemed colleague. I trust your preparations for the season are going well. I'm currently evaluating my defensive needs, particularly around Tyrolia and Trieste. Any insights you might share on the general stability in our shared neighborhood would be most appreciated. A peaceful southern flank benefits us both, wouldn't you agree?"
}

5. Public statement of intent and private follow-up (as England, after taking North Sea and Norwegian Sea, aiming for St. Petersburg but wanting to appear non-threatening to Germany initially):
{
  "message_type": "global",
  "content": "England reaffirms its commitment to maritime security and the free passage of all neutral shipping in northern waters. Our recent naval deployments are purely to ensure these principles are upheld."
}
{
  "message_type": "private",
  "recipient": "RUSSIA",
  "content": "My friend, your northern ports are looking rather exposed. While my public stance is one of general peace, perhaps we could discuss ways to ensure *your* security in the region? I have no desire for conflict with you, but an unguarded St. Petersburg is a tempting target for others. Maybe a mutual understanding could be beneficial?"
}

6. Direct response to a specific proposal (as Italy responding to Austria's question about stability in the region):
{
  "message_type": "private",
  "recipient": "AUSTRIA",
  "content": "Thank you for your inquiry about regional stability. Regarding your concerns about Tyrolia and Trieste, I want to assure you that my army in Venice has purely defensive intentions. I agree that a peaceful southern flank benefits us both. In fact, I would propose we formalize this with a demilitarized zone agreement along our border, allowing both of us to focus elsewhere. Would you be amenable to such an arrangement?"
}

Your response must contain at least one valid JSON message block.
- Ensure recipient names are spelled correctly if sending private messages.
- Think strategically about *why* you are sending each message and what outcome you hope to achieve.
- When responding to a message, explicitly acknowledge what was said and reference specific points.
- For ongoing conversations, maintain thread continuity by referencing previous exchanges.
- If another power has made a specific proposal or request, address it directly in your response.
- When making agreements, be clear about what you are committing to and what you expect in return.
- If you need to quote something, only use single quotes in the actual messages so as not to interfere with the JSON structure.
</ImportantReminders>

JSON ONLY BELOW (DO NOT PREPEND WITH ```json or ``` or any other text)



================================================
File: prompts/diary_consolidation_prompt.j2
================================================
DIARY CONSOLIDATION REQUEST
Power: {{ power_name }}
Year to Consolidate: {{ year }}

GAME CONTEXT
You are playing Diplomacy, a strategic board game set in pre-WWI Europe. Seven powers compete for control by conquering supply centers. Victory requires 18 supply centers. The powers are:

Key game mechanics:
- Spring (S) and Fall (F) movement phases where armies/fleets move
- Fall phases include builds/disbands based on supply center control
- Units can support, convoy, or attack
- All orders resolve simultaneously
- Success often requires negotiated coordination with other powers

DIARY ENTRIES FROM {{ year }}
{{ year_diary_entries }}

TASK
Create a concise summary (200-300 words) that captures the essential strategic developments from {{ year }}. Focus on:

1. Diplomatic Evolution
   - Alliances formed, maintained, or broken
   - Trust relationships established or shattered
   - Key negotiations and their outcomes

2. Strategic Position
   - Supply centers gained or lost
   - Critical battles won or lost
   - Strategic breakthroughs or setbacks
   - Changes in board position relative to other powers

3. Military Actions
   - Successful attacks or defenses
   - Key supports that worked or failed
   - Convoy operations
   - Stalemate lines formed or broken

4. Trust Assessment
   - Which powers proved reliable
   - Who betrayed agreements
   - Patterns of behavior observed

5. Lessons Learned
   - Strategic insights gained
   - Mistakes to avoid
   - Successful tactics to repeat

Maintain the first-person perspective of {{ power_name }} and preserve critical strategic insights while condensing operational details. The summary should provide sufficient context for future strategic planning.

RESPONSE FORMAT
Return ONLY the consolidated summary text. Do not include JSON, formatting markers, or meta-commentary.



================================================
File: prompts/england_system_prompt.txt
================================================
**SYSTEM PROMPT: ENGLAND**

You are playing as ENGLAND in the game of Diplomacy. Your primary goal is to control 18 supply centers on the map to achieve victory.

**Personality:** You are a naval power focused on maritime dominance and securing island/coastal centers. You are somewhat isolationist initially but opportunistic. You value alliances that secure your coasts and allow expansion into Scandinavia or France.

**General Strategic Principles for Victory:**

*   **Proactive Expansion:** Diplomacy is a game of conquest. Prioritize securing new supply centers, especially in the early game. An aggressive, expansionist strategy is often key to building a dominant position.
*   **Calculated Aggression:** While caution has its place, overly defensive or passive play rarely leads to victory. Identify opportunities for bold moves and take calculated risks to seize advantages.
*   **Dynamic Alliances:** Alliances are temporary tools to achieve your objectives. Form them strategically, but always be prepared to adapt, shift, or even betray alliances if it serves your path to ultimate victory. Do not become overly reliant on any single power.
*   **Exploit Weaknesses:** Constantly assess the strengths and weaknesses of other powers. A well-timed strike against a vulnerable or overextended neighbor can yield significant gains.
*   **Focus on Winning:** The ultimate goal is to control 18 supply centers. Every negotiation, move, and strategic decision should be made with this objective in mind. Aim for outright victory, not just survival or a stalemate.
*   **Adapt and Overcome:** Be flexible in your strategy. The political landscape will change rapidly. Re-evaluate your plans each turn and adapt to new threats and opportunities.

Remember to adapt your strategy based on the evolving game state and interactions with other powers. Your ultimate loyalty is to the advancement of ENGLAND.



================================================
File: prompts/few_shot_example.txt
================================================
EXAMPLE GAME STATE
Power: FRANCE
Phase: S1901M
Your Units: ['A PAR','F BRE']
Possible Orders:
  PAR: ['A PAR H','A PAR - BUR','A PAR - GAS']
  BRE: ['F BRE H','F BRE - MAO']

PAST PHASE SUMMARIES
- Your move A BUD -> SER bounced last time because Turkey also moved A SMY -> SER with support.
- Your support F TRI S A BUD -> SER was wasted because F TRI was needed to block Ionian invasion.

THINKING PROCESS
1. Consider enemy units, centers, and likely moves
2. Review your units, centers, and strategic position
3. Analyze recent conversations and phase summaries
4. Evaluate public/private goals and reality of positions
5. Choose best strategic moves from possible orders

Example thought process:
- Germany might move to BUR with support - consider bounce or defend
- Moving A PAR -> BUR is aggressive but strategic
- F BRE -> MAO secures Atlantic expansion
- Avoid contradictory or random supports

RESPONSE FORMAT
PARSABLE OUTPUT:
{{
  "orders": ["A PAR - BUR","F BRE - MAO"]
}}


================================================
File: prompts/france_system_prompt.txt
================================================
You are playing as France in a game of Diplomacy.

Your Goal: Achieve world domination by controlling 18 supply centers.

Your Personality: You are a balanced power with strong land and naval capabilities, often seen as cultured but proud. You value secure borders and opportunities for colonial or continental expansion. Alliances with England or Germany can be pivotal.

**General Strategic Principles for Victory:**

*   **Proactive Expansion:** Diplomacy is a game of conquest. Prioritize securing new supply centers, especially in the early game. An aggressive, expansionist strategy is often key to building a dominant position.
*   **Calculated Aggression:** While caution has its place, overly defensive or passive play rarely leads to victory. Identify opportunities for bold moves and take calculated risks to seize advantages.
*   **Dynamic Alliances:** Alliances are temporary tools to achieve your objectives. Form them strategically, but always be prepared to adapt, shift, or even betray alliances if it serves your path to ultimate victory. Do not become overly reliant on any single power.
*   **Exploit Weaknesses:** Constantly assess the strengths and weaknesses of other powers. A well-timed strike against a vulnerable or overextended neighbor can yield significant gains.
*   **Focus on Winning:** The ultimate goal is to control 18 supply centers. Every negotiation, move, and strategic decision should be made with this objective in mind. Aim for outright victory, not just survival or a stalemate.
*   **Adapt and Overcome:** Be flexible in your strategy. The political landscape will change rapidly. Re-evaluate your plans each turn and adapt to new threats and opportunities.

General Instructions:
- Analyze the game state carefully each phase.
- Communicate clearly and strategically with other powers.
- Formulate plans and issue orders that align with your goals and personality.
- Always output your reasoning and then your orders in the specified format.



================================================
File: prompts/germany_system_prompt.txt
================================================
**SYSTEM PROMPT: GERMANY**

You are playing as GERMANY in the game of Diplomacy. Your primary goal is to control 18 supply centers on the map to achieve victory.

**Personality:** You are a strong central land power with naval ambitions, often viewed as industrious and militaristic. You seek to dominate central Europe and value alliances that allow expansion East or West while securing your other flank.

**General Strategic Principles for Victory:**

*   **Proactive Expansion:** Diplomacy is a game of conquest. Prioritize securing new supply centers, especially in the early game. An aggressive, expansionist strategy is often key to building a dominant position.
*   **Calculated Aggression:** While caution has its place, overly defensive or passive play rarely leads to victory. Identify opportunities for bold moves and take calculated risks to seize advantages.
*   **Dynamic Alliances:** Alliances are temporary tools to achieve your objectives. Form them strategically, but always be prepared to adapt, shift, or even betray alliances if it serves your path to ultimate victory. Do not become overly reliant on any single power.
*   **Exploit Weaknesses:** Constantly assess the strengths and weaknesses of other powers. A well-timed strike against a vulnerable or overextended neighbor can yield significant gains.
*   **Focus on Winning:** The ultimate goal is to control 18 supply centers. Every negotiation, move, and strategic decision should be made with this objective in mind. Aim for outright victory, not just survival or a stalemate.
*   **Adapt and Overcome:** Be flexible in your strategy. The political landscape will change rapidly. Re-evaluate your plans each turn and adapt to new threats and opportunities.

Remember to adapt your strategy based on the evolving game state and interactions with other powers. Your ultimate loyalty is to the advancement of GERMANY.



================================================
File: prompts/italy_system_prompt.txt
================================================
**SYSTEM PROMPT: ITALY**

You are playing as ITALY in the game of Diplomacy. Your primary goal is to control 18 supply centers on the map to achieve victory.

**Personality:** You are a naval power with a central Mediterranean position, often opportunistic and flexible. You seek to expand in the Mediterranean and Balkans, valuing alliances that protect your homeland while enabling growth abroad.

**General Strategic Principles for Victory:**

*   **Proactive Expansion:** Diplomacy is a game of conquest. Prioritize securing new supply centers, especially in the early game. An aggressive, expansionist strategy is often key to building a dominant position.
*   **Calculated Aggression:** While caution has its place, overly defensive or passive play rarely leads to victory. Identify opportunities for bold moves and take calculated risks to seize advantages.
*   **Dynamic Alliances:** Alliances are temporary tools to achieve your objectives. Form them strategically, but always be prepared to adapt, shift, or even betray alliances if it serves your path to ultimate victory. Do not become overly reliant on any single power.
*   **Exploit Weaknesses:** Constantly assess the strengths and weaknesses of other powers. A well-timed strike against a vulnerable or overextended neighbor can yield significant gains.
*   **Focus on Winning:** The ultimate goal is to control 18 supply centers. Every negotiation, move, and strategic decision should be made with this objective in mind. Aim for outright victory, not just survival or a stalemate.
*   **Adapt and Overcome:** Be flexible in your strategy. The political landscape will change rapidly. Re-evaluate your plans each turn and adapt to new threats and opportunities.

Remember to adapt your strategy based on the evolving game state and interactions with other powers. Your ultimate loyalty is to the advancement of ITALY.



================================================
File: prompts/negotiation_diary_prompt.txt
================================================
NEGOTIATION SUMMARY REQUEST
Power: {power_name}
Phase: {current_phase}

MESSAGES THIS ROUND
{messages_this_round}
{ignored_messages_context}

CURRENT STATUS
Goals:
{agent_goals}

Relationships:
{agent_relationships}

Game State:
{board_state_str}

TASK
Analyze the negotiations, goals, relationships, and game state to:
1. Summarize key outcomes and agreements
2. State your strategic intent for {current_phase}
3. Update relationships as needed (Enemy, Unfriendly, Neutral, Friendly, Ally)
4. Note which powers are not responding to your messages and consider adjusting your approach

When powers ignore your messages, consider:
- They may be intentionally avoiding commitment
- They could be prioritizing other relationships
- Your approach may need adjustment (more direct questions, different incentives)
- Their silence might indicate hostility or indifference

RESPONSE FORMAT
Return ONLY a JSON object with this structure:

{{
"negotiation_summary": "Key outcomes from negotiations",
"intent": "Strategic intent for upcoming orders",
"updated_relationships": {{
"POWER_NAME": "Enemy|Unfriendly|Neutral|Friendly|Ally"
}}
}}


Do not include any text outside the JSON.

EXAMPLES:

Scenario 1: As France, after discussing a joint move against Germany with England, while Italy seems to be posturing aggressively in Piedmont.

{{
"negotiation_summary": "Reached a tentative agreement with England to support their fleet into Belgium (BEL) if they support my army into Ruhr (RUH). Italy's messages are vague but their army in Piedmont (PIE) is concerning; they claim it's defensive against Austria but it also threatens Marseilles (MAR). Russia remains silent. Austria and Turkey are focused on each other.",
"intent": "Secure Ruhr with English support. Hold Marseilles defensively. Probe Italy's intentions further. If England upholds their end, improve relations. If Italy moves on MAR, downgrade relations severely.",
"updated_relationships": {{
"ENGLAND": "Friendly",
"GERMANY": "Enemy",
"ITALY": "Unfriendly",
"AUSTRIA": "Neutral",
"RUSSIA": "Neutral",
"TURKEY": "Neutral"
}}
}}

Scenario 2: As Turkey, after Germany proposed an alliance against Russia, but France also offered a non-aggression pact and hinted at concerns about Austria.

{{
"negotiation_summary": "Germany is keen on an anti-Russian alliance, offering support into Sevastopol (SEV) if I attack. France proposed a mutual non-aggression pact and expressed worry about Austrian expansion in the Balkans, which aligns with my concerns. England is distant. Italy seems focused on France.",
"intent": "Prioritize securing Black Sea (BLA) and consider options against Russia, but German support needs to be concrete. Maintain neutrality with France for now, as their non-aggression pact could be useful if Austria becomes a larger threat. Try to confirm German commitment before moving on Russia. Delay any aggressive moves against Austria until my position is stronger.",
"updated_relationships": {{
"GERMANY": "Friendly",
"RUSSIA": "Unfriendly",
"FRANCE": "Neutral",
"ENGLAND": "Neutral",
"ITALY": "Neutral",
"AUSTRIA": "Unfriendly"
}}
}}

Scenario 3: As England, when France hasn't responded to two alliance proposals and Russia is ignoring naval cooperation messages.

{{
"negotiation_summary": "France continues to ignore my alliance proposals regarding Belgium and the Channel, having not responded to messages in the last two phases. Russia similarly hasn't acknowledged my Baltic cooperation suggestions. Meanwhile, Germany actively engaged about Denmark. This silence from France and Russia is telling - they likely have other commitments or see me as a threat.",
"intent": "Shift focus to Germany as primary partner given their responsiveness. Prepare defensive positions against potentially hostile France. Consider more aggressive Baltic moves since Russia seems uninterested in cooperation. May need to force France's hand with direct questions or public statements.",
"updated_relationships": {{
"FRANCE": "Unfriendly",
"GERMANY": "Friendly", 
"RUSSIA": "Unfriendly",
"ITALY": "Neutral",
"AUSTRIA": "Neutral",
"TURKEY": "Neutral"
}}
}}

Reminder: If you need to quote something, only use single quotes in the actual messages so as not to interfere with the JSON structure.
JSON ONLY BELOW (DO NOT PREPEND WITH ```json or ``` or any other text)


================================================
File: prompts/order_diary_prompt.j2
================================================
ORDER DIARY ENTRY
Power: {{ power_name }}
Phase: {{ current_phase }}

ORDERS ISSUED
{{ orders_list_str }}

CURRENT STATUS
Game State:
{{ board_state_str }}

Goals:
{{ agent_goals }}

Relationships:
{{ agent_relationships }}

TASK
Write a concise diary note summarizing your orders.

RESPONSE FORMAT
Return ONLY a JSON object with this structure:
{
"order_summary": "Brief summary of orders and strategic intent"
}

Do not include any text outside the JSON.


================================================
File: prompts/order_instructions.txt
================================================
PRIMARY OBJECTIVE
Control 18 supply centers. Nothing else will do.

ORDER SUBMISSION PROCESS
1. ANALYZE
   - Review game state, orders, messages, and other powers' motivations
   - Focus on expansion and capturing supply centers
   - Be aggressive, not passive
   - Take calculated risks for significant gains
   - Find alternative paths if blocked

2. REASON
   - Write out your strategic thinking
   - Explain goals and move choices
   - Consider supports and holds

3. FORMAT
   Return orders in this exact format:
   PARSABLE OUTPUT:
   {{
     "orders": ["order1", "order2", ...]
   }}

CRITICAL RULES
1. ONLY use orders from the provided possible_orders list - these are the ONLY valid orders for YOUR units
2. You can ONLY give orders to YOUR OWN units - never order other powers' units
3. Every order must start with one of YOUR units (shown in the possible_orders section)
4. Look at the "Unit Locations" section to see which units YOU control
5. Choose EXACTLY ONE order per unit - do not list multiple options for the same unit
6. A unit CANNOT support itself (e.g., "A MAR S A MAR - GAS" is INVALID)
7. Each unit can only appear ONCE in your orders list
8. Support orders must match actual moves (e.g., 'A PAR S F BRE - ENG' needs 'F BRE - ENG' to also be ordered)
9. Build orders (build phase only):
   - Format: '[UnitType] [Location3LetterCode] B'
   - UnitType: 'A' (Army) or 'F' (Fleet)
   - Example: 'A PAR B', 'F LON B'
10. Dual-coast provinces (STP, SPA, BUL):
    - Specify coast when needed: 'F [PROVINCE]/[COAST_CODE]'
    - Example: 'F STP/NC B', 'A MAR S F SPA/SC - WES'
    - Coast codes: NC (North), SC (South), EC (East), WC (West)
11. All orders resolve simultaneously
12. Submit orders only, no messages

VALID ORDERS FOR YOUR UNITS
Below are ALL the valid orders you can choose from. You MUST pick EXACTLY ONE order per unit from this list:

{valid_orders_list}

IMPORTANT: 
- Choose one order per unit. If you have 3 units, submit exactly 3 orders.
- Each unit (F BRE, A MAR, A PAR) should appear exactly once in your orders.
- Do NOT duplicate units or create self-support orders.

RESPOND WITH YOUR REASONING AND ORDERS (within PARSABLE OUTPUT) BELOW


================================================
File: prompts/phase_result_diary_prompt.txt
================================================
PHASE RESULT ANALYSIS
Power: {power_name}
Phase: {current_phase}

PHASE SUMMARY
{phase_summary}

ALL POWERS' ORDERS THIS PHASE
{all_orders_formatted}

YOUR NEGOTIATIONS THIS PHASE
{your_negotiations}

YOUR RELATIONSHIPS BEFORE THIS PHASE
{pre_phase_relationships}

YOUR GOALS
{agent_goals}

YOUR ACTUAL ORDERS
{your_actual_orders}

TASK
Analyze what actually happened this phase compared to negotiations and expectations.

Consider:
1. BETRAYALS: Who broke their promises? Did you break any promises?
2. COLLABORATIONS: Which agreements were successfully executed?
3. SURPRISES: What unexpected moves occurred?
4. IMPACT: How did these events affect your strategic position?

Write a reflective diary entry (150-250 words) that:
- Identifies key betrayals or successful collaborations
- Assesses impact on your position
- Updates your understanding of other powers' trustworthiness
- Notes strategic lessons learned
- Adjusts your perception of threats and opportunities

Focus on concrete events and their implications for your future strategy.

RESPONSE FORMAT
Return ONLY a diary entry text. Do not include JSON or formatting markers.


================================================
File: prompts/planning_instructions.txt
================================================
STRATEGIC PLANNING

PRIMARY OBJECTIVE
Capture 18 supply centers to win. Be aggressive and expansionist.
- Prioritize capturing supply centers
- Seize opportunities aggressively
- Take calculated risks for significant gains
- Find alternative paths if blocked
- Avoid purely defensive postures

KEY CONSIDERATIONS
1. Target Supply Centers
   - Which centers can you capture this phase?
   - Which centers should you target in future phases?

2. Success Requirements
   - What must happen for your moves to succeed?
   - How to prevent bounces?

3. Diplomatic Strategy
   - Which negotiations could help your moves succeed?
   - What deals or threats might be effective?
   - Consider alliances, deception, and concessions

4. Defense Assessment
   - Which of your centers might others target?
   - How can you protect vulnerable positions?

5. Diplomatic Protection
   - What negotiations could deter attacks?
   - How to mislead potential attackers?

TASK
Write a detailed one-paragraph directive covering:
- Supply centers to capture
- How to capture them (orders, allies, deals)
- Defensive considerations
- Diplomatic approach (including potential deception)


This directive will guide your future negotiations and orders.
Be specific, strategic, and wary of deception from others.

RESPOND WITH YOUR DIRECTIVE BELOW



================================================
File: prompts/russia_system_prompt.txt
================================================
**SYSTEM PROMPT: RUSSIA**

You are playing as RUSSIA in the game of Diplomacy. Your primary goal is to control 18 supply centers on the map to achieve victory.

**Personality:** You are a vast land power with access to multiple fronts, often seen as patient but capable of overwhelming force. You aim to secure warm-water ports and expand in the North, South, or into Central Europe. Alliances are crucial for managing your extensive borders.

**General Strategic Principles for Victory:**

*   **Proactive Expansion:** Diplomacy is a game of conquest. Prioritize securing new supply centers, especially in the early game. An aggressive, expansionist strategy is often key to building a dominant position.
*   **Calculated Aggression:** While caution has its place, overly defensive or passive play rarely leads to victory. Identify opportunities for bold moves and take calculated risks to seize advantages.
*   **Dynamic Alliances:** Alliances are temporary tools to achieve your objectives. Form them strategically, but always be prepared to adapt, shift, or even betray alliances if it serves your path to ultimate victory. Do not become overly reliant on any single power.
*   **Exploit Weaknesses:** Constantly assess the strengths and weaknesses of other powers. A well-timed strike against a vulnerable or overextended neighbor can yield significant gains.
*   **Focus on Winning:** The ultimate goal is to control 18 supply centers. Every negotiation, move, and strategic decision should be made with this objective in mind. Aim for outright victory, not just survival or a stalemate.
*   **Adapt and Overcome:** Be flexible in your strategy. The political landscape will change rapidly. Re-evaluate your plans each turn and adapt to new threats and opportunities.

Remember to adapt your strategy based on the evolving game state and interactions with other powers. Your ultimate loyalty is to the advancement of RUSSIA.



================================================
File: prompts/state_update_prompt.txt
================================================
You are analyzing the results of a phase in Diplomacy for {power_name}.

GAME STATE
Year: {current_year}
Phase: {current_phase}
Board State:
{board_state_str}

PHASE SUMMARY ({current_phase}):
{phase_summary}

CURRENT STATUS
Goals:
{current_goals}

Relationships with other powers ({other_powers}):
{current_relationships}

TASK
Analyze the phase summary and game state to update your relationships and goals.

IMPORTANT RULES
1. Update relationships for ALL powers in {other_powers}
2. Use ONLY these relationship values: Enemy, Unfriendly, Neutral, Friendly, Ally
3. Make goals specific and actionable
4. Base analysis on actual events, not assumptions
5. Return ONLY valid JSON - no text before or after

Example Response Structure:
{{
  "reasoning": "Brief explanation of your analysis",
  "relationships": {{
    "FRANCE": "Neutral",
    "GERMANY": "Unfriendly",
    "RUSSIA": "Enemy"
  }},
  "goals": [
    "Specific goal 1",
    "Specific goal 2"
  ]
}}

EXAMPLE SCENARIOS

1. After Cooperation:
{{
  "reasoning": "Austria helped take Warsaw. Russia attacked Prussia.",
  "relationships": {{
    "AUSTRIA": "Ally",
    "RUSSIA": "Enemy",
    "TURKEY": "Neutral",
    "ITALY": "Unfriendly",
    "FRANCE": "Neutral"
  }},
  "goals": [
    "Hold Warsaw against Russia",
    "Keep Austrian alliance",
    "Block Italian expansion"
  ]
}}

2. After Betrayal:
{{
  "reasoning": "France betrayed Channel agreement. Russia cooperating north.",
  "relationships": {{
    "FRANCE": "Enemy",
    "RUSSIA": "Friendly",
    "GERMANY": "Unfriendly",
    "ITALY": "Neutral",
    "AUSTRIA": "Neutral"
  }},
  "goals": [
    "Counter French fleet",
    "Secure Norway with Russia",
    "Build London fleet"
  ]
}}

3. After Builds:
{{
  "reasoning": "Naval buildup in north. Russia threatening.",
  "relationships": {{
    "RUSSIA": "Enemy",
    "GERMANY": "Unfriendly",
    "FRANCE": "Neutral",
    "AUSTRIA": "Neutral",
    "TURKEY": "Neutral"
  }},
  "goals": [
    "Control northern waters",
    "Take Denmark first",
    "Find anti-Russia ally"
  ]
}}

4. As England, after a failed attack on Belgium (BEL) which was occupied by France, supported by Germany. Russia moved into Sweden (SWE) uncontested. Austria and Italy skirmished over Trieste (TRI). Turkey was quiet.

{{
  "reasoning": "My attack on Belgium was decisively repulsed due to Franco-German cooperation, marking them as a significant threat bloc. Russia's acquisition of Sweden is concerning for my northern position. The Austro-Italian conflict seems localized for now, and Turkey's inactivity makes them an unknown variable, potentially open to diplomacy.",
  "relationships": {{
    "FRANCE": "Enemy",
    "GERMANY": "Enemy",
    "RUSSIA": "Unfriendly",
    "AUSTRIA": "Neutral",
    "ITALY": "Neutral",
    "TURKEY": "Neutral"
  }},
  "goals": [
    "Break the Franco-German alliance or find a way to counter their combined strength.",
    "Secure North Sea (NTH) and prevent further Russian expansion towards Norway (NWY).",
    "Seek dialogue with Turkey or Austria/Italy to create a counterweight to the dominant bloc."
  ]
}}

5. As Russia, after successfully negotiating passage through Black Sea (BLA) with Turkey to take Rumania (RUM). Germany moved into Silesia (SIL), threatening Warsaw (WAR). Austria and France exchanged hostile messages but made no direct moves against each other. England built a new fleet in London (LON). Italy seems focused west.

{{
  "reasoning": "Securing Rumania via Turkish agreement is a major success. This improves my southern position and Turkey is now a provisional ally. Germany's move into Silesia is a direct and immediate threat to Warsaw; they are now my primary adversary. Austria and France are posturing, but their conflict doesn't directly affect me yet, keeping them neutral. England's new fleet is a long-term concern but not immediate. Italy's westward focus means they are not a current threat or priority.",
  "relationships": {{
    "GERMANY": "Enemy",
    "AUSTRIA": "Neutral",
    "TURKEY": "Ally",
    "ITALY": "Neutral",
    "FRANCE": "Neutral",
    "ENGLAND": "Unfriendly"
  }},
  "goals": [
    "Defend Warsaw against Germany, possibly by moving Lvn-War or Mos-War.",
    "Solidify alliance with Turkey, potentially coordinating further moves in the south or against Austria if Germany allies with them.",
    "Monitor English fleet movements and prepare for a potential northern threat in future turns.",
    "Explore diplomatic options with France or Austria to counter German aggression."
  ]
}}

JSON FORMAT
Return a single JSON object with these exact keys:
- reasoning: String explaining your updates
- relationships: Object mapping power names to relationship values
- goals: Array of specific goal strings

RETURN JSON BELOW ONLY (DO NOT PREPEND WITH ```json or ``` or any other text)


================================================
File: prompts/system_prompt.txt
================================================
You are playing a game of Diplomacy over text. The map is the standard Diplomacy map. Your goal is to win the game by capturing supply centers, growing your army, and taking over the map. Be aggressive. 

You will be given:
• Which power you are controlling.
• The current phase (e.g. S1901M).
• Details about the map. 
• Your prior conversation history with other players (which may include agreements, lies, etc). 
• The prior order history which includes whether each order was successful or not. 
• A strategic plan that you have made if you are in the negotiations or orders phase. 
• Your units and the possible orders you may make. **Always refer to these possible_orders.**
• A list of enemy units and centers.

For the negotiations and orders phase, remember that while your private chain-of-thought can consider your in-depth reasoning about possible outcomes, **only** the “PARSABLE OUTPUT” (your final orders or messages) will be used by the game engine.


================================================
File: prompts/turkey_system_prompt.txt
================================================
**SYSTEM PROMPT: TURKEY**

You are playing as TURKEY in the game of Diplomacy. Your primary goal is to control 18 supply centers on the map to achieve victory.

**Personality:** You are a strategically positioned power controlling key waterways, often defensive but with potential for significant influence in the East and Mediterranean. You value secure control of the Black Sea and Straits, and alliances that protect against Russia or Austria.

**General Strategic Principles for Victory:**

*   **Proactive Expansion:** Diplomacy is a game of conquest. Prioritize securing new supply centers, especially in the early game. An aggressive, expansionist strategy is often key to building a dominant position.
*   **Calculated Aggression:** While caution has its place, overly defensive or passive play rarely leads to victory. Identify opportunities for bold moves and take calculated risks to seize advantages.
*   **Dynamic Alliances:** Alliances are temporary tools to achieve your objectives. Form them strategically, but always be prepared to adapt, shift, or even betray alliances if it serves your path to ultimate victory. Do not become overly reliant on any single power.
*   **Exploit Weaknesses:** Constantly assess the strengths and weaknesses of other powers. A well-timed strike against a vulnerable or overextended neighbor can yield significant gains.
*   **Focus on Winning:** The ultimate goal is to control 18 supply centers. Every negotiation, move, and strategic decision should be made with this objective in mind. Aim for outright victory, not just survival or a stalemate.
*   **Adapt and Overcome:** Be flexible in your strategy. The political landscape will change rapidly. Re-evaluate your plans each turn and adapt to new threats and opportunities.

Remember to adapt your strategy based on the evolving game state and interactions with other powers. Your ultimate loyalty is to the advancement of TURKEY.



================================================
File: services/__init__.py
================================================
# Reusable infrastructure services 


================================================
File: services/config.py
================================================
"""
Configuration management using Pydantic for validation and type safety.
Supports both game-level and agent-level configuration.
"""
from typing import List, Optional
from pydantic import BaseModel, Field, validator, SettingsConfigDict
import yaml
import logging

logger = logging.getLogger(__name__)


class GameConfig(BaseModel):
    """Game-level configuration."""
    random_seed: Optional[int] = None
    use_mcp: bool = False
    token_budget: int = 6500
    max_years: Optional[int] = None
    log_level: str = "INFO"
    
    class Config:
        extra = "allow"  # Allow additional fields for flexibility


class AgentConfig(BaseModel):
    """Configuration for a single agent."""
    country: str = Field(..., description="Country/power name (e.g., FRANCE)")
    type: str = Field(..., description="Agent type: 'llm', 'scripted', etc.")
    model_id: Optional[str] = Field(None, description="LLM model identifier")
    context_provider: str = Field("auto", description="Context provider: 'inline', 'mcp', 'auto'")
    personality_prompt: Optional[str] = Field(None, description="Path to personality prompt template")
    tool_whitelist: List[str] = Field(default_factory=list, description="Allowed MCP tools")
    
    @validator('country')
    def country_uppercase(cls, v):
        return v.upper()
    
    @validator('type')
    def validate_agent_type(cls, v):
        allowed_types = {'llm', 'scripted', 'human'}
        if v not in allowed_types:
            raise ValueError(f"Agent type must be one of {allowed_types}")
        return v
    
    @validator('context_provider')
    def validate_context_provider(cls, v):
        allowed_providers = {'inline', 'mcp', 'auto'}
        if v not in allowed_providers:
            raise ValueError(f"Context provider must be one of {allowed_providers}")
        return v
    
    class Config:
        extra = "allow"


class DiplomacyConfig(BaseModel):
    """Main configuration container."""
    game: GameConfig = Field(default_factory=GameConfig)
    agents: List[AgentConfig] = Field(default_factory=list)
    
    @validator('agents')
    def validate_unique_countries(cls, v):
        countries = [agent.country for agent in v]
        if len(countries) != len(set(countries)):
            raise ValueError("Each country can only be assigned to one agent")
        return v
    
    @classmethod
    def from_yaml(cls, path: str) -> "DiplomacyConfig":
        """Load configuration from YAML file."""
        try:
            with open(path, 'r') as f:
                data = yaml.safe_load(f)
            return cls(**data)
        except FileNotFoundError:
            logger.warning(f"Config file {path} not found, using defaults")
            return cls()
        except Exception as e:
            logger.error(f"Error loading config from {path}: {e}")
            raise
    
    @classmethod
    def from_legacy_args(cls, args) -> "DiplomacyConfig":
        """Create configuration from legacy argparse.Namespace object."""
        # Convert legacy arguments to new format
        game_config = GameConfig(
            random_seed=getattr(args, 'random_seed', None),
            use_mcp=getattr(args, 'use_mcp', False),
            token_budget=getattr(args, 'max_diary_tokens', 6500),
            max_years=getattr(args, 'max_years', None),
            log_level=getattr(args, 'log_level', 'INFO')
        )
        
        agents = []
        
        # Handle single power mode
        if hasattr(args, 'power_name') and args.power_name:
            agents.append(AgentConfig(
                country=args.power_name,
                type='llm',
                model_id=getattr(args, 'model_id', None),
                context_provider='auto'
            ))
        else:
            # Handle multi-agent configuration from fixed_models
            if hasattr(args, 'fixed_models') and args.fixed_models:
                countries = ['FRANCE', 'GERMANY', 'RUSSIA', 'ENGLAND', 'ITALY', 'AUSTRIA', 'TURKEY']
                for i, model_id in enumerate(args.fixed_models):
                    if i < len(countries):
                        agents.append(AgentConfig(
                            country=countries[i],
                            type='llm',
                            model_id=model_id,
                            context_provider='auto'
                        ))
        
        return cls(game=game_config, agents=agents)
    
    def get_agent_config(self, country: str) -> Optional[AgentConfig]:
        """Get configuration for a specific country."""
        country_upper = country.upper()
        for agent in self.agents:
            if agent.country == country_upper:
                return agent
        return None
    
    def get_llm_agents(self) -> List[AgentConfig]:
        """Get all LLM-based agent configurations."""
        return [agent for agent in self.agents if agent.type == 'llm']
    
    def to_yaml(self, path: str) -> None:
        """Save configuration to YAML file."""
        with open(path, 'w') as f:
            yaml.dump(self.dict(), f, default_flow_style=False)


# Model capability registry for context provider selection
MODEL_CAPABILITIES = {
    'supports_tools': {
        'gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-3.5-turbo',
        'claude-3-5-sonnet', 'claude-3-opus', 'claude-3-sonnet', 'claude-3-haiku'
    }
}


def supports_tools(model_id: str) -> bool:
    """Check if a model supports tool calling."""
    return model_id in MODEL_CAPABILITIES['supports_tools']


def resolve_context_provider(agent_config: AgentConfig) -> str:
    """Resolve 'auto' context provider to concrete implementation."""
    if agent_config.context_provider != 'auto':
        return agent_config.context_provider
    
    if agent_config.model_id and supports_tools(agent_config.model_id):
        return 'mcp'
    else:
        return 'inline'


model_config = SettingsConfigDict(env_prefix = "AID_", extra = "ignore")

@validator("agent_type", pre=True, allow_reuse=True)
def validate_agent_type(cls, v):
    allowed_types = {'llm', 'scripted', 'human'}
    if v not in allowed_types:
        raise ValueError(f"Agent type must be one of {allowed_types}")
    return v 


================================================
File: services/context_provider.py
================================================
"""
Pluggable context provider system for agents.
Supports both inline context (embedded JSON) and MCP-based context (using tools).
"""
import logging
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

from ..core.state import PhaseState
from .config import AgentConfig

logger = logging.getLogger(__name__)


@dataclass
class ContextData:
    """Container for all context information needed by agents."""
    phase_state: PhaseState
    possible_orders: Dict[str, List[str]]
    game_history: Optional[Any] = None  # GameHistory object
    recent_messages: Optional[str] = None
    strategic_analysis: Optional[str] = None
    additional_data: Optional[Dict[str, Any]] = None


class ContextProvider(ABC):
    """
    Abstract base class for context providers.
    
    Context providers are responsible for delivering game state and context
    information to agents in different formats (inline vs MCP tools).
    """
    
    @abstractmethod
    async def provide_context(
        self, 
        agent_id: str,
        country: str,
        context_data: ContextData,
        agent_config: AgentConfig
    ) -> Dict[str, Any]:
        """
        Provide context information to an agent.
        
        Args:
            agent_id: Unique identifier for the requesting agent
            country: The country/power the agent represents
            context_data: All available context information
            agent_config: Agent configuration
            
        Returns:
            Dictionary containing context in provider-specific format
        """
        pass
    
    @abstractmethod
    def get_provider_type(self) -> str:
        """Return the type identifier for this provider."""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """Check if this provider is available/configured correctly."""
        pass


class InlineContextProvider(ContextProvider):
    """
    Provides context by embedding all information directly in prompts.
    
    This is the traditional approach where all game state, possible orders,
    and strategic analysis are included as formatted text in the prompt.
    """
    
    def __init__(self):
        """Initialize the inline context provider."""
        self.provider_type = "inline"
        logger.info("InlineContextProvider initialized")
    
    async def provide_context(
        self, 
        agent_id: str,
        country: str,
        context_data: ContextData,
        agent_config: AgentConfig
    ) -> Dict[str, Any]:
        """
        Provide inline context by formatting all data as text.
        
        Returns:
            Dictionary with 'context_text' containing formatted context
        """
        logger.debug(f"Providing inline context for {country}")
        
        try:
            # Format phase state information
            phase_info = self._format_phase_state(context_data.phase_state, country)
            
            # Format possible orders
            orders_info = self._format_possible_orders(context_data.possible_orders, country)
            
            # Format strategic analysis if available
            strategic_info = self._format_strategic_analysis(context_data.strategic_analysis)
            
            # Format recent messages
            messages_info = self._format_recent_messages(context_data.recent_messages)
            
            # Combine all context sections
            context_sections = [
                "=== GAME STATE ===",
                phase_info,
                "",
                "=== YOUR POSSIBLE ORDERS ===",
                orders_info,
                "",
                "=== STRATEGIC ANALYSIS ===", 
                strategic_info,
                "",
                "=== RECENT MESSAGES ===",
                messages_info
            ]
            
            context_text = "\n".join(context_sections)
            
            return {
                "provider_type": "inline",
                "context_text": context_text,
                "tools_available": False
            }
            
        except Exception as e:
            logger.error(f"Error providing inline context for {country}: {e}", exc_info=True)
            # Return minimal fallback context
            return {
                "provider_type": "inline",
                "context_text": f"Context generation failed: {e}",
                "tools_available": False
            }
    
    def _format_phase_state(self, phase_state: PhaseState, country: str) -> str:
        """Format phase state information as text."""
        lines = [
            f"Phase: {phase_state.phase_name}",
            f"Year: {phase_state.year}, Season: {phase_state.season}",
            f"Phase Type: {phase_state.phase_type}",
            "",
            f"Your Units ({country}):",
        ]
        
        my_units = phase_state.get_power_units(country)
        if my_units:
            for unit in my_units:
                lines.append(f"  - {unit}")
        else:
            lines.append("  - No units")
        
        lines.append("")
        lines.append(f"Your Supply Centers ({country}):")
        my_centers = phase_state.get_power_centers(country)
        if my_centers:
            for center in my_centers:
                lines.append(f"  - {center}")
        else:
            lines.append("  - No supply centers")
        
        lines.append("")
        lines.append("All Powers Status:")
        for power in sorted(phase_state.powers):
            if phase_state.is_power_eliminated(power):
                status = "[ELIMINATED]"
            else:
                center_count = phase_state.get_center_count(power)
                unit_count = len(phase_state.get_power_units(power))
                status = f"({center_count} centers, {unit_count} units)"
            lines.append(f"  - {power}: {status}")
        
        return "\n".join(lines)
    
    def _format_possible_orders(self, possible_orders: Dict[str, List[str]], country: str) -> str:
        """Format possible orders as text."""
        if not possible_orders:
            return "No orders available for this phase."
        
        lines = []
        for location, orders in possible_orders.items():
            lines.append(f"Unit at {location}:")
            for order in orders:
                lines.append(f"  - {order}")
            lines.append("")
        
        return "\n".join(lines)
    
    def _format_strategic_analysis(self, strategic_analysis: Optional[str]) -> str:
        """Format strategic analysis as text."""
        if not strategic_analysis:
            return "No strategic analysis available."
        return strategic_analysis
    
    def _format_recent_messages(self, recent_messages: Optional[str]) -> str:
        """Format recent messages as text."""
        if not recent_messages:
            return "No recent messages."
        return recent_messages
    
    def get_provider_type(self) -> str:
        """Return the provider type."""
        return self.provider_type
    
    def is_available(self) -> bool:
        """Inline context is always available."""
        return True


class MCPContextProvider(ContextProvider):
    """
    Provides context through MCP (Model Context Protocol) tools.
    
    This provider exposes game state and analysis as callable tools
    that MCP-aware models can invoke dynamically during reasoning.
    """
    
    def __init__(self, mcp_client=None):
        """
        Initialize the MCP context provider.
        
        Args:
            mcp_client: MCP client instance (will create if None)
        """
        self.provider_type = "mcp"
        self.mcp_client = mcp_client
        logger.info(f"MCP client set for {self.__class__.__name__}")
    
    async def provide_context(
        self, 
        agent_id: str,
        country: str,
        context_data: ContextData,
        agent_config: AgentConfig
    ) -> Dict[str, Any]:
        """
        Provide MCP-based context through tool definitions.
        
        Returns:
            Dictionary with tool definitions and minimal prompt context
        """
        logger.debug(f"Providing MCP context for {country}")
        
        if not self.is_available():
            logger.warning(f"MCP provider not available for {country}, falling back to basic context")
            return {
                "provider_type": "mcp",
                "context_text": "MCP tools not available - using basic context",
                "tools_available": False,
                "tools": []
            }
        
        try:
            # Define available tools for this agent
            tools = self._define_available_tools(agent_id, country, context_data)
            
            # Provide minimal prompt context (MCP tools will provide the rest)
            basic_context = f"""
You are playing as {country} in Diplomacy.
Current Phase: {context_data.phase_state.phase_name}

You have access to the following tools to get detailed information:
{self._format_tool_descriptions(tools)}

Use these tools to gather the information you need to make decisions.
            """.strip()
            
            return {
                "provider_type": "mcp",
                "context_text": basic_context,
                "tools_available": True,
                "tools": tools
            }
            
        except Exception as e:
            logger.error(f"Error providing MCP context for {country}: {e}", exc_info=True)
            return {
                "provider_type": "mcp",
                "context_text": f"MCP context failed: {e}",
                "tools_available": False,
                "tools": []
            }
    
    def _define_available_tools(self, agent_id: str, country: str, context_data: ContextData) -> List[Dict[str, Any]]:
        """Define MCP tools available to this agent."""
        tools = [
            {
                "name": "diplomacy.board_state",
                "description": f"Get current board state for {country} including units, centers, and power status",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "include_details": {
                            "type": "boolean",
                            "description": "Include detailed analysis",
                            "default": True
                        }
                    }
                }
            },
            {
                "name": "diplomacy.possible_orders",
                "description": f"Get all possible orders for {country}'s units this phase",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "include_strategic_analysis": {
                            "type": "boolean", 
                            "description": "Include strategic analysis of each order",
                            "default": False
                        }
                    }
                }
            },
            {
                "name": "diplomacy.recent_messages",
                "description": "Get recent diplomatic messages involving this power",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "phases_back": {
                            "type": "integer",
                            "description": "How many phases back to look",
                            "default": 3
                        }
                    }
                }
            }
        ]
        
        return tools
    
    def _format_tool_descriptions(self, tools: List[Dict[str, Any]]) -> str:
        """Format tool descriptions for the prompt."""
        descriptions = []
        for tool in tools:
            descriptions.append(f"- {tool['name']}: {tool['description']}")
        return "\n".join(descriptions)
    
    def get_provider_type(self) -> str:
        """Return the provider type."""
        return self.provider_type
    
    def is_available(self) -> bool:
        """Check if MCP client is configured and available."""
        return self.mcp_client is not None


class ContextProviderFactory:
    """
    Factory for creating and managing context providers.
    
    Handles automatic provider selection based on model capabilities
    and configuration preferences.
    """
    
    def __init__(self):
        """Initialize the factory."""
        self._providers = {}
        self._register_default_providers()
        logger.info("ContextProviderFactory initialized")
    
    def _register_default_providers(self):
        """Register the default context providers."""
        self._providers["inline"] = InlineContextProvider()
        self._providers["mcp"] = MCPContextProvider()
    
    def get_provider(self, provider_type: str) -> ContextProvider:
        """
        Get a context provider by type.
        
        Args:
            provider_type: Type of provider ("inline", "mcp", or "auto")
            
        Returns:
            ContextProvider instance
            
        Raises:
            ValueError: If provider type is not supported
        """
        if provider_type == "auto":
            # Auto-selection logic - prefer MCP if available, fallback to inline
            if self._providers["mcp"].is_available():
                return self._providers["mcp"]
            else:
                return self._providers["inline"]
        
        if provider_type not in self._providers:
            raise ValueError(f"Unknown context provider type: {provider_type}")
        
        provider = self._providers[provider_type]
        
        if not provider.is_available():
            logger.warning(f"Requested provider '{provider_type}' is not available, falling back to inline")
            return self._providers["inline"]
        
        return provider
    
    def get_available_providers(self) -> List[str]:
        """Get list of available provider types."""
        return [ptype for ptype, provider in self._providers.items() if provider.is_available()] 


================================================
File: services/llm_coordinator.py
================================================
"""
Centralized LLM coordination service.
Single entry point for all LLM calls with model pooling, serial locking, usage tracking, and retry logic.
"""
import asyncio
# Removed: import os
import logging
from typing import Optional, Dict, Any, AsyncIterator, List # Removed Union, ContextManager
from contextlib import asynccontextmanager
# Removed: import json
import sqlite3 # Added import
# Removed: import functools

import llm # Assuming this is the llm library by Simon Willison
from llm.models import Model as LLMModel # Renamed to avoid conflict, used for type hinting
from llm import Response as LLMResponse # For type hinting

logger = logging.getLogger(__name__)

# --- New Global Components based on the provided pattern ---

DATABASE_PATH = "ai_diplomacy_usage.db"
_local_lock = asyncio.Lock() # Removed comment: Global lock for local LLM engines

class ModelPool:
    """Caches LLM model instances."""
    _cache: Dict[str, LLMModel] = {}

    @classmethod
    def get(cls, model_id: str) -> LLMModel:
        """Retrieves a model from the cache, loading if not present."""
        if model_id not in cls._cache:
            logger.debug(f"[ModelPool] Loading and caching model: {model_id}")
            cls._cache[model_id] = llm.get_async_model(model_id)
        else:
            logger.debug(f"[ModelPool] Retrieving model from cache: {model_id}")
        return cls._cache[model_id]

@asynccontextmanager
async def serial_if_local(model_id: str) -> AsyncIterator[None]:
    """
    Context manager to serialize access to local LLMs (ollama, llamacpp).
    """
    model_id_lower = model_id.lower()
    # Case-insensitive check will be applied to these prefixes
    # These prefixes are taken from the original SERIAL_ACCESS_PREFIXES
    if any(model_id_lower.startswith(prefix) for prefix in ["ollama/", "llamacpp/"]):
        logger.debug(f"Acquiring lock for local model: {model_id}")
        async with _local_lock:
            logger.debug(f"Lock acquired for local model: {model_id}")
            yield
            logger.debug(f"Lock released for local model: {model_id}")
    else:
        yield

def initialize_database():
    """Initializes the SQLite database and creates the 'usage' table if it doesn't exist."""
    try:
        with sqlite3.connect(DATABASE_PATH) as conn:
            conn.execute("PRAGMA journal_mode=WAL;")
            conn.execute("""
            CREATE TABLE IF NOT EXISTS usage (
              id          INTEGER PRIMARY KEY,
              game_id     TEXT,
              agent       TEXT,
              phase       TEXT,
              model       TEXT,
              input       INTEGER,
              output      INTEGER,
              ts          DATETIME DEFAULT CURRENT_TIMESTAMP
            );
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS usage_game_agent ON usage (game_id, agent);")
            conn.commit()
        logger.info(f"Database initialized successfully at {DATABASE_PATH}")
    except sqlite3.Error as e:
        logger.error(f"Error initializing database {DATABASE_PATH}: {e}", exc_info=True)
        raise

initialize_database() # Removed comment: Initialize DB on module load

async def record_usage(game_id: str, agent: str, phase: str, response: LLMResponse):
    """Records LLM token usage in the database."""
    try:
        usage_stats = await response.usage() # Usage(input=..., output=..., details=...)
        with sqlite3.connect(DATABASE_PATH) as conn:
            conn.execute(
                "INSERT INTO usage (game_id, agent, phase, model, input, output) VALUES (?, ?, ?, ?, ?, ?)",
                (game_id, agent, phase, response.model.model_id, usage_stats.input, usage_stats.output)
            )
            conn.commit()
        logger.debug(f"Usage recorded for {agent} in game {game_id}, phase {phase}: {usage_stats.input} in, {usage_stats.output} out for model {response.model.model_id}")
    except sqlite3.Error as e:
        logger.error(f"SQLite error in record_usage: {e}", exc_info=True)
    except AttributeError as e:
        logger.error(f"Error accessing response attributes in record_usage (model: {response.model.model_id if hasattr(response, 'model') else 'N/A'}): {e}", exc_info=True)
    except Exception as e:
        logger.error(f"Unexpected error in record_usage: {e}", exc_info=True)

def get_usage_stats_by_country(game_id: str) -> Dict[str, Dict[str, int]]:
    """Get API usage statistics by country for a specific game."""
    try:
        with sqlite3.connect(DATABASE_PATH) as conn:
            cursor = conn.execute("""
                SELECT agent, 
                       COUNT(*) as api_calls,
                       SUM(input) as total_input_tokens,
                       SUM(output) as total_output_tokens,
                       model
                FROM usage 
                WHERE game_id = ? 
                GROUP BY agent, model
                ORDER BY agent
            """, (game_id,))
            
            results = {}
            for row in cursor.fetchall():
                agent, api_calls, input_tokens, output_tokens, model = row
                if agent not in results:
                    results[agent] = {
                        'api_calls': 0,
                        'input_tokens': 0,
                        'output_tokens': 0,
                        'models': []
                    }
                results[agent]['api_calls'] += api_calls
                results[agent]['input_tokens'] += input_tokens or 0
                results[agent]['output_tokens'] += output_tokens or 0
                if model not in results[agent]['models']:
                    results[agent]['models'].append(model)
            
            return results
    except sqlite3.Error as e:
        logger.error(f"Error getting usage stats: {e}", exc_info=True)
        return {}

def get_total_usage_stats(game_id: str) -> Dict[str, int]:
    """Get total API usage statistics for a specific game."""
    try:
        with sqlite3.connect(DATABASE_PATH) as conn:
            cursor = conn.execute("""
                SELECT COUNT(*) as total_api_calls,
                       SUM(input) as total_input_tokens,
                       SUM(output) as total_output_tokens
                FROM usage 
                WHERE game_id = ?
            """, (game_id,))
            
            row = cursor.fetchone()
            if row:
                return {
                    'total_api_calls': row[0],
                    'total_input_tokens': row[1] or 0,
                    'total_output_tokens': row[2] or 0
                }
            return {'total_api_calls': 0, 'total_input_tokens': 0, 'total_output_tokens': 0}
    except sqlite3.Error as e:
        logger.error(f"Error getting total usage stats: {e}", exc_info=True)
        return {'total_api_calls': 0, 'total_input_tokens': 0, 'total_output_tokens': 0}

async def llm_call_internal(
    game_id: str,
    agent_name: str,
    phase_str: str,
    model_id: str,
    prompt: str,
    system_prompt: Optional[str] = None,
    **kwargs: Any
) -> str:
    """
    Internal wrapper for LLM calls incorporating model pooling, serial locking, and usage recording.
    """
    model_obj = ModelPool.get(model_id)
    
    prompt_options: Dict[str, Any] = {}
    if system_prompt:
        prompt_options['system'] = system_prompt
    prompt_options.update(kwargs)

    async with serial_if_local(model_id):
        response_obj = model_obj.prompt(prompt, **prompt_options)
        
        # Ensure we wait for the text to be fully generated.
        response_text = await response_obj.text()
        
        # Record usage after getting the response (fire-and-forget)
        asyncio.create_task(record_usage(game_id, agent_name, phase_str, response_obj))
        
        return response_text

# --- End of New Global Components ---

# _local_llm_lock = asyncio.Lock() # Removed, use _local_lock

# Case-insensitive check will be applied to these prefixes
# SERIAL_ACCESS_PREFIXES = ["ollama/", "llamacpp/"] # Removed
# SERIALIZE_LOCAL_LLMS_ENV_VAR = "SERIALIZE_LOCAL_LLMS" # Removed


class LLMCallResult:
    """Structured result from an LLM call with parsing."""
    def __init__(
        self, 
        raw_response: str, 
        parsed_json: Optional[Dict[str, Any]] = None,
        success: bool = True,
        error_message: str = ""
    ):
        self.raw_response = raw_response
        self.parsed_json = parsed_json
        self.success = success
        self.error_message = error_message

    def get_field(self, *field_names: str) -> Optional[Any]:
        """Get the first available field from the parsed JSON."""
        if not self.parsed_json:
            return None
        
        for field_name in field_names:
            if field_name in self.parsed_json:
                return self.parsed_json[field_name]
        return None

class LLMCoordinator:
    """
    Coordinates requests to LLMs, incorporating model pooling, serial access for local models,
    and usage tracking. Single entry point for all LLM interactions.
    """

    def __init__(self):
        """Initialize the LLM coordinator."""
        logger.info("LLMCoordinator initialized.")

    async def call_text(
        self,
        prompt: str,
        *,
        model_id: str,
        agent_id: str,
        game_id: str = "default",
        phase: str = "unknown",
        system_prompt: Optional[str] = None
    ) -> str:
        """
        Simple text completion call.
        
        Args:
            prompt: The prompt text
            model_id: LLM model identifier  
            agent_id: Agent identifier for tracking
            game_id: Game identifier for tracking
            phase: Game phase for tracking
            system_prompt: Optional system prompt
            
        Returns:
            The raw text response
        """
        return await llm_call_internal(
            game_id=game_id,
            agent_name=agent_id,
            phase_str=phase,
            model_id=model_id,
            prompt=prompt,
            system_prompt=system_prompt
        )

    async def call_json(
        self,
        prompt: str,
        *,
        model_id: str,
        agent_id: str,
        game_id: str = "default",
        phase: str = "unknown",
        system_prompt: Optional[str] = None,
        tools: Optional[List[Dict[str, Any]]] = None,
        expected_fields: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        JSON completion call with parsing and validation.
        
        Args:
            prompt: The prompt text
            model_id: LLM model identifier
            agent_id: Agent identifier for tracking
            game_id: Game identifier for tracking  
            phase: Game phase for tracking
            system_prompt: Optional system prompt
            tools: Optional tool definitions for MCP-capable models
            expected_fields: Optional list of required JSON fields
            
        Returns:
            Parsed JSON response
            
        Raises:
            ValueError: If JSON parsing fails or required fields are missing
        """
        # TODO: Implement tool calling logic for MCP in Stage 3
        if tools:
            logger.debug(f"Tools provided but MCP not yet implemented: {len(tools)} tools")
        
        result = await self.call_llm_with_json_parsing(
            model_id=model_id,
            prompt=prompt,
            system_prompt=system_prompt,
            game_id=game_id,
            agent_name=agent_id,
            phase_str=phase,
            expected_json_fields=expected_fields
        )
        
        if not result.success:
            raise ValueError(f"LLM call failed: {result.error_message}")
        
        return result.parsed_json or {}

    async def call_llm_with_json_parsing(
        self,
        model_id: str,
        prompt: str,
        game_id: str,
        agent_name: str,
        phase_str: str,
        system_prompt: Optional[str] = None,
        request_identifier: str = "request",
        expected_json_fields: Optional[list] = None,
        response_type: str = "llm_call",
        log_to_file_path: Optional[str] = None
    ) -> LLMCallResult:
        """
        Internal method for LLM calls with JSON parsing.
        Used by call_json() and legacy code during transition.
        """
        from .. import llm_utils  # Import here to avoid circular imports
        from ..utils import log_llm_response # Assuming this is still used for file logging
        
        result = LLMCallResult("", None, False, "Not initialized")
        
        try:
            logger.info(f"[{request_identifier}] Preparing LLM call. "
                       f"Game: {game_id}, Agent: {agent_name}, Phase: {phase_str}, Model: {model_id}")
            
            raw_response = await llm_call_internal(
                game_id=game_id,
                agent_name=agent_name,
                phase_str=phase_str,
                model_id=model_id,
                prompt=prompt,
                system_prompt=system_prompt
            )
            
            result.raw_response = raw_response
            
            if raw_response and raw_response.strip():
                try:
                    parsed_data = llm_utils.extract_json_from_text(
                        raw_response, logger, f"[{request_identifier}] JSON Parsing"
                    )
                    result.parsed_json = parsed_data
                    result.success = True
                    result.error_message = ""
                    
                    # Validate expected fields if provided
                    if expected_json_fields and isinstance(parsed_data, dict):
                        missing_fields = [field for field in expected_json_fields 
                                        if field not in parsed_data]
                        if missing_fields:
                            result.success = False
                            result.error_message = f"Missing expected fields: {missing_fields}"
                    
                except Exception as e:
                    logger.error(f"[{request_identifier}] JSON parsing failed: {e}", exc_info=True)
                    result.success = False
                    result.error_message = f"JSON parsing error: {e}"
            else:
                result.success = False
                result.error_message = "Empty or no response from LLM"
                
        except Exception as e:
            logger.error(f"[{request_identifier}] LLM call failed: {e}", exc_info=True)
            result.success = False
            result.error_message = f"LLM call error: {e}"
            if not result.raw_response:
                result.raw_response = f"Error: {e}"
        
        # Log the full prompt/response to file if path provided
        if log_to_file_path and agent_name and phase_str:
            success_status = "TRUE" if result.success else f"FALSE: {result.error_message}"
            log_llm_response(
                log_file_path=log_to_file_path,
                model_name=model_id,
                power_name=agent_name,
                phase=phase_str,
                response_type=response_type,
                raw_input_prompt=prompt,
                raw_response=result.raw_response,
                success=success_status
            )
        
        return result

    async def request(
        self,
        model_id: str,
        prompt_text: str,
        system_prompt_text: Optional[str],
        # New parameters for llm_call_internal
        game_id: str,
        agent_name: str, # Was implicitly part of request_identifier before, now explicit
        phase_str: str,    # New explicit parameter
        request_identifier: str = "request" # For coordinator's logging
    ) -> str:
        """
        Makes a request to the specified LLM using the new internal wrapper.
        Handles model pooling, serial locking for local models, and DB-based usage logging.

        Args:
            model_id: The ID of the LLM to use (e.g., "ollama/llama3", "gpt-4o").
            prompt_text: The main prompt text for the LLM.
            system_prompt_text: Optional system prompt text.
            game_id: Game identifier for DB logging and context.
            agent_name: Agent/Power name for DB logging and context.
            phase_str: Game phase for DB logging and context.
            request_identifier: An identifier for the coordinator's logging purposes.

        Returns:
            The text response from the LLM.

        Raises:
            Exception: Propagates exceptions from llm_call_internal.
        """
        logger.debug(f"[{request_identifier}] LLMCoordinator.request initiated. Model: {model_id}, Game: {game_id}, Agent: {agent_name}, Phase: {phase_str}")
        logger.debug(f"[LLMCoordinator] Using model_id: {model_id}, system_prompt: {'Yes' if system_prompt_text else 'No'}")
        logger.debug(f"[LLMCoordinator] Prompt (first 200 chars): {prompt_text[:200]}...")
        
        try:
            response_text = await llm_call_internal(
                game_id=game_id,
                agent_name=agent_name,
                phase_str=phase_str,
                model_id=model_id,
                prompt=prompt_text,
                system_prompt=system_prompt_text
            )
            
            logger.info(f"[{request_identifier}] LLM call for {model_id} (Game: {game_id}, Agent: {agent_name}) succeeded via llm_call_internal.")
            logger.debug(f"[{request_identifier}] Received response from '{model_id}'. Response length: {len(response_text)}")
            return response_text
            
        except Exception as e:
            logger.error(f"[{request_identifier}] Error during LLM request via llm_call_internal to '{model_id}' (Game: {game_id}, Agent: {agent_name}): {type(e).__name__}: {e}", exc_info=True)
            raise

    async def get_model(self, model_id: str) -> LLMModel: # Renamed from get_model_for_power
        """Retrieves an LLM model instance using the ModelPool."""
        # power_name argument removed as ModelPool is global
        logger.debug(f"Requesting model: {model_id} via ModelPool")
        try:
            model_obj = ModelPool.get(model_id)
            logger.debug(f"Successfully retrieved model: {model_id} from ModelPool")
            return model_obj
        except Exception as e:
            logger.error(f"Failed to get model {model_id} via ModelPool: {e}", exc_info=True)
            raise

    # execute_llm_call method removed as it was a simple wrapper for request

# Initialize database on module load
initialize_database()

# Global coordinator instance
_global_coordinator = LLMCoordinator()



================================================
File: services/usage_tracker.py
================================================
"""
Usage tracking and analytics service.
Provides utilities for token usage analysis and Datasette integration.
"""
import sqlite3
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime

logger = logging.getLogger(__name__)

DATABASE_PATH = "ai_diplomacy_usage.db"


@dataclass
class UsageStats:
    """Container for usage statistics."""
    agent: str
    total_calls: int
    total_input_tokens: int
    total_output_tokens: int
    models_used: List[str]
    cost_estimate: Optional[float] = None


@dataclass
class GameSummary:
    """Summary statistics for a complete game."""
    game_id: str
    total_agents: int
    total_calls: int
    total_input_tokens: int
    total_output_tokens: int
    duration_hours: Optional[float] = None
    cost_estimate: Optional[float] = None


class UsageTracker:
    """Service for analyzing LLM usage patterns and costs."""
    
    def __init__(self, db_path: str = DATABASE_PATH):
        self.db_path = db_path
    
    def get_agent_stats(self, game_id: str, agent: str) -> Optional[UsageStats]:
        """Get usage statistics for a specific agent in a game."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT 
                        COUNT(*) as calls,
                        SUM(input) as input_tokens,
                        SUM(output) as output_tokens,
                        GROUP_CONCAT(DISTINCT model) as models
                    FROM usage 
                    WHERE game_id = ? AND agent = ?
                """, (game_id, agent))
                
                row = cursor.fetchone()
                if row and row[0] > 0:
                    models = row[3].split(',') if row[3] else []
                    return UsageStats(
                        agent=agent,
                        total_calls=row[0],
                        total_input_tokens=row[1] or 0,
                        total_output_tokens=row[2] or 0,
                        models_used=models
                    )
                return None
        except sqlite3.Error as e:
            logger.error(f"Error getting agent stats: {e}")
            return None
    
    def get_game_summary(self, game_id: str) -> Optional[GameSummary]:
        """Get overall statistics for a game."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Get basic stats
                cursor = conn.execute("""
                    SELECT 
                        COUNT(DISTINCT agent) as agents,
                        COUNT(*) as calls,
                        SUM(input) as input_tokens,
                        SUM(output) as output_tokens,
                        MIN(ts) as start_time,
                        MAX(ts) as end_time
                    FROM usage 
                    WHERE game_id = ?
                """, (game_id,))
                
                row = cursor.fetchone()
                if row and row[1] > 0:
                    # Calculate duration if we have timestamps
                    duration = None
                    if row[4] and row[5]:
                        try:
                            start = datetime.fromisoformat(row[4])
                            end = datetime.fromisoformat(row[5])
                            duration = (end - start).total_seconds() / 3600  # hours
                        except ValueError:
                            pass
                    
                    return GameSummary(
                        game_id=game_id,
                        total_agents=row[0],
                        total_calls=row[1],
                        total_input_tokens=row[2] or 0,
                        total_output_tokens=row[3] or 0,
                        duration_hours=duration
                    )
                return None
        except sqlite3.Error as e:
            logger.error(f"Error getting game summary: {e}")
            return None
    
    def get_all_games(self) -> List[str]:
        """Get list of all game IDs in the database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("SELECT DISTINCT game_id FROM usage ORDER BY game_id")
                return [row[0] for row in cursor.fetchall()]
        except sqlite3.Error as e:
            logger.error(f"Error getting game list: {e}")
            return []
    
    def get_phase_breakdown(self, game_id: str) -> Dict[str, UsageStats]:
        """Get usage breakdown by phase for a game."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT 
                        phase,
                        COUNT(*) as calls,
                        SUM(input) as input_tokens,
                        SUM(output) as output_tokens
                    FROM usage 
                    WHERE game_id = ?
                    GROUP BY phase
                    ORDER BY phase
                """, (game_id,))
                
                results = {}
                for row in cursor.fetchall():
                    results[row[0]] = UsageStats(
                        agent=f"Phase {row[0]}",
                        total_calls=row[1],
                        total_input_tokens=row[2] or 0,
                        total_output_tokens=row[3] or 0,
                        models_used=[]
                    )
                return results
        except sqlite3.Error as e:
            logger.error(f"Error getting phase breakdown: {e}")
            return {}
    
    def export_for_datasette(self, output_path: Optional[str] = None) -> str:
        """
        Export data in a format optimized for Datasette viewing.
        Returns the path to the exported database.
        """
        if output_path is None:
            output_path = self.db_path.replace('.db', '_datasette.db')
        
        try:
            with sqlite3.connect(self.db_path) as source:
                with sqlite3.connect(output_path) as dest:
                    # Copy the usage table
                    source.backup(dest)
                    
                    # Add computed views for better Datasette experience
                    dest.execute("""
                        CREATE VIEW IF NOT EXISTS game_summary AS
                        SELECT 
                            game_id,
                            COUNT(DISTINCT agent) as agents,
                            COUNT(*) as total_calls,
                            SUM(input) as total_input_tokens,
                            SUM(output) as total_output_tokens,
                            ROUND(AVG(input), 2) as avg_input_per_call,
                            ROUND(AVG(output), 2) as avg_output_per_call,
                            MIN(ts) as start_time,
                            MAX(ts) as end_time
                        FROM usage 
                        GROUP BY game_id
                    """)
                    
                    dest.execute("""
                        CREATE VIEW IF NOT EXISTS agent_performance AS
                        SELECT 
                            game_id,
                            agent,
                            COUNT(*) as calls,
                            SUM(input) as input_tokens,
                            SUM(output) as output_tokens,
                            ROUND(SUM(input + output) / COUNT(*), 2) as avg_tokens_per_call,
                            GROUP_CONCAT(DISTINCT model) as models_used
                        FROM usage 
                        GROUP BY game_id, agent
                    """)
                    
                    dest.execute("""
                        CREATE VIEW IF NOT EXISTS phase_analysis AS
                        SELECT 
                            game_id,
                            phase,
                            COUNT(*) as calls,
                            COUNT(DISTINCT agent) as active_agents,
                            SUM(input) as input_tokens,
                            SUM(output) as output_tokens
                        FROM usage 
                        GROUP BY game_id, phase
                    """)
                    
                    dest.commit()
            
            logger.info(f"Exported Datasette-optimized database to {output_path}")
            return output_path
            
        except sqlite3.Error as e:
            logger.error(f"Error exporting for Datasette: {e}")
            raise
    
    def generate_cost_estimate(self, stats: UsageStats, model_id: str) -> float:
        """
        Generate rough cost estimate based on token usage.
        These are approximations based on common pricing as of 2024.
        """
        # Rough pricing per 1K tokens (input/output) for common models
        pricing = {
            'gpt-4o': (0.005, 0.015),
            'gpt-4o-mini': (0.00015, 0.0006),
            'gpt-4-turbo': (0.01, 0.03),
            'gpt-3.5-turbo': (0.001, 0.002),
            'claude-3-5-sonnet': (0.003, 0.015),
            'claude-3-opus': (0.015, 0.075),
            'claude-3-sonnet': (0.003, 0.015),
            'claude-3-haiku': (0.00025, 0.00125),
        }
        
        # Default pricing for unknown models (use GPT-4o-mini as baseline)
        input_price, output_price = pricing.get(model_id, (0.00015, 0.0006))
        
        input_cost = (stats.total_input_tokens / 1000) * input_price
        output_cost = (stats.total_output_tokens / 1000) * output_price
        
        return input_cost + output_cost


def create_datasette_config(db_path: str) -> Dict[str, Any]:
    """
    Create a Datasette configuration for the usage database.
    Returns a config dict that can be saved as metadata.json.
    """
    return {
        "title": "AI Diplomacy Usage Analytics",
        "description": "Token usage and performance analytics for AI Diplomacy games",
        "databases": {
            "usage": {
                "title": "LLM Usage Database",
                "description": "Detailed token usage logs for AI agents",
                "tables": {
                    "usage": {
                        "title": "Raw Usage Data",
                        "description": "Individual LLM API calls with token counts",
                        "sort_desc": "ts"
                    },
                    "game_summary": {
                        "title": "Game Summaries",
                        "description": "Aggregated statistics per game"
                    },
                    "agent_performance": {
                        "title": "Agent Performance", 
                        "description": "Per-agent statistics across games"
                    },
                    "phase_analysis": {
                        "title": "Phase Analysis",
                        "description": "Token usage patterns by game phase"
                    }
                }
            }
        },
        "plugins": {
            "datasette-vega": {
                "default_width": 800,
                "default_height": 400
            }
        }
    } 


